{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "import seaborn as sns\n",
    "from keras.layers import Input,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "import quandl\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>515.00</td>\n",
       "      <td>453.16</td>\n",
       "      <td>499.01</td>\n",
       "      <td>500.01</td>\n",
       "      <td>505.04</td>\n",
       "      <td>28535.844106</td>\n",
       "      <td>491.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>548.00</td>\n",
       "      <td>494.02</td>\n",
       "      <td>534.00</td>\n",
       "      <td>535.01</td>\n",
       "      <td>536.00</td>\n",
       "      <td>31159.941300</td>\n",
       "      <td>520.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>537.24</td>\n",
       "      <td>481.63</td>\n",
       "      <td>506.52</td>\n",
       "      <td>504.70</td>\n",
       "      <td>505.38</td>\n",
       "      <td>21126.375080</td>\n",
       "      <td>504.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>508.43</td>\n",
       "      <td>470.00</td>\n",
       "      <td>487.00</td>\n",
       "      <td>484.14</td>\n",
       "      <td>487.00</td>\n",
       "      <td>11879.484756</td>\n",
       "      <td>485.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>507.43</td>\n",
       "      <td>472.81</td>\n",
       "      <td>504.74</td>\n",
       "      <td>504.74</td>\n",
       "      <td>505.00</td>\n",
       "      <td>10262.195861</td>\n",
       "      <td>492.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>16894.93</td>\n",
       "      <td>15875.50</td>\n",
       "      <td>16724.62</td>\n",
       "      <td>16719.84</td>\n",
       "      <td>16729.63</td>\n",
       "      <td>7511.143605</td>\n",
       "      <td>16409.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>17868.00</td>\n",
       "      <td>16570.00</td>\n",
       "      <td>17681.77</td>\n",
       "      <td>17670.67</td>\n",
       "      <td>17680.50</td>\n",
       "      <td>9824.899652</td>\n",
       "      <td>17260.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>18483.00</td>\n",
       "      <td>17041.47</td>\n",
       "      <td>17785.95</td>\n",
       "      <td>17783.71</td>\n",
       "      <td>17792.96</td>\n",
       "      <td>15717.759599</td>\n",
       "      <td>17874.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>18189.97</td>\n",
       "      <td>17346.62</td>\n",
       "      <td>17819.37</td>\n",
       "      <td>17817.05</td>\n",
       "      <td>17819.42</td>\n",
       "      <td>10507.652250</td>\n",
       "      <td>17792.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>18824.88</td>\n",
       "      <td>17755.81</td>\n",
       "      <td>18685.08</td>\n",
       "      <td>18674.71</td>\n",
       "      <td>18681.69</td>\n",
       "      <td>10018.272538</td>\n",
       "      <td>18370.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      High       Low      Last       Bid       Ask  \\\n",
       "0    2014-04-15    515.00    453.16    499.01    500.01    505.04   \n",
       "1    2014-04-16    548.00    494.02    534.00    535.01    536.00   \n",
       "2    2014-04-17    537.24    481.63    506.52    504.70    505.38   \n",
       "3    2014-04-18    508.43    470.00    487.00    484.14    487.00   \n",
       "4    2014-04-19    507.43    472.81    504.74    504.74    505.00   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "2381 2020-11-17  16894.93  15875.50  16724.62  16719.84  16729.63   \n",
       "2382 2020-11-18  17868.00  16570.00  17681.77  17670.67  17680.50   \n",
       "2383 2020-11-19  18483.00  17041.47  17785.95  17783.71  17792.96   \n",
       "2384 2020-11-20  18189.97  17346.62  17819.37  17817.05  17819.42   \n",
       "2385 2020-11-21  18824.88  17755.81  18685.08  18674.71  18681.69   \n",
       "\n",
       "            Volume      VWAP  \n",
       "0     28535.844106    491.41  \n",
       "1     31159.941300    520.21  \n",
       "2     21126.375080    504.83  \n",
       "3     11879.484756    485.72  \n",
       "4     10262.195861    492.22  \n",
       "...            ...       ...  \n",
       "2381   7511.143605  16409.99  \n",
       "2382   9824.899652  17260.21  \n",
       "2383  15717.759599  17874.21  \n",
       "2384  10507.652250  17792.16  \n",
       "2385  10018.272538  18370.15  \n",
       "\n",
       "[2386 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quandl.ApiConfig.api_key = '_66tvRgY5_szTgfB7aeB'\n",
    "df = quandl.get('BITSTAMP/USD')\n",
    "data = df\n",
    "# data = pd.read_csv('bitcoin_data.csv')\n",
    "data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(columns='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>13907.47</td>\n",
       "      <td>13629.31</td>\n",
       "      <td>13711.21</td>\n",
       "      <td>13700.59</td>\n",
       "      <td>13711.21</td>\n",
       "      <td>2465.795017</td>\n",
       "      <td>13766.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>13842.50</td>\n",
       "      <td>13220.00</td>\n",
       "      <td>13563.72</td>\n",
       "      <td>13570.69</td>\n",
       "      <td>13578.98</td>\n",
       "      <td>7062.704712</td>\n",
       "      <td>13545.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>14083.76</td>\n",
       "      <td>13287.70</td>\n",
       "      <td>14041.58</td>\n",
       "      <td>14030.89</td>\n",
       "      <td>14041.58</td>\n",
       "      <td>7226.516356</td>\n",
       "      <td>13633.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>14277.50</td>\n",
       "      <td>13520.87</td>\n",
       "      <td>14160.59</td>\n",
       "      <td>14162.68</td>\n",
       "      <td>14171.73</td>\n",
       "      <td>10925.676805</td>\n",
       "      <td>13908.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>15770.58</td>\n",
       "      <td>14100.00</td>\n",
       "      <td>15605.04</td>\n",
       "      <td>15603.49</td>\n",
       "      <td>15608.32</td>\n",
       "      <td>18422.631860</td>\n",
       "      <td>14937.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07</th>\n",
       "      <td>15968.98</td>\n",
       "      <td>15196.01</td>\n",
       "      <td>15598.09</td>\n",
       "      <td>15598.10</td>\n",
       "      <td>15603.23</td>\n",
       "      <td>13479.467068</td>\n",
       "      <td>15570.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-08</th>\n",
       "      <td>15778.60</td>\n",
       "      <td>14351.00</td>\n",
       "      <td>14838.97</td>\n",
       "      <td>14832.01</td>\n",
       "      <td>14842.70</td>\n",
       "      <td>10933.924192</td>\n",
       "      <td>15076.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>15664.90</td>\n",
       "      <td>14727.19</td>\n",
       "      <td>15489.15</td>\n",
       "      <td>15480.45</td>\n",
       "      <td>15490.09</td>\n",
       "      <td>5046.499164</td>\n",
       "      <td>15255.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>15854.48</td>\n",
       "      <td>14824.66</td>\n",
       "      <td>15332.04</td>\n",
       "      <td>15335.50</td>\n",
       "      <td>15348.95</td>\n",
       "      <td>14466.079537</td>\n",
       "      <td>15364.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>15482.76</td>\n",
       "      <td>15092.47</td>\n",
       "      <td>15313.65</td>\n",
       "      <td>15313.87</td>\n",
       "      <td>15317.81</td>\n",
       "      <td>8966.481714</td>\n",
       "      <td>15325.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>15991.01</td>\n",
       "      <td>15290.85</td>\n",
       "      <td>15702.00</td>\n",
       "      <td>15696.48</td>\n",
       "      <td>15703.40</td>\n",
       "      <td>10014.264272</td>\n",
       "      <td>15652.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>16369.99</td>\n",
       "      <td>15481.00</td>\n",
       "      <td>16300.00</td>\n",
       "      <td>16297.91</td>\n",
       "      <td>16300.00</td>\n",
       "      <td>16261.206579</td>\n",
       "      <td>15939.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-14</th>\n",
       "      <td>16494.52</td>\n",
       "      <td>15970.33</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16339.27</td>\n",
       "      <td>7842.488826</td>\n",
       "      <td>16279.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-15</th>\n",
       "      <td>16341.89</td>\n",
       "      <td>15715.10</td>\n",
       "      <td>16086.34</td>\n",
       "      <td>16087.77</td>\n",
       "      <td>16094.81</td>\n",
       "      <td>5046.326705</td>\n",
       "      <td>15982.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-16</th>\n",
       "      <td>16170.00</td>\n",
       "      <td>15786.46</td>\n",
       "      <td>15975.49</td>\n",
       "      <td>15969.41</td>\n",
       "      <td>15973.22</td>\n",
       "      <td>3226.276565</td>\n",
       "      <td>15979.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-17</th>\n",
       "      <td>16894.93</td>\n",
       "      <td>15875.50</td>\n",
       "      <td>16724.62</td>\n",
       "      <td>16719.84</td>\n",
       "      <td>16729.63</td>\n",
       "      <td>7511.143605</td>\n",
       "      <td>16409.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18</th>\n",
       "      <td>17868.00</td>\n",
       "      <td>16570.00</td>\n",
       "      <td>17681.77</td>\n",
       "      <td>17670.67</td>\n",
       "      <td>17680.50</td>\n",
       "      <td>9824.899652</td>\n",
       "      <td>17260.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19</th>\n",
       "      <td>18483.00</td>\n",
       "      <td>17041.47</td>\n",
       "      <td>17785.95</td>\n",
       "      <td>17783.71</td>\n",
       "      <td>17792.96</td>\n",
       "      <td>15717.759599</td>\n",
       "      <td>17874.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>18189.97</td>\n",
       "      <td>17346.62</td>\n",
       "      <td>17819.37</td>\n",
       "      <td>17817.05</td>\n",
       "      <td>17819.42</td>\n",
       "      <td>10507.652250</td>\n",
       "      <td>17792.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-21</th>\n",
       "      <td>18824.88</td>\n",
       "      <td>17755.81</td>\n",
       "      <td>18685.08</td>\n",
       "      <td>18674.71</td>\n",
       "      <td>18681.69</td>\n",
       "      <td>10018.272538</td>\n",
       "      <td>18370.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low      Last       Bid       Ask        Volume  \\\n",
       "Date                                                                         \n",
       "2020-11-01  13907.47  13629.31  13711.21  13700.59  13711.21   2465.795017   \n",
       "2020-11-03  13842.50  13220.00  13563.72  13570.69  13578.98   7062.704712   \n",
       "2020-11-04  14083.76  13287.70  14041.58  14030.89  14041.58   7226.516356   \n",
       "2020-11-05  14277.50  13520.87  14160.59  14162.68  14171.73  10925.676805   \n",
       "2020-11-06  15770.58  14100.00  15605.04  15603.49  15608.32  18422.631860   \n",
       "2020-11-07  15968.98  15196.01  15598.09  15598.10  15603.23  13479.467068   \n",
       "2020-11-08  15778.60  14351.00  14838.97  14832.01  14842.70  10933.924192   \n",
       "2020-11-09  15664.90  14727.19  15489.15  15480.45  15490.09   5046.499164   \n",
       "2020-11-10  15854.48  14824.66  15332.04  15335.50  15348.95  14466.079537   \n",
       "2020-11-11  15482.76  15092.47  15313.65  15313.87  15317.81   8966.481714   \n",
       "2020-11-12  15991.01  15290.85  15702.00  15696.48  15703.40  10014.264272   \n",
       "2020-11-13  16369.99  15481.00  16300.00  16297.91  16300.00  16261.206579   \n",
       "2020-11-14  16494.52  15970.33  16335.58  16335.58  16339.27   7842.488826   \n",
       "2020-11-15  16341.89  15715.10  16086.34  16087.77  16094.81   5046.326705   \n",
       "2020-11-16  16170.00  15786.46  15975.49  15969.41  15973.22   3226.276565   \n",
       "2020-11-17  16894.93  15875.50  16724.62  16719.84  16729.63   7511.143605   \n",
       "2020-11-18  17868.00  16570.00  17681.77  17670.67  17680.50   9824.899652   \n",
       "2020-11-19  18483.00  17041.47  17785.95  17783.71  17792.96  15717.759599   \n",
       "2020-11-20  18189.97  17346.62  17819.37  17817.05  17819.42  10507.652250   \n",
       "2020-11-21  18824.88  17755.81  18685.08  18674.71  18681.69  10018.272538   \n",
       "\n",
       "                VWAP  \n",
       "Date                  \n",
       "2020-11-01  13766.72  \n",
       "2020-11-03  13545.15  \n",
       "2020-11-04  13633.01  \n",
       "2020-11-05  13908.16  \n",
       "2020-11-06  14937.25  \n",
       "2020-11-07  15570.55  \n",
       "2020-11-08  15076.99  \n",
       "2020-11-09  15255.08  \n",
       "2020-11-10  15364.34  \n",
       "2020-11-11  15325.34  \n",
       "2020-11-12  15652.52  \n",
       "2020-11-13  15939.46  \n",
       "2020-11-14  16279.18  \n",
       "2020-11-15  15982.98  \n",
       "2020-11-16  15979.39  \n",
       "2020-11-17  16409.99  \n",
       "2020-11-18  17260.21  \n",
       "2020-11-19  17874.21  \n",
       "2020-11-20  17792.16  \n",
       "2020-11-21  18370.15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.tail(20)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "High = test.High.values\n",
    "Low = test.Low.values\n",
    "Volume = test.Volume.values\n",
    "Last = test.Last.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13907.47, 13629.31],\n",
       "       [13842.5 , 13220.  ],\n",
       "       [14083.76, 13287.7 ],\n",
       "       [14277.5 , 13520.87],\n",
       "       [15770.58, 14100.  ],\n",
       "       [15968.98, 15196.01],\n",
       "       [15778.6 , 14351.  ],\n",
       "       [15664.9 , 14727.19],\n",
       "       [15854.48, 14824.66],\n",
       "       [15482.76, 15092.47],\n",
       "       [15991.01, 15290.85],\n",
       "       [16369.99, 15481.  ],\n",
       "       [16494.52, 15970.33],\n",
       "       [16341.89, 15715.1 ],\n",
       "       [16170.  , 15786.46],\n",
       "       [16894.93, 15875.5 ],\n",
       "       [17868.  , 16570.  ],\n",
       "       [18483.  , 17041.47],\n",
       "       [18189.97, 17346.62],\n",
       "       [18824.88, 17755.81]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(High)):\n",
    "    row = []\n",
    "    yrow = []\n",
    "    row.append(High[i])\n",
    "    row.append(Low[i])\n",
    "#     row.append(Volume[i])\n",
    "    yrow.append(Last[i])\n",
    "    X.append(row)\n",
    "    y.append(yrow)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower = np.array(X_train)\n",
    "horsepower2 = np.array(X_train)\n",
    "horsepower_normalizer = preprocessing.Normalization(input_shape=[1,])\n",
    "horsepower_normalizer.adapt(horsepower)\n",
    "horsepower_normalizer2 = preprocessing.Normalization(input_shape=[1,])\n",
    "horsepower_normalizer2.adapt(horsepower2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input_layer = Input(shape=(X.shape[1],))\n",
    "# dense_layer_1 = Dense(100, input_shape=(X.shape[1],), activation='relu')\n",
    "# dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "# dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "# output = Dense(1)\n",
    "\n",
    "# model = Model([\n",
    "#     Dense(100, input_dim=X.shape[1], activation='relu'),\n",
    "#     Dense(50, activation='relu'),\n",
    "#     Dense(25, activation='relu'),\n",
    "#     Dense(units=1, activation='softmax')\n",
    "# ])\n",
    "# model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "horsepower_model = tf.keras.Sequential([\n",
    "#     horsepower_normalizer,\n",
    "    layers.Dense(50, activation='relu', input_dim=2),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(25, activation='relu'),\n",
    "    layers.Dense(units=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#horsepower_model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 4 samples\n",
      "Epoch 1/700\n",
      "12/12 - 1s - loss: 15630.5947 - accuracy: 0.0000e+00 - val_loss: 14958.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/700\n",
      "12/12 - 0s - loss: 15581.3174 - accuracy: 0.0000e+00 - val_loss: 14910.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/700\n",
      "12/12 - 0s - loss: 15532.0986 - accuracy: 0.0000e+00 - val_loss: 14863.7793 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/700\n",
      "12/12 - 0s - loss: 15482.9375 - accuracy: 0.0000e+00 - val_loss: 14814.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/700\n",
      "12/12 - 0s - loss: 15432.7998 - accuracy: 0.0000e+00 - val_loss: 14760.2051 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/700\n",
      "12/12 - 0s - loss: 15377.1377 - accuracy: 0.0000e+00 - val_loss: 14704.7363 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/700\n",
      "12/12 - 0s - loss: 15319.4092 - accuracy: 0.0000e+00 - val_loss: 14648.6641 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/700\n",
      "12/12 - 0s - loss: 15261.0283 - accuracy: 0.0000e+00 - val_loss: 14592.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/700\n",
      "12/12 - 0s - loss: 15202.1201 - accuracy: 0.0000e+00 - val_loss: 14535.3613 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/700\n",
      "12/12 - 0s - loss: 15142.8467 - accuracy: 0.0000e+00 - val_loss: 14477.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/700\n",
      "12/12 - 0s - loss: 15082.5977 - accuracy: 0.0000e+00 - val_loss: 14418.7578 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/700\n",
      "12/12 - 0s - loss: 15021.2842 - accuracy: 0.0000e+00 - val_loss: 14359.7930 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/700\n",
      "12/12 - 0s - loss: 14959.5947 - accuracy: 0.0000e+00 - val_loss: 14300.5059 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/700\n",
      "12/12 - 0s - loss: 14897.6396 - accuracy: 0.0000e+00 - val_loss: 14240.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/700\n",
      "12/12 - 0s - loss: 14835.7305 - accuracy: 0.0000e+00 - val_loss: 14182.6055 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/700\n",
      "12/12 - 0s - loss: 14775.0469 - accuracy: 0.0000e+00 - val_loss: 14124.6729 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/700\n",
      "12/12 - 0s - loss: 14714.5127 - accuracy: 0.0000e+00 - val_loss: 14066.6104 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/700\n",
      "12/12 - 0s - loss: 14653.8408 - accuracy: 0.0000e+00 - val_loss: 14008.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/700\n",
      "12/12 - 0s - loss: 14593.0156 - accuracy: 0.0000e+00 - val_loss: 13950.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/700\n",
      "12/12 - 0s - loss: 14531.9893 - accuracy: 0.0000e+00 - val_loss: 13891.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/700\n",
      "12/12 - 0s - loss: 14470.7412 - accuracy: 0.0000e+00 - val_loss: 13832.8398 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/700\n",
      "12/12 - 0s - loss: 14409.2686 - accuracy: 0.0000e+00 - val_loss: 13773.8535 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/700\n",
      "12/12 - 0s - loss: 14347.6182 - accuracy: 0.0000e+00 - val_loss: 13714.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/700\n",
      "12/12 - 0s - loss: 14285.8359 - accuracy: 0.0000e+00 - val_loss: 13656.5684 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/700\n",
      "12/12 - 0s - loss: 14227.2031 - accuracy: 0.0000e+00 - val_loss: 13607.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/700\n",
      "12/12 - 0s - loss: 14176.2148 - accuracy: 0.0000e+00 - val_loss: 13558.4004 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/700\n",
      "12/12 - 0s - loss: 14125.1562 - accuracy: 0.0000e+00 - val_loss: 13509.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/700\n",
      "12/12 - 0s - loss: 14073.4297 - accuracy: 0.0000e+00 - val_loss: 13460.3008 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/700\n",
      "12/12 - 0s - loss: 14020.5400 - accuracy: 0.0000e+00 - val_loss: 13409.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/700\n",
      "12/12 - 0s - loss: 13965.9219 - accuracy: 0.0000e+00 - val_loss: 13355.9844 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/700\n",
      "12/12 - 0s - loss: 13908.1953 - accuracy: 0.0000e+00 - val_loss: 13298.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/700\n",
      "12/12 - 0s - loss: 13847.1514 - accuracy: 0.0000e+00 - val_loss: 13237.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/700\n",
      "12/12 - 0s - loss: 13784.0986 - accuracy: 0.0000e+00 - val_loss: 13175.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/700\n",
      "12/12 - 0s - loss: 13719.6709 - accuracy: 0.0000e+00 - val_loss: 13113.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/700\n",
      "12/12 - 0s - loss: 13654.0654 - accuracy: 0.0000e+00 - val_loss: 13049.6064 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/700\n",
      "12/12 - 0s - loss: 13587.5781 - accuracy: 0.0000e+00 - val_loss: 12985.4570 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/700\n",
      "12/12 - 0s - loss: 13520.1982 - accuracy: 0.0000e+00 - val_loss: 12920.4150 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/700\n",
      "12/12 - 0s - loss: 13452.1484 - accuracy: 0.0000e+00 - val_loss: 12854.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/700\n",
      "12/12 - 0s - loss: 13383.5146 - accuracy: 0.0000e+00 - val_loss: 12788.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/700\n",
      "12/12 - 0s - loss: 13314.1885 - accuracy: 0.0000e+00 - val_loss: 12722.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/700\n",
      "12/12 - 0s - loss: 13244.1807 - accuracy: 0.0000e+00 - val_loss: 12654.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/700\n",
      "12/12 - 0s - loss: 13173.4404 - accuracy: 0.0000e+00 - val_loss: 12585.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/700\n",
      "12/12 - 0s - loss: 13101.8936 - accuracy: 0.0000e+00 - val_loss: 12516.3691 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/700\n",
      "12/12 - 0s - loss: 13029.5459 - accuracy: 0.0000e+00 - val_loss: 12446.3115 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/700\n",
      "12/12 - 0s - loss: 12956.4834 - accuracy: 0.0000e+00 - val_loss: 12375.5801 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/700\n",
      "12/12 - 0s - loss: 12882.6875 - accuracy: 0.0000e+00 - val_loss: 12304.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/700\n",
      "12/12 - 0s - loss: 12808.2061 - accuracy: 0.0000e+00 - val_loss: 12223.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/700\n",
      "12/12 - 0s - loss: 12724.1982 - accuracy: 0.0000e+00 - val_loss: 12140.2070 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/700\n",
      "12/12 - 0s - loss: 12637.4209 - accuracy: 0.0000e+00 - val_loss: 12054.6709 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/700\n",
      "12/12 - 0s - loss: 12548.2139 - accuracy: 0.0000e+00 - val_loss: 11967.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/700\n",
      "12/12 - 0s - loss: 12456.9287 - accuracy: 0.0000e+00 - val_loss: 11877.8545 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/700\n",
      "12/12 - 0s - loss: 12363.8154 - accuracy: 0.0000e+00 - val_loss: 11786.9980 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/700\n",
      "12/12 - 0s - loss: 12269.0703 - accuracy: 0.0000e+00 - val_loss: 11694.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/700\n",
      "12/12 - 0s - loss: 12172.8398 - accuracy: 0.0000e+00 - val_loss: 11601.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/700\n",
      "12/12 - 0s - loss: 12075.2529 - accuracy: 0.0000e+00 - val_loss: 11506.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/700\n",
      "12/12 - 0s - loss: 11976.4092 - accuracy: 0.0000e+00 - val_loss: 11410.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/700\n",
      "12/12 - 0s - loss: 11876.4561 - accuracy: 0.0000e+00 - val_loss: 11313.6553 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/700\n",
      "12/12 - 0s - loss: 11775.4014 - accuracy: 0.0000e+00 - val_loss: 11215.9297 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/700\n",
      "12/12 - 0s - loss: 11673.3252 - accuracy: 0.0000e+00 - val_loss: 11118.1582 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/700\n",
      "12/12 - 0s - loss: 11570.7686 - accuracy: 0.0000e+00 - val_loss: 11021.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/700\n",
      "12/12 - 0s - loss: 11469.3672 - accuracy: 0.0000e+00 - val_loss: 10929.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/700\n",
      "12/12 - 0s - loss: 11371.8623 - accuracy: 0.0000e+00 - val_loss: 10837.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/700\n",
      "12/12 - 0s - loss: 11274.9766 - accuracy: 0.0000e+00 - val_loss: 10744.5010 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/700\n",
      "12/12 - 0s - loss: 11177.8125 - accuracy: 0.0000e+00 - val_loss: 10650.8584 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/700\n",
      "12/12 - 0s - loss: 11080.1729 - accuracy: 0.0000e+00 - val_loss: 10556.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/700\n",
      "12/12 - 0s - loss: 10981.6328 - accuracy: 0.0000e+00 - val_loss: 10460.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/700\n",
      "12/12 - 0s - loss: 10882.2148 - accuracy: 0.0000e+00 - val_loss: 10364.7715 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/700\n",
      "12/12 - 0s - loss: 10781.8389 - accuracy: 0.0000e+00 - val_loss: 10268.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/700\n",
      "12/12 - 0s - loss: 10680.8096 - accuracy: 0.0000e+00 - val_loss: 10171.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/700\n",
      "12/12 - 0s - loss: 10579.4033 - accuracy: 0.0000e+00 - val_loss: 10073.3164 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/700\n",
      "12/12 - 0s - loss: 10477.2236 - accuracy: 0.0000e+00 - val_loss: 9974.3340 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/700\n",
      "12/12 - 0s - loss: 10373.9854 - accuracy: 0.0000e+00 - val_loss: 9874.1592 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/700\n",
      "12/12 - 0s - loss: 10269.5693 - accuracy: 0.0000e+00 - val_loss: 9772.8301 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/700\n",
      "12/12 - 0s - loss: 10163.9717 - accuracy: 0.0000e+00 - val_loss: 9670.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/700\n",
      "12/12 - 0s - loss: 10057.3838 - accuracy: 0.0000e+00 - val_loss: 9566.5215 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/700\n",
      "12/12 - 0s - loss: 9949.0469 - accuracy: 0.0000e+00 - val_loss: 9456.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/700\n",
      "12/12 - 0s - loss: 9834.3779 - accuracy: 0.0000e+00 - val_loss: 9344.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/700\n",
      "12/12 - 0s - loss: 9717.4521 - accuracy: 0.0000e+00 - val_loss: 9229.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/700\n",
      "12/12 - 0s - loss: 9598.3643 - accuracy: 0.0000e+00 - val_loss: 9113.6543 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/700\n",
      "12/12 - 0s - loss: 9477.0791 - accuracy: 0.0000e+00 - val_loss: 8994.5410 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/700\n",
      "12/12 - 0s - loss: 9351.5859 - accuracy: 0.0000e+00 - val_loss: 8869.7949 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/700\n",
      "12/12 - 0s - loss: 9221.1221 - accuracy: 0.0000e+00 - val_loss: 8742.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/700\n",
      "12/12 - 0s - loss: 9087.9365 - accuracy: 0.0000e+00 - val_loss: 8612.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/700\n",
      "12/12 - 0s - loss: 8952.4580 - accuracy: 0.0000e+00 - val_loss: 8480.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/700\n",
      "12/12 - 0s - loss: 8814.8223 - accuracy: 0.0000e+00 - val_loss: 8345.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/700\n",
      "12/12 - 0s - loss: 8675.1553 - accuracy: 0.0000e+00 - val_loss: 8209.9795 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/700\n",
      "12/12 - 0s - loss: 8533.5889 - accuracy: 0.0000e+00 - val_loss: 8072.3560 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/700\n",
      "12/12 - 0s - loss: 8390.2412 - accuracy: 0.0000e+00 - val_loss: 7934.3037 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/700\n",
      "12/12 - 0s - loss: 8245.8135 - accuracy: 0.0000e+00 - val_loss: 7796.9087 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/700\n",
      "12/12 - 0s - loss: 8101.5806 - accuracy: 0.0000e+00 - val_loss: 7658.3525 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/700\n",
      "12/12 - 0s - loss: 7956.7070 - accuracy: 0.0000e+00 - val_loss: 7518.1641 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/700\n",
      "12/12 - 0s - loss: 7810.5522 - accuracy: 0.0000e+00 - val_loss: 7376.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/700\n",
      "12/12 - 0s - loss: 7662.7754 - accuracy: 0.0000e+00 - val_loss: 7233.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/700\n",
      "12/12 - 0s - loss: 7513.3633 - accuracy: 0.0000e+00 - val_loss: 7088.2935 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/700\n",
      "12/12 - 0s - loss: 7362.7495 - accuracy: 0.0000e+00 - val_loss: 6950.7607 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/700\n",
      "12/12 - 0s - loss: 7220.2539 - accuracy: 0.0000e+00 - val_loss: 6812.7520 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/700\n",
      "12/12 - 0s - loss: 7076.3613 - accuracy: 0.0000e+00 - val_loss: 6672.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/700\n",
      "12/12 - 0s - loss: 6930.0488 - accuracy: 0.0000e+00 - val_loss: 6530.2490 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/700\n",
      "12/12 - 0s - loss: 6781.7925 - accuracy: 0.0000e+00 - val_loss: 6386.1665 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/700\n",
      "12/12 - 0s - loss: 6631.5859 - accuracy: 0.0000e+00 - val_loss: 6239.8833 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/700\n",
      "12/12 - 0s - loss: 6479.0366 - accuracy: 0.0000e+00 - val_loss: 6091.6436 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/700\n",
      "12/12 - 0s - loss: 6324.4673 - accuracy: 0.0000e+00 - val_loss: 5941.9902 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/700\n",
      "12/12 - 0s - loss: 6168.3149 - accuracy: 0.0000e+00 - val_loss: 5790.4639 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/700\n",
      "12/12 - 0s - loss: 6010.2251 - accuracy: 0.0000e+00 - val_loss: 5640.7666 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/700\n",
      "12/12 - 0s - loss: 5853.6523 - accuracy: 0.0000e+00 - val_loss: 5489.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/700\n",
      "12/12 - 0s - loss: 5696.2231 - accuracy: 0.0000e+00 - val_loss: 5337.3325 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/700\n",
      "12/12 - 0s - loss: 5537.0293 - accuracy: 0.0000e+00 - val_loss: 5183.3291 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/700\n",
      "12/12 - 0s - loss: 5376.2183 - accuracy: 0.0000e+00 - val_loss: 5027.4541 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/700\n",
      "12/12 - 0s - loss: 5213.4414 - accuracy: 0.0000e+00 - val_loss: 4870.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/700\n",
      "12/12 - 0s - loss: 5048.9478 - accuracy: 0.0000e+00 - val_loss: 4711.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/700\n",
      "12/12 - 0s - loss: 4882.8301 - accuracy: 0.0000e+00 - val_loss: 4550.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/700\n",
      "12/12 - 0s - loss: 4714.8242 - accuracy: 0.0000e+00 - val_loss: 4388.1035 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/700\n",
      "12/12 - 0s - loss: 4544.9829 - accuracy: 0.0000e+00 - val_loss: 4224.0176 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/700\n",
      "12/12 - 0s - loss: 4373.3843 - accuracy: 0.0000e+00 - val_loss: 4061.8962 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/700\n",
      "12/12 - 0s - loss: 4202.9058 - accuracy: 0.0000e+00 - val_loss: 3898.7021 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/700\n",
      "12/12 - 0s - loss: 4032.4128 - accuracy: 0.0000e+00 - val_loss: 3732.4573 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/700\n",
      "12/12 - 0s - loss: 3858.7683 - accuracy: 0.0000e+00 - val_loss: 3563.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/700\n",
      "12/12 - 0s - loss: 3681.8596 - accuracy: 0.0000e+00 - val_loss: 3391.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/700\n",
      "12/12 - 0s - loss: 3501.9646 - accuracy: 0.0000e+00 - val_loss: 3216.1770 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/700\n",
      "12/12 - 0s - loss: 3319.0535 - accuracy: 0.0000e+00 - val_loss: 3038.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/700\n",
      "12/12 - 0s - loss: 3133.7761 - accuracy: 0.0000e+00 - val_loss: 2860.2390 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/700\n",
      "12/12 - 0s - loss: 2948.5049 - accuracy: 0.0000e+00 - val_loss: 2682.0195 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/700\n",
      "12/12 - 0s - loss: 2762.4592 - accuracy: 0.0000e+00 - val_loss: 2501.5125 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/700\n",
      "12/12 - 0s - loss: 2573.9148 - accuracy: 0.0000e+00 - val_loss: 2318.5017 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/700\n",
      "12/12 - 0s - loss: 2382.7754 - accuracy: 0.0000e+00 - val_loss: 2132.9800 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/700\n",
      "12/12 - 0s - loss: 2189.1194 - accuracy: 0.0000e+00 - val_loss: 1944.9551 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/700\n",
      "12/12 - 0s - loss: 1992.8737 - accuracy: 0.0000e+00 - val_loss: 1754.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/700\n",
      "12/12 - 0s - loss: 1794.0299 - accuracy: 0.0000e+00 - val_loss: 1561.3621 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/700\n",
      "12/12 - 0s - loss: 1592.5814 - accuracy: 0.0000e+00 - val_loss: 1366.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/700\n",
      "12/12 - 0s - loss: 1388.6021 - accuracy: 0.0000e+00 - val_loss: 1169.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/700\n",
      "12/12 - 0s - loss: 1183.0265 - accuracy: 0.0000e+00 - val_loss: 971.6353 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/700\n",
      "12/12 - 0s - loss: 975.7728 - accuracy: 0.0000e+00 - val_loss: 770.4678 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/700\n",
      "12/12 - 0s - loss: 765.6892 - accuracy: 0.0000e+00 - val_loss: 565.8499 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/700\n",
      "12/12 - 0s - loss: 552.4289 - accuracy: 0.0000e+00 - val_loss: 358.0952 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/700\n",
      "12/12 - 0s - loss: 362.4927 - accuracy: 0.0000e+00 - val_loss: 159.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/700\n",
      "12/12 - 0s - loss: 200.4593 - accuracy: 0.0000e+00 - val_loss: 98.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/700\n",
      "12/12 - 0s - loss: 205.7217 - accuracy: 0.0000e+00 - val_loss: 222.9517 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/700\n",
      "12/12 - 0s - loss: 289.5648 - accuracy: 0.0000e+00 - val_loss: 360.8572 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/700\n",
      "12/12 - 0s - loss: 412.5216 - accuracy: 0.0000e+00 - val_loss: 459.9009 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/700\n",
      "12/12 - 0s - loss: 515.7764 - accuracy: 0.0000e+00 - val_loss: 523.9065 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/700\n",
      "12/12 - 0s - loss: 582.5375 - accuracy: 0.0000e+00 - val_loss: 556.6135 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/700\n",
      "12/12 - 0s - loss: 616.5993 - accuracy: 0.0000e+00 - val_loss: 561.3237 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/700\n",
      "12/12 - 0s - loss: 621.4826 - accuracy: 0.0000e+00 - val_loss: 541.2493 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/700\n",
      "12/12 - 0s - loss: 600.5637 - accuracy: 0.0000e+00 - val_loss: 499.3718 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/700\n",
      "12/12 - 0s - loss: 556.8997 - accuracy: 0.0000e+00 - val_loss: 438.3625 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/700\n",
      "12/12 - 0s - loss: 493.2773 - accuracy: 0.0000e+00 - val_loss: 360.6492 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/700\n",
      "12/12 - 0s - loss: 412.2299 - accuracy: 0.0000e+00 - val_loss: 268.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/700\n",
      "12/12 - 0s - loss: 329.0136 - accuracy: 0.0000e+00 - val_loss: 166.9724 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/700\n",
      "12/12 - 0s - loss: 243.9815 - accuracy: 0.0000e+00 - val_loss: 99.2380 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/700\n",
      "12/12 - 0s - loss: 208.1087 - accuracy: 0.0000e+00 - val_loss: 99.8611 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/700\n",
      "12/12 - 0s - loss: 189.2202 - accuracy: 0.0000e+00 - val_loss: 150.0007 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/700\n",
      "12/12 - 0s - loss: 190.7557 - accuracy: 0.0000e+00 - val_loss: 205.9590 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/700\n",
      "12/12 - 0s - loss: 235.2970 - accuracy: 0.0000e+00 - val_loss: 257.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/700\n",
      "12/12 - 0s - loss: 274.8579 - accuracy: 0.0000e+00 - val_loss: 285.2244 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/700\n",
      "12/12 - 0s - loss: 299.1908 - accuracy: 0.0000e+00 - val_loss: 291.9773 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/700\n",
      "12/12 - 0s - loss: 305.0905 - accuracy: 0.0000e+00 - val_loss: 279.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/700\n",
      "12/12 - 0s - loss: 294.5206 - accuracy: 0.0000e+00 - val_loss: 250.9966 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/700\n",
      "12/12 - 0s - loss: 269.1852 - accuracy: 0.0000e+00 - val_loss: 206.8992 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/700\n",
      "12/12 - 0s - loss: 235.8578 - accuracy: 0.0000e+00 - val_loss: 161.0923 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/700\n",
      "12/12 - 0s - loss: 200.9685 - accuracy: 0.0000e+00 - val_loss: 128.8662 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/700\n",
      "12/12 - 0s - loss: 178.7158 - accuracy: 0.0000e+00 - val_loss: 101.8708 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/700\n",
      "12/12 - 0s - loss: 188.0970 - accuracy: 0.0000e+00 - val_loss: 99.6182 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/700\n",
      "12/12 - 0s - loss: 195.8180 - accuracy: 0.0000e+00 - val_loss: 99.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/700\n",
      "12/12 - 0s - loss: 202.0303 - accuracy: 0.0000e+00 - val_loss: 99.2363 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/700\n",
      "12/12 - 0s - loss: 206.8720 - accuracy: 0.0000e+00 - val_loss: 99.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/700\n",
      "12/12 - 0s - loss: 210.4769 - accuracy: 0.0000e+00 - val_loss: 99.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/700\n",
      "12/12 - 0s - loss: 213.6702 - accuracy: 0.0000e+00 - val_loss: 98.9709 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/700\n",
      "12/12 - 0s - loss: 215.1231 - accuracy: 0.0000e+00 - val_loss: 98.9827 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/700\n",
      "12/12 - 0s - loss: 213.6405 - accuracy: 0.0000e+00 - val_loss: 99.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/700\n",
      "12/12 - 0s - loss: 210.7443 - accuracy: 0.0000e+00 - val_loss: 99.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/700\n",
      "12/12 - 0s - loss: 207.9812 - accuracy: 0.0000e+00 - val_loss: 99.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/700\n",
      "12/12 - 0s - loss: 204.7012 - accuracy: 0.0000e+00 - val_loss: 99.3103 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/700\n",
      "12/12 - 0s - loss: 200.9552 - accuracy: 0.0000e+00 - val_loss: 99.4292 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/700\n",
      "12/12 - 0s - loss: 196.7887 - accuracy: 0.0000e+00 - val_loss: 99.5596 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/700\n",
      "12/12 - 0s - loss: 192.2432 - accuracy: 0.0000e+00 - val_loss: 103.5417 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/700\n",
      "12/12 - 0s - loss: 187.3551 - accuracy: 0.0000e+00 - val_loss: 118.4390 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/700\n",
      "12/12 - 0s - loss: 182.1599 - accuracy: 0.0000e+00 - val_loss: 134.1321 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/700\n",
      "12/12 - 0s - loss: 179.2833 - accuracy: 0.0000e+00 - val_loss: 146.4043 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/700\n",
      "12/12 - 0s - loss: 187.3704 - accuracy: 0.0000e+00 - val_loss: 151.3979 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/700\n",
      "12/12 - 0s - loss: 192.0198 - accuracy: 0.0000e+00 - val_loss: 149.8379 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/700\n",
      "12/12 - 0s - loss: 190.5754 - accuracy: 0.0000e+00 - val_loss: 142.3650 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/700\n",
      "12/12 - 0s - loss: 183.6657 - accuracy: 0.0000e+00 - val_loss: 131.6550 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/700\n",
      "12/12 - 0s - loss: 178.5678 - accuracy: 0.0000e+00 - val_loss: 120.0864 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/700\n",
      "12/12 - 0s - loss: 181.5323 - accuracy: 0.0000e+00 - val_loss: 111.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/700\n",
      "12/12 - 0s - loss: 184.3621 - accuracy: 0.0000e+00 - val_loss: 106.8855 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/700\n",
      "12/12 - 0s - loss: 186.1128 - accuracy: 0.0000e+00 - val_loss: 104.6426 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/700\n",
      "12/12 - 0s - loss: 186.8862 - accuracy: 0.0000e+00 - val_loss: 104.9417 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/700\n",
      "12/12 - 0s - loss: 186.7750 - accuracy: 0.0000e+00 - val_loss: 107.5391 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/700\n",
      "12/12 - 0s - loss: 185.8628 - accuracy: 0.0000e+00 - val_loss: 112.2153 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/700\n",
      "12/12 - 0s - loss: 184.2275 - accuracy: 0.0000e+00 - val_loss: 118.7712 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/700\n",
      "12/12 - 0s - loss: 181.9382 - accuracy: 0.0000e+00 - val_loss: 127.0234 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/700\n",
      "12/12 - 0s - loss: 179.0598 - accuracy: 0.0000e+00 - val_loss: 136.8071 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/700\n",
      "12/12 - 0s - loss: 180.3068 - accuracy: 0.0000e+00 - val_loss: 141.5410 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/700\n",
      "12/12 - 0s - loss: 183.1749 - accuracy: 0.0000e+00 - val_loss: 141.7219 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/700\n",
      "12/12 - 0s - loss: 183.2861 - accuracy: 0.0000e+00 - val_loss: 137.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/700\n",
      "12/12 - 0s - loss: 180.9062 - accuracy: 0.0000e+00 - val_loss: 130.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/700\n",
      "12/12 - 0s - loss: 178.3584 - accuracy: 0.0000e+00 - val_loss: 123.4817 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/700\n",
      "12/12 - 0s - loss: 180.2441 - accuracy: 0.0000e+00 - val_loss: 119.8516 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/700\n",
      "12/12 - 0s - loss: 181.4999 - accuracy: 0.0000e+00 - val_loss: 118.9587 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/700\n",
      "12/12 - 0s - loss: 181.8027 - accuracy: 0.0000e+00 - val_loss: 120.5447 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/700\n",
      "12/12 - 0s - loss: 181.2437 - accuracy: 0.0000e+00 - val_loss: 124.3704 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/700\n",
      "12/12 - 0s - loss: 179.9041 - accuracy: 0.0000e+00 - val_loss: 130.2192 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/700\n",
      "12/12 - 0s - loss: 178.3409 - accuracy: 0.0000e+00 - val_loss: 135.7551 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/700\n",
      "12/12 - 0s - loss: 179.7371 - accuracy: 0.0000e+00 - val_loss: 138.7581 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/700\n",
      "12/12 - 0s - loss: 181.4993 - accuracy: 0.0000e+00 - val_loss: 137.2664 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/700\n",
      "12/12 - 0s - loss: 180.5964 - accuracy: 0.0000e+00 - val_loss: 131.7161 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/700\n",
      "12/12 - 0s - loss: 178.5728 - accuracy: 0.0000e+00 - val_loss: 124.6970 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/700\n",
      "12/12 - 0s - loss: 179.7453 - accuracy: 0.0000e+00 - val_loss: 120.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/700\n",
      "12/12 - 0s - loss: 181.0950 - accuracy: 0.0000e+00 - val_loss: 119.7166 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/700\n",
      "12/12 - 0s - loss: 181.4635 - accuracy: 0.0000e+00 - val_loss: 121.1851 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/700\n",
      "12/12 - 0s - loss: 180.9432 - accuracy: 0.0000e+00 - val_loss: 124.9612 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/700\n",
      "12/12 - 0s - loss: 179.6197 - accuracy: 0.0000e+00 - val_loss: 130.8196 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/700\n",
      "12/12 - 0s - loss: 178.3161 - accuracy: 0.0000e+00 - val_loss: 134.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/700\n",
      "12/12 - 0s - loss: 179.2515 - accuracy: 0.0000e+00 - val_loss: 134.9622 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/700\n",
      "12/12 - 0s - loss: 179.5096 - accuracy: 0.0000e+00 - val_loss: 133.7251 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/700\n",
      "12/12 - 0s - loss: 179.1536 - accuracy: 0.0000e+00 - val_loss: 130.5605 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/700\n",
      "12/12 - 0s - loss: 178.2939 - accuracy: 0.0000e+00 - val_loss: 127.9744 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/700\n",
      "12/12 - 0s - loss: 178.5207 - accuracy: 0.0000e+00 - val_loss: 128.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/700\n",
      "12/12 - 0s - loss: 178.4588 - accuracy: 0.0000e+00 - val_loss: 130.7661 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/700\n",
      "12/12 - 0s - loss: 178.3035 - accuracy: 0.0000e+00 - val_loss: 131.0747 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/700\n",
      "12/12 - 0s - loss: 178.3933 - accuracy: 0.0000e+00 - val_loss: 129.2805 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/700\n",
      "12/12 - 0s - loss: 178.3303 - accuracy: 0.0000e+00 - val_loss: 127.9338 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/700\n",
      "12/12 - 0s - loss: 178.4952 - accuracy: 0.0000e+00 - val_loss: 129.2371 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/700\n",
      "12/12 - 0s - loss: 178.3274 - accuracy: 0.0000e+00 - val_loss: 130.6880 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/700\n",
      "12/12 - 0s - loss: 178.2833 - accuracy: 0.0000e+00 - val_loss: 129.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/700\n",
      "12/12 - 0s - loss: 178.2975 - accuracy: 0.0000e+00 - val_loss: 129.4719 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/700\n",
      "12/12 - 0s - loss: 178.3122 - accuracy: 0.0000e+00 - val_loss: 129.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/700\n",
      "12/12 - 0s - loss: 178.3140 - accuracy: 0.0000e+00 - val_loss: 129.5322 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/700\n",
      "12/12 - 0s - loss: 178.3062 - accuracy: 0.0000e+00 - val_loss: 129.9678 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/700\n",
      "12/12 - 0s - loss: 178.2865 - accuracy: 0.0000e+00 - val_loss: 130.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/700\n",
      "12/12 - 0s - loss: 178.2693 - accuracy: 0.0000e+00 - val_loss: 129.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/700\n",
      "12/12 - 0s - loss: 178.3141 - accuracy: 0.0000e+00 - val_loss: 128.0278 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/700\n",
      "12/12 - 0s - loss: 178.3962 - accuracy: 0.0000e+00 - val_loss: 129.6235 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/700\n",
      "12/12 - 0s - loss: 178.2913 - accuracy: 0.0000e+00 - val_loss: 131.3440 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/700\n",
      "12/12 - 0s - loss: 178.4722 - accuracy: 0.0000e+00 - val_loss: 130.7527 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/700\n",
      "12/12 - 0s - loss: 178.3018 - accuracy: 0.0000e+00 - val_loss: 128.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/700\n",
      "12/12 - 0s - loss: 178.3570 - accuracy: 0.0000e+00 - val_loss: 128.2529 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/700\n",
      "12/12 - 0s - loss: 178.3337 - accuracy: 0.0000e+00 - val_loss: 128.7017 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/700\n",
      "12/12 - 0s - loss: 178.3146 - accuracy: 0.0000e+00 - val_loss: 129.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/700\n",
      "12/12 - 0s - loss: 178.2865 - accuracy: 0.0000e+00 - val_loss: 130.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/700\n",
      "12/12 - 0s - loss: 178.2502 - accuracy: 0.0000e+00 - val_loss: 131.3989 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/700\n",
      "12/12 - 0s - loss: 178.4886 - accuracy: 0.0000e+00 - val_loss: 130.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/700\n",
      "12/12 - 0s - loss: 178.2491 - accuracy: 0.0000e+00 - val_loss: 129.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/700\n",
      "12/12 - 0s - loss: 178.2762 - accuracy: 0.0000e+00 - val_loss: 129.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/700\n",
      "12/12 - 0s - loss: 178.2903 - accuracy: 0.0000e+00 - val_loss: 128.9319 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/700\n",
      "12/12 - 0s - loss: 178.2911 - accuracy: 0.0000e+00 - val_loss: 129.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/700\n",
      "12/12 - 0s - loss: 178.2817 - accuracy: 0.0000e+00 - val_loss: 129.6194 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/700\n",
      "12/12 - 0s - loss: 178.2616 - accuracy: 0.0000e+00 - val_loss: 130.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/700\n",
      "12/12 - 0s - loss: 178.2323 - accuracy: 0.0000e+00 - val_loss: 131.2805 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/700\n",
      "12/12 - 0s - loss: 178.4537 - accuracy: 0.0000e+00 - val_loss: 129.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/700\n",
      "12/12 - 0s - loss: 178.2446 - accuracy: 0.0000e+00 - val_loss: 128.9712 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/700\n",
      "12/12 - 0s - loss: 178.2779 - accuracy: 0.0000e+00 - val_loss: 128.4131 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/700\n",
      "12/12 - 0s - loss: 178.2969 - accuracy: 0.0000e+00 - val_loss: 128.2039 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/700\n",
      "12/12 - 0s - loss: 178.3031 - accuracy: 0.0000e+00 - val_loss: 128.3081 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/700\n",
      "12/12 - 0s - loss: 178.2968 - accuracy: 0.0000e+00 - val_loss: 128.6980 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/700\n",
      "12/12 - 0s - loss: 178.2802 - accuracy: 0.0000e+00 - val_loss: 129.3435 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/700\n",
      "12/12 - 0s - loss: 178.2542 - accuracy: 0.0000e+00 - val_loss: 130.2207 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/700\n",
      "12/12 - 0s - loss: 178.2187 - accuracy: 0.0000e+00 - val_loss: 131.3088 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/700\n",
      "12/12 - 0s - loss: 178.4590 - accuracy: 0.0000e+00 - val_loss: 130.0295 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/700\n",
      "12/12 - 0s - loss: 178.2210 - accuracy: 0.0000e+00 - val_loss: 129.1733 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/700\n",
      "12/12 - 0s - loss: 178.2519 - accuracy: 0.0000e+00 - val_loss: 128.6987 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/700\n",
      "12/12 - 0s - loss: 178.2682 - accuracy: 0.0000e+00 - val_loss: 128.5703 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/700\n",
      "12/12 - 0s - loss: 178.2703 - accuracy: 0.0000e+00 - val_loss: 128.7539 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/700\n",
      "12/12 - 0s - loss: 178.2620 - accuracy: 0.0000e+00 - val_loss: 129.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/700\n",
      "12/12 - 0s - loss: 178.2424 - accuracy: 0.0000e+00 - val_loss: 129.9409 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/700\n",
      "12/12 - 0s - loss: 178.2131 - accuracy: 0.0000e+00 - val_loss: 130.8918 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/700\n",
      "12/12 - 0s - loss: 178.3371 - accuracy: 0.0000e+00 - val_loss: 129.4495 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/700\n",
      "12/12 - 0s - loss: 178.2275 - accuracy: 0.0000e+00 - val_loss: 128.4517 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/700\n",
      "12/12 - 0s - loss: 178.2634 - accuracy: 0.0000e+00 - val_loss: 127.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/700\n",
      "12/12 - 0s - loss: 178.2839 - accuracy: 0.0000e+00 - val_loss: 127.6189 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/700\n",
      "12/12 - 0s - loss: 178.3363 - accuracy: 0.0000e+00 - val_loss: 130.2126 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/700\n",
      "12/12 - 0s - loss: 178.1909 - accuracy: 0.0000e+00 - val_loss: 132.8567 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/700\n",
      "12/12 - 0s - loss: 178.9004 - accuracy: 0.0000e+00 - val_loss: 132.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/700\n",
      "12/12 - 0s - loss: 178.9167 - accuracy: 0.0000e+00 - val_loss: 130.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/700\n",
      "12/12 - 0s - loss: 178.2598 - accuracy: 0.0000e+00 - val_loss: 126.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/700\n",
      "12/12 - 0s - loss: 178.7913 - accuracy: 0.0000e+00 - val_loss: 125.0996 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/700\n",
      "12/12 - 0s - loss: 179.1786 - accuracy: 0.0000e+00 - val_loss: 126.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/700\n",
      "12/12 - 0s - loss: 178.5403 - accuracy: 0.0000e+00 - val_loss: 131.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/700\n",
      "12/12 - 0s - loss: 178.4796 - accuracy: 0.0000e+00 - val_loss: 133.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/700\n",
      "12/12 - 0s - loss: 178.9639 - accuracy: 0.0000e+00 - val_loss: 132.2339 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/700\n",
      "12/12 - 0s - loss: 178.7219 - accuracy: 0.0000e+00 - val_loss: 129.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/700\n",
      "12/12 - 0s - loss: 178.2088 - accuracy: 0.0000e+00 - val_loss: 126.6096 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/700\n",
      "12/12 - 0s - loss: 178.6117 - accuracy: 0.0000e+00 - val_loss: 127.2195 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/700\n",
      "12/12 - 0s - loss: 178.3917 - accuracy: 0.0000e+00 - val_loss: 130.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/700\n",
      "12/12 - 0s - loss: 178.2645 - accuracy: 0.0000e+00 - val_loss: 131.3472 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/700\n",
      "12/12 - 0s - loss: 178.4673 - accuracy: 0.0000e+00 - val_loss: 129.5986 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/700\n",
      "12/12 - 0s - loss: 178.1783 - accuracy: 0.0000e+00 - val_loss: 128.3350 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/700\n",
      "12/12 - 0s - loss: 178.2231 - accuracy: 0.0000e+00 - val_loss: 127.5100 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/700\n",
      "12/12 - 0s - loss: 178.2536 - accuracy: 0.0000e+00 - val_loss: 129.6658 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/700\n",
      "12/12 - 0s - loss: 178.1681 - accuracy: 0.0000e+00 - val_loss: 131.9253 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/700\n",
      "12/12 - 0s - loss: 178.6338 - accuracy: 0.0000e+00 - val_loss: 131.5549 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/700\n",
      "12/12 - 0s - loss: 178.5270 - accuracy: 0.0000e+00 - val_loss: 128.8096 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/700\n",
      "12/12 - 0s - loss: 178.1923 - accuracy: 0.0000e+00 - val_loss: 126.6494 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/700\n",
      "12/12 - 0s - loss: 178.5172 - accuracy: 0.0000e+00 - val_loss: 127.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/700\n",
      "12/12 - 0s - loss: 178.2313 - accuracy: 0.0000e+00 - val_loss: 128.8325 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/700\n",
      "12/12 - 0s - loss: 178.1823 - accuracy: 0.0000e+00 - val_loss: 130.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/700\n",
      "12/12 - 0s - loss: 178.1443 - accuracy: 0.0000e+00 - val_loss: 129.0662 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/700\n",
      "12/12 - 0s - loss: 178.1665 - accuracy: 0.0000e+00 - val_loss: 128.3308 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/700\n",
      "12/12 - 0s - loss: 178.1916 - accuracy: 0.0000e+00 - val_loss: 127.9883 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/700\n",
      "12/12 - 0s - loss: 178.2007 - accuracy: 0.0000e+00 - val_loss: 128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/700\n",
      "12/12 - 0s - loss: 178.1971 - accuracy: 0.0000e+00 - val_loss: 128.3333 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/700\n",
      "12/12 - 0s - loss: 178.1808 - accuracy: 0.0000e+00 - val_loss: 128.9575 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/700\n",
      "12/12 - 0s - loss: 178.1546 - accuracy: 0.0000e+00 - val_loss: 129.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/700\n",
      "12/12 - 0s - loss: 178.1187 - accuracy: 0.0000e+00 - val_loss: 130.9648 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/700\n",
      "12/12 - 0s - loss: 178.3526 - accuracy: 0.0000e+00 - val_loss: 129.5049 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/700\n",
      "12/12 - 0s - loss: 178.1270 - accuracy: 0.0000e+00 - val_loss: 128.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/700\n",
      "12/12 - 0s - loss: 178.1629 - accuracy: 0.0000e+00 - val_loss: 127.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/700\n",
      "12/12 - 0s - loss: 178.1813 - accuracy: 0.0000e+00 - val_loss: 127.7607 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/700\n",
      "12/12 - 0s - loss: 178.1860 - accuracy: 0.0000e+00 - val_loss: 127.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/700\n",
      "12/12 - 0s - loss: 178.1781 - accuracy: 0.0000e+00 - val_loss: 128.3918 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/700\n",
      "12/12 - 0s - loss: 178.1579 - accuracy: 0.0000e+00 - val_loss: 129.1445 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/700\n",
      "12/12 - 0s - loss: 178.1275 - accuracy: 0.0000e+00 - val_loss: 130.1533 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/700\n",
      "12/12 - 0s - loss: 178.1187 - accuracy: 0.0000e+00 - val_loss: 128.5522 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/700\n",
      "12/12 - 0s - loss: 178.1447 - accuracy: 0.0000e+00 - val_loss: 127.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/700\n",
      "12/12 - 0s - loss: 178.1854 - accuracy: 0.0000e+00 - val_loss: 126.7690 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/700\n",
      "12/12 - 0s - loss: 178.3421 - accuracy: 0.0000e+00 - val_loss: 129.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/700\n",
      "12/12 - 0s - loss: 178.1133 - accuracy: 0.0000e+00 - val_loss: 131.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/700\n",
      "12/12 - 0s - loss: 178.5757 - accuracy: 0.0000e+00 - val_loss: 131.4988 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/700\n",
      "12/12 - 0s - loss: 178.5050 - accuracy: 0.0000e+00 - val_loss: 128.7441 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/700\n",
      "12/12 - 0s - loss: 178.1238 - accuracy: 0.0000e+00 - val_loss: 126.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/700\n",
      "12/12 - 0s - loss: 178.3764 - accuracy: 0.0000e+00 - val_loss: 127.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/700\n",
      "12/12 - 0s - loss: 178.1576 - accuracy: 0.0000e+00 - val_loss: 129.0867 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/700\n",
      "12/12 - 0s - loss: 178.1036 - accuracy: 0.0000e+00 - val_loss: 130.6458 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/700\n",
      "12/12 - 0s - loss: 178.2582 - accuracy: 0.0000e+00 - val_loss: 129.4954 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/700\n",
      "12/12 - 0s - loss: 178.0835 - accuracy: 0.0000e+00 - val_loss: 128.7954 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/700\n",
      "12/12 - 0s - loss: 178.1073 - accuracy: 0.0000e+00 - val_loss: 128.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/700\n",
      "12/12 - 0s - loss: 178.1169 - accuracy: 0.0000e+00 - val_loss: 128.5713 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/700\n",
      "12/12 - 0s - loss: 178.1119 - accuracy: 0.0000e+00 - val_loss: 128.9739 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/700\n",
      "12/12 - 0s - loss: 178.0944 - accuracy: 0.0000e+00 - val_loss: 129.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/700\n",
      "12/12 - 0s - loss: 178.0647 - accuracy: 0.0000e+00 - val_loss: 130.6467 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/700\n",
      "12/12 - 0s - loss: 178.2561 - accuracy: 0.0000e+00 - val_loss: 128.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/700\n",
      "12/12 - 0s - loss: 178.0881 - accuracy: 0.0000e+00 - val_loss: 127.7322 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/700\n",
      "12/12 - 0s - loss: 178.1316 - accuracy: 0.0000e+00 - val_loss: 126.9888 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/700\n",
      "12/12 - 0s - loss: 178.1682 - accuracy: 0.0000e+00 - val_loss: 129.4624 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/700\n",
      "12/12 - 0s - loss: 178.0614 - accuracy: 0.0000e+00 - val_loss: 132.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/700\n",
      "12/12 - 0s - loss: 178.6532 - accuracy: 0.0000e+00 - val_loss: 131.7451 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/700\n",
      "12/12 - 0s - loss: 178.5698 - accuracy: 0.0000e+00 - val_loss: 128.8708 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/700\n",
      "12/12 - 0s - loss: 178.0770 - accuracy: 0.0000e+00 - val_loss: 126.6230 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/700\n",
      "12/12 - 0s - loss: 178.2683 - accuracy: 0.0000e+00 - val_loss: 127.7661 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/700\n",
      "12/12 - 0s - loss: 178.1133 - accuracy: 0.0000e+00 - val_loss: 129.1423 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/700\n",
      "12/12 - 0s - loss: 178.0590 - accuracy: 0.0000e+00 - val_loss: 130.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/700\n",
      "12/12 - 0s - loss: 178.2752 - accuracy: 0.0000e+00 - val_loss: 129.5220 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/700\n",
      "12/12 - 0s - loss: 178.0397 - accuracy: 0.0000e+00 - val_loss: 128.7820 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/700\n",
      "12/12 - 0s - loss: 178.0652 - accuracy: 0.0000e+00 - val_loss: 128.4626 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/700\n",
      "12/12 - 0s - loss: 178.0752 - accuracy: 0.0000e+00 - val_loss: 128.5198 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/700\n",
      "12/12 - 0s - loss: 178.0706 - accuracy: 0.0000e+00 - val_loss: 128.9214 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/700\n",
      "12/12 - 0s - loss: 178.0523 - accuracy: 0.0000e+00 - val_loss: 129.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/700\n",
      "12/12 - 0s - loss: 178.0232 - accuracy: 0.0000e+00 - val_loss: 130.6238 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/700\n",
      "12/12 - 0s - loss: 178.2430 - accuracy: 0.0000e+00 - val_loss: 128.8494 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/700\n",
      "12/12 - 0s - loss: 178.0481 - accuracy: 0.0000e+00 - val_loss: 127.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/700\n",
      "12/12 - 0s - loss: 178.0930 - accuracy: 0.0000e+00 - val_loss: 126.8276 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/700\n",
      "12/12 - 0s - loss: 178.1243 - accuracy: 0.0000e+00 - val_loss: 129.3687 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/700\n",
      "12/12 - 0s - loss: 178.0208 - accuracy: 0.0000e+00 - val_loss: 132.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/700\n",
      "12/12 - 0s - loss: 178.6401 - accuracy: 0.0000e+00 - val_loss: 131.7063 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/700\n",
      "12/12 - 0s - loss: 178.5518 - accuracy: 0.0000e+00 - val_loss: 128.7424 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/700\n",
      "12/12 - 0s - loss: 178.0374 - accuracy: 0.0000e+00 - val_loss: 126.4221 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/700\n",
      "12/12 - 0s - loss: 178.2371 - accuracy: 0.0000e+00 - val_loss: 127.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/700\n",
      "12/12 - 0s - loss: 178.0758 - accuracy: 0.0000e+00 - val_loss: 129.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/700\n",
      "12/12 - 0s - loss: 178.0203 - accuracy: 0.0000e+00 - val_loss: 130.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/700\n",
      "12/12 - 0s - loss: 178.2419 - accuracy: 0.0000e+00 - val_loss: 129.3926 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/700\n",
      "12/12 - 0s - loss: 178.0007 - accuracy: 0.0000e+00 - val_loss: 128.6277 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/700\n",
      "12/12 - 0s - loss: 178.0273 - accuracy: 0.0000e+00 - val_loss: 128.2961 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/700\n",
      "12/12 - 0s - loss: 178.0369 - accuracy: 0.0000e+00 - val_loss: 128.3545 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/700\n",
      "12/12 - 0s - loss: 178.0326 - accuracy: 0.0000e+00 - val_loss: 128.7649 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/700\n",
      "12/12 - 0s - loss: 178.0146 - accuracy: 0.0000e+00 - val_loss: 129.4944 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/700\n",
      "12/12 - 0s - loss: 177.9845 - accuracy: 0.0000e+00 - val_loss: 130.5103 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/700\n",
      "12/12 - 0s - loss: 178.2037 - accuracy: 0.0000e+00 - val_loss: 128.6838 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/700\n",
      "12/12 - 0s - loss: 178.0099 - accuracy: 0.0000e+00 - val_loss: 127.3992 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/700\n",
      "12/12 - 0s - loss: 178.0559 - accuracy: 0.0000e+00 - val_loss: 126.6016 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/700\n",
      "12/12 - 0s - loss: 178.1008 - accuracy: 0.0000e+00 - val_loss: 129.2146 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/700\n",
      "12/12 - 0s - loss: 177.9820 - accuracy: 0.0000e+00 - val_loss: 131.9304 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/700\n",
      "12/12 - 0s - loss: 178.6095 - accuracy: 0.0000e+00 - val_loss: 131.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/700\n",
      "12/12 - 0s - loss: 178.5183 - accuracy: 0.0000e+00 - val_loss: 128.5662 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/700\n",
      "12/12 - 0s - loss: 177.9999 - accuracy: 0.0000e+00 - val_loss: 126.1794 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/700\n",
      "12/12 - 0s - loss: 178.2185 - accuracy: 0.0000e+00 - val_loss: 127.3848 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/700\n",
      "12/12 - 0s - loss: 178.0392 - accuracy: 0.0000e+00 - val_loss: 128.8354 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/700\n",
      "12/12 - 0s - loss: 177.9817 - accuracy: 0.0000e+00 - val_loss: 130.5107 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/700\n",
      "12/12 - 0s - loss: 178.1986 - accuracy: 0.0000e+00 - val_loss: 129.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/700\n",
      "12/12 - 0s - loss: 177.9611 - accuracy: 0.0000e+00 - val_loss: 128.4438 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/700\n",
      "12/12 - 0s - loss: 177.9886 - accuracy: 0.0000e+00 - val_loss: 128.1011 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/700\n",
      "12/12 - 0s - loss: 177.9987 - accuracy: 0.0000e+00 - val_loss: 128.1611 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/700\n",
      "12/12 - 0s - loss: 177.9942 - accuracy: 0.0000e+00 - val_loss: 128.5815 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/700\n",
      "12/12 - 0s - loss: 177.9755 - accuracy: 0.0000e+00 - val_loss: 129.3313 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/700\n",
      "12/12 - 0s - loss: 177.9439 - accuracy: 0.0000e+00 - val_loss: 130.3755 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/700\n",
      "12/12 - 0s - loss: 178.1565 - accuracy: 0.0000e+00 - val_loss: 128.4985 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/700\n",
      "12/12 - 0s - loss: 177.9709 - accuracy: 0.0000e+00 - val_loss: 127.1782 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/700\n",
      "12/12 - 0s - loss: 178.0177 - accuracy: 0.0000e+00 - val_loss: 126.3574 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/700\n",
      "12/12 - 0s - loss: 178.0807 - accuracy: 0.0000e+00 - val_loss: 129.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/700\n",
      "12/12 - 0s - loss: 177.9427 - accuracy: 0.0000e+00 - val_loss: 131.8306 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/700\n",
      "12/12 - 0s - loss: 178.5736 - accuracy: 0.0000e+00 - val_loss: 131.5076 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/700\n",
      "12/12 - 0s - loss: 178.4802 - accuracy: 0.0000e+00 - val_loss: 128.3740 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/700\n",
      "12/12 - 0s - loss: 177.9595 - accuracy: 0.0000e+00 - val_loss: 125.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/700\n",
      "12/12 - 0s - loss: 178.2021 - accuracy: 0.0000e+00 - val_loss: 127.1604 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/700\n",
      "12/12 - 0s - loss: 178.0006 - accuracy: 0.0000e+00 - val_loss: 128.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/700\n",
      "12/12 - 0s - loss: 177.9420 - accuracy: 0.0000e+00 - val_loss: 130.3684 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/700\n",
      "12/12 - 0s - loss: 178.1501 - accuracy: 0.0000e+00 - val_loss: 129.0547 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/700\n",
      "12/12 - 0s - loss: 177.9212 - accuracy: 0.0000e+00 - val_loss: 128.2463 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/700\n",
      "12/12 - 0s - loss: 177.9491 - accuracy: 0.0000e+00 - val_loss: 127.8950 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/700\n",
      "12/12 - 0s - loss: 177.9600 - accuracy: 0.0000e+00 - val_loss: 127.9558 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/700\n",
      "12/12 - 0s - loss: 177.9551 - accuracy: 0.0000e+00 - val_loss: 128.3894 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/700\n",
      "12/12 - 0s - loss: 177.9357 - accuracy: 0.0000e+00 - val_loss: 129.1572 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/700\n",
      "12/12 - 0s - loss: 177.9044 - accuracy: 0.0000e+00 - val_loss: 130.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/700\n",
      "12/12 - 0s - loss: 178.1064 - accuracy: 0.0000e+00 - val_loss: 128.3020 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/700\n",
      "12/12 - 0s - loss: 177.9316 - accuracy: 0.0000e+00 - val_loss: 126.9451 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/700\n",
      "12/12 - 0s - loss: 177.9801 - accuracy: 0.0000e+00 - val_loss: 126.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/700\n",
      "12/12 - 0s - loss: 178.0614 - accuracy: 0.0000e+00 - val_loss: 128.8560 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/700\n",
      "12/12 - 0s - loss: 177.9028 - accuracy: 0.0000e+00 - val_loss: 131.7195 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/700\n",
      "12/12 - 0s - loss: 178.5337 - accuracy: 0.0000e+00 - val_loss: 131.3872 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/700\n",
      "12/12 - 0s - loss: 178.4382 - accuracy: 0.0000e+00 - val_loss: 128.1721 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/700\n",
      "12/12 - 0s - loss: 177.9210 - accuracy: 0.0000e+00 - val_loss: 125.6567 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/700\n",
      "12/12 - 0s - loss: 178.1860 - accuracy: 0.0000e+00 - val_loss: 126.9260 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/700\n",
      "12/12 - 0s - loss: 177.9620 - accuracy: 0.0000e+00 - val_loss: 128.4551 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/700\n",
      "12/12 - 0s - loss: 177.9014 - accuracy: 0.0000e+00 - val_loss: 130.2170 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/700\n",
      "12/12 - 0s - loss: 178.0989 - accuracy: 0.0000e+00 - val_loss: 128.8694 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/700\n",
      "12/12 - 0s - loss: 177.8802 - accuracy: 0.0000e+00 - val_loss: 128.0405 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/700\n",
      "12/12 - 0s - loss: 177.9089 - accuracy: 0.0000e+00 - val_loss: 127.6790 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/700\n",
      "12/12 - 0s - loss: 177.9200 - accuracy: 0.0000e+00 - val_loss: 127.7400 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/700\n",
      "12/12 - 0s - loss: 177.9153 - accuracy: 0.0000e+00 - val_loss: 128.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/700\n",
      "12/12 - 0s - loss: 177.8953 - accuracy: 0.0000e+00 - val_loss: 128.9729 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/700\n",
      "12/12 - 0s - loss: 177.8626 - accuracy: 0.0000e+00 - val_loss: 130.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/700\n",
      "12/12 - 0s - loss: 178.0544 - accuracy: 0.0000e+00 - val_loss: 128.0955 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/700\n",
      "12/12 - 0s - loss: 177.8905 - accuracy: 0.0000e+00 - val_loss: 126.7048 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/700\n",
      "12/12 - 0s - loss: 177.9407 - accuracy: 0.0000e+00 - val_loss: 125.8408 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/700\n",
      "12/12 - 0s - loss: 178.0426 - accuracy: 0.0000e+00 - val_loss: 128.6628 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/700\n",
      "12/12 - 0s - loss: 177.8615 - accuracy: 0.0000e+00 - val_loss: 131.5972 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/700\n",
      "12/12 - 0s - loss: 178.4902 - accuracy: 0.0000e+00 - val_loss: 131.2563 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/700\n",
      "12/12 - 0s - loss: 178.3925 - accuracy: 0.0000e+00 - val_loss: 127.9614 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/700\n",
      "12/12 - 0s - loss: 177.8799 - accuracy: 0.0000e+00 - val_loss: 125.3828 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/700\n",
      "12/12 - 0s - loss: 178.1700 - accuracy: 0.0000e+00 - val_loss: 126.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/700\n",
      "12/12 - 0s - loss: 177.9223 - accuracy: 0.0000e+00 - val_loss: 128.2510 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/700\n",
      "12/12 - 0s - loss: 177.8603 - accuracy: 0.0000e+00 - val_loss: 130.0564 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/700\n",
      "12/12 - 0s - loss: 178.0445 - accuracy: 0.0000e+00 - val_loss: 128.6743 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/700\n",
      "12/12 - 0s - loss: 177.8384 - accuracy: 0.0000e+00 - val_loss: 127.8240 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/700\n",
      "12/12 - 0s - loss: 177.8676 - accuracy: 0.0000e+00 - val_loss: 127.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/700\n",
      "12/12 - 0s - loss: 177.8791 - accuracy: 0.0000e+00 - val_loss: 127.5176 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/700\n",
      "12/12 - 0s - loss: 177.8737 - accuracy: 0.0000e+00 - val_loss: 127.9712 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/700\n",
      "12/12 - 0s - loss: 177.8538 - accuracy: 0.0000e+00 - val_loss: 128.7778 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/700\n",
      "12/12 - 0s - loss: 177.8206 - accuracy: 0.0000e+00 - val_loss: 129.9036 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/700\n",
      "12/12 - 0s - loss: 177.9981 - accuracy: 0.0000e+00 - val_loss: 127.8796 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/700\n",
      "12/12 - 0s - loss: 177.8495 - accuracy: 0.0000e+00 - val_loss: 126.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/700\n",
      "12/12 - 0s - loss: 177.9001 - accuracy: 0.0000e+00 - val_loss: 125.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/700\n",
      "12/12 - 0s - loss: 178.0235 - accuracy: 0.0000e+00 - val_loss: 128.4592 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/700\n",
      "12/12 - 0s - loss: 177.8191 - accuracy: 0.0000e+00 - val_loss: 131.4644 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/700\n",
      "12/12 - 0s - loss: 178.4447 - accuracy: 0.0000e+00 - val_loss: 131.1157 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/700\n",
      "12/12 - 0s - loss: 178.3440 - accuracy: 0.0000e+00 - val_loss: 127.7405 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/700\n",
      "12/12 - 0s - loss: 177.8377 - accuracy: 0.0000e+00 - val_loss: 125.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/700\n",
      "12/12 - 0s - loss: 178.1548 - accuracy: 0.0000e+00 - val_loss: 126.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/700\n",
      "12/12 - 0s - loss: 177.8815 - accuracy: 0.0000e+00 - val_loss: 128.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/700\n",
      "12/12 - 0s - loss: 177.8180 - accuracy: 0.0000e+00 - val_loss: 129.8838 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/700\n",
      "12/12 - 0s - loss: 177.9866 - accuracy: 0.0000e+00 - val_loss: 128.4678 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/700\n",
      "12/12 - 0s - loss: 177.7960 - accuracy: 0.0000e+00 - val_loss: 127.5991 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/700\n",
      "12/12 - 0s - loss: 177.8262 - accuracy: 0.0000e+00 - val_loss: 127.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/700\n",
      "12/12 - 0s - loss: 177.8372 - accuracy: 0.0000e+00 - val_loss: 127.2834 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/700\n",
      "12/12 - 0s - loss: 177.8324 - accuracy: 0.0000e+00 - val_loss: 127.7478 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/700\n",
      "12/12 - 0s - loss: 177.8114 - accuracy: 0.0000e+00 - val_loss: 128.5735 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/700\n",
      "12/12 - 0s - loss: 177.7779 - accuracy: 0.0000e+00 - val_loss: 129.7258 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/700\n",
      "12/12 - 0s - loss: 177.9386 - accuracy: 0.0000e+00 - val_loss: 127.6533 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/700\n",
      "12/12 - 0s - loss: 177.8070 - accuracy: 0.0000e+00 - val_loss: 126.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/700\n",
      "12/12 - 0s - loss: 177.8593 - accuracy: 0.0000e+00 - val_loss: 125.2876 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/700\n",
      "12/12 - 0s - loss: 178.0048 - accuracy: 0.0000e+00 - val_loss: 128.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/700\n",
      "12/12 - 0s - loss: 177.7767 - accuracy: 0.0000e+00 - val_loss: 131.3215 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/700\n",
      "12/12 - 0s - loss: 178.3956 - accuracy: 0.0000e+00 - val_loss: 130.9634 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/700\n",
      "12/12 - 0s - loss: 178.2926 - accuracy: 0.0000e+00 - val_loss: 127.5103 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/700\n",
      "12/12 - 0s - loss: 177.7957 - accuracy: 0.0000e+00 - val_loss: 124.8071 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/700\n",
      "12/12 - 0s - loss: 178.1392 - accuracy: 0.0000e+00 - val_loss: 126.1694 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/700\n",
      "12/12 - 0s - loss: 177.8402 - accuracy: 0.0000e+00 - val_loss: 127.8093 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/700\n",
      "12/12 - 0s - loss: 177.7751 - accuracy: 0.0000e+00 - val_loss: 129.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/700\n",
      "12/12 - 0s - loss: 177.9264 - accuracy: 0.0000e+00 - val_loss: 128.2534 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/700\n",
      "12/12 - 0s - loss: 177.7532 - accuracy: 0.0000e+00 - val_loss: 127.3625 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/700\n",
      "12/12 - 0s - loss: 177.7839 - accuracy: 0.0000e+00 - val_loss: 126.9746 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/700\n",
      "12/12 - 0s - loss: 177.7957 - accuracy: 0.0000e+00 - val_loss: 127.0398 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/700\n",
      "12/12 - 0s - loss: 177.7897 - accuracy: 0.0000e+00 - val_loss: 127.5142 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/700\n",
      "12/12 - 0s - loss: 177.7690 - accuracy: 0.0000e+00 - val_loss: 128.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/700\n",
      "12/12 - 0s - loss: 177.7342 - accuracy: 0.0000e+00 - val_loss: 129.5361 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/700\n",
      "12/12 - 0s - loss: 177.8753 - accuracy: 0.0000e+00 - val_loss: 127.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/700\n",
      "12/12 - 0s - loss: 177.7644 - accuracy: 0.0000e+00 - val_loss: 125.9233 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/700\n",
      "12/12 - 0s - loss: 177.8179 - accuracy: 0.0000e+00 - val_loss: 124.9951 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/700\n",
      "12/12 - 0s - loss: 177.9876 - accuracy: 0.0000e+00 - val_loss: 128.0225 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/700\n",
      "12/12 - 0s - loss: 177.7325 - accuracy: 0.0000e+00 - val_loss: 131.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/700\n",
      "12/12 - 0s - loss: 178.3422 - accuracy: 0.0000e+00 - val_loss: 130.8003 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/700\n",
      "12/12 - 0s - loss: 178.2366 - accuracy: 0.0000e+00 - val_loss: 127.2681 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/700\n",
      "12/12 - 0s - loss: 177.7524 - accuracy: 0.0000e+00 - val_loss: 124.5044 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/700\n",
      "12/12 - 0s - loss: 178.1253 - accuracy: 0.0000e+00 - val_loss: 125.8975 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/700\n",
      "12/12 - 0s - loss: 177.7983 - accuracy: 0.0000e+00 - val_loss: 127.5725 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/700\n",
      "12/12 - 0s - loss: 177.7316 - accuracy: 0.0000e+00 - val_loss: 129.5076 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/700\n",
      "12/12 - 0s - loss: 177.8619 - accuracy: 0.0000e+00 - val_loss: 128.0261 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/700\n",
      "12/12 - 0s - loss: 177.7087 - accuracy: 0.0000e+00 - val_loss: 127.1160 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/700\n",
      "12/12 - 0s - loss: 177.7406 - accuracy: 0.0000e+00 - val_loss: 126.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/700\n",
      "12/12 - 0s - loss: 177.7526 - accuracy: 0.0000e+00 - val_loss: 126.7849 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/700\n",
      "12/12 - 0s - loss: 177.7467 - accuracy: 0.0000e+00 - val_loss: 127.2698 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/700\n",
      "12/12 - 0s - loss: 177.7257 - accuracy: 0.0000e+00 - val_loss: 128.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/700\n",
      "12/12 - 0s - loss: 177.6907 - accuracy: 0.0000e+00 - val_loss: 129.3357 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/700\n",
      "12/12 - 0s - loss: 177.8098 - accuracy: 0.0000e+00 - val_loss: 127.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/700\n",
      "12/12 - 0s - loss: 177.7208 - accuracy: 0.0000e+00 - val_loss: 125.6426 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/700\n",
      "12/12 - 0s - loss: 177.7756 - accuracy: 0.0000e+00 - val_loss: 124.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/700\n",
      "12/12 - 0s - loss: 177.9713 - accuracy: 0.0000e+00 - val_loss: 127.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/700\n",
      "12/12 - 0s - loss: 177.6883 - accuracy: 0.0000e+00 - val_loss: 130.9985 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/700\n",
      "12/12 - 0s - loss: 178.2856 - accuracy: 0.0000e+00 - val_loss: 130.6235 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/700\n",
      "12/12 - 0s - loss: 178.1781 - accuracy: 0.0000e+00 - val_loss: 127.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/700\n",
      "12/12 - 0s - loss: 177.7089 - accuracy: 0.0000e+00 - val_loss: 124.1907 - val_accuracy: 0.0000e+00\n",
      "Epoch 501/700\n",
      "12/12 - 0s - loss: 178.1127 - accuracy: 0.0000e+00 - val_loss: 125.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 502/700\n",
      "12/12 - 0s - loss: 177.7551 - accuracy: 0.0000e+00 - val_loss: 127.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 503/700\n",
      "12/12 - 0s - loss: 177.6877 - accuracy: 0.0000e+00 - val_loss: 129.3015 - val_accuracy: 0.0000e+00\n",
      "Epoch 504/700\n",
      "12/12 - 0s - loss: 177.7946 - accuracy: 0.0000e+00 - val_loss: 127.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 505/700\n",
      "12/12 - 0s - loss: 177.6637 - accuracy: 0.0000e+00 - val_loss: 126.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 506/700\n",
      "12/12 - 0s - loss: 177.6962 - accuracy: 0.0000e+00 - val_loss: 126.4504 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/700\n",
      "12/12 - 0s - loss: 177.7086 - accuracy: 0.0000e+00 - val_loss: 126.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/700\n",
      "12/12 - 0s - loss: 177.7032 - accuracy: 0.0000e+00 - val_loss: 127.0122 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/700\n",
      "12/12 - 0s - loss: 177.6812 - accuracy: 0.0000e+00 - val_loss: 127.8928 - val_accuracy: 0.0000e+00\n",
      "Epoch 510/700\n",
      "12/12 - 0s - loss: 177.6448 - accuracy: 0.0000e+00 - val_loss: 129.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/700\n",
      "12/12 - 0s - loss: 177.7392 - accuracy: 0.0000e+00 - val_loss: 126.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 512/700\n",
      "12/12 - 0s - loss: 177.6764 - accuracy: 0.0000e+00 - val_loss: 125.3501 - val_accuracy: 0.0000e+00\n",
      "Epoch 513/700\n",
      "12/12 - 0s - loss: 177.7318 - accuracy: 0.0000e+00 - val_loss: 124.3816 - val_accuracy: 0.0000e+00\n",
      "Epoch 514/700\n",
      "12/12 - 0s - loss: 177.9565 - accuracy: 0.0000e+00 - val_loss: 127.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 515/700\n",
      "12/12 - 0s - loss: 177.6433 - accuracy: 0.0000e+00 - val_loss: 130.8184 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/700\n",
      "12/12 - 0s - loss: 178.2249 - accuracy: 0.0000e+00 - val_loss: 130.4360 - val_accuracy: 0.0000e+00\n",
      "Epoch 517/700\n",
      "12/12 - 0s - loss: 178.1147 - accuracy: 0.0000e+00 - val_loss: 126.7493 - val_accuracy: 0.0000e+00\n",
      "Epoch 518/700\n",
      "12/12 - 0s - loss: 177.6643 - accuracy: 0.0000e+00 - val_loss: 123.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/700\n",
      "12/12 - 0s - loss: 178.1006 - accuracy: 0.0000e+00 - val_loss: 125.3169 - val_accuracy: 0.0000e+00\n",
      "Epoch 520/700\n",
      "12/12 - 0s - loss: 177.7126 - accuracy: 0.0000e+00 - val_loss: 127.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 521/700\n",
      "12/12 - 0s - loss: 177.6423 - accuracy: 0.0000e+00 - val_loss: 129.0813 - val_accuracy: 0.0000e+00\n",
      "Epoch 522/700\n",
      "12/12 - 0s - loss: 177.7221 - accuracy: 0.0000e+00 - val_loss: 127.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 523/700\n",
      "12/12 - 0s - loss: 177.6182 - accuracy: 0.0000e+00 - val_loss: 126.5854 - val_accuracy: 0.0000e+00\n",
      "Epoch 524/700\n",
      "12/12 - 0s - loss: 177.6513 - accuracy: 0.0000e+00 - val_loss: 126.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 525/700\n",
      "12/12 - 0s - loss: 177.6641 - accuracy: 0.0000e+00 - val_loss: 126.2400 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/700\n",
      "12/12 - 0s - loss: 177.6581 - accuracy: 0.0000e+00 - val_loss: 126.7441 - val_accuracy: 0.0000e+00\n",
      "Epoch 527/700\n",
      "12/12 - 0s - loss: 177.6362 - accuracy: 0.0000e+00 - val_loss: 127.6436 - val_accuracy: 0.0000e+00\n",
      "Epoch 528/700\n",
      "12/12 - 0s - loss: 177.5990 - accuracy: 0.0000e+00 - val_loss: 128.8965 - val_accuracy: 0.0000e+00\n",
      "Epoch 529/700\n",
      "12/12 - 0s - loss: 177.6658 - accuracy: 0.0000e+00 - val_loss: 126.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 530/700\n",
      "12/12 - 0s - loss: 177.6307 - accuracy: 0.0000e+00 - val_loss: 125.0464 - val_accuracy: 0.0000e+00\n",
      "Epoch 531/700\n",
      "12/12 - 0s - loss: 177.6882 - accuracy: 0.0000e+00 - val_loss: 124.0569 - val_accuracy: 0.0000e+00\n",
      "Epoch 532/700\n",
      "12/12 - 0s - loss: 177.9427 - accuracy: 0.0000e+00 - val_loss: 127.2776 - val_accuracy: 0.0000e+00\n",
      "Epoch 533/700\n",
      "12/12 - 0s - loss: 177.5979 - accuracy: 0.0000e+00 - val_loss: 130.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 534/700\n",
      "12/12 - 0s - loss: 178.1613 - accuracy: 0.0000e+00 - val_loss: 130.2349 - val_accuracy: 0.0000e+00\n",
      "Epoch 535/700\n",
      "12/12 - 0s - loss: 178.0476 - accuracy: 0.0000e+00 - val_loss: 126.4724 - val_accuracy: 0.0000e+00\n",
      "Epoch 536/700\n",
      "12/12 - 0s - loss: 177.6186 - accuracy: 0.0000e+00 - val_loss: 123.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 537/700\n",
      "12/12 - 0s - loss: 178.0911 - accuracy: 0.0000e+00 - val_loss: 125.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 538/700\n",
      "12/12 - 0s - loss: 177.6684 - accuracy: 0.0000e+00 - val_loss: 126.7949 - val_accuracy: 0.0000e+00\n",
      "Epoch 539/700\n",
      "12/12 - 0s - loss: 177.5976 - accuracy: 0.0000e+00 - val_loss: 128.8508 - val_accuracy: 0.0000e+00\n",
      "Epoch 540/700\n",
      "12/12 - 0s - loss: 177.6468 - accuracy: 0.0000e+00 - val_loss: 127.2747 - val_accuracy: 0.0000e+00\n",
      "Epoch 541/700\n",
      "12/12 - 0s - loss: 177.5727 - accuracy: 0.0000e+00 - val_loss: 126.3042 - val_accuracy: 0.0000e+00\n",
      "Epoch 542/700\n",
      "12/12 - 0s - loss: 177.6065 - accuracy: 0.0000e+00 - val_loss: 125.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 543/700\n",
      "12/12 - 0s - loss: 177.6191 - accuracy: 0.0000e+00 - val_loss: 125.9500 - val_accuracy: 0.0000e+00\n",
      "Epoch 544/700\n",
      "12/12 - 0s - loss: 177.6134 - accuracy: 0.0000e+00 - val_loss: 126.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 545/700\n",
      "12/12 - 0s - loss: 177.5906 - accuracy: 0.0000e+00 - val_loss: 127.3804 - val_accuracy: 0.0000e+00\n",
      "Epoch 546/700\n",
      "12/12 - 0s - loss: 177.5526 - accuracy: 0.0000e+00 - val_loss: 128.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 547/700\n",
      "12/12 - 0s - loss: 177.5880 - accuracy: 0.0000e+00 - val_loss: 126.3533 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/700\n",
      "12/12 - 0s - loss: 177.5853 - accuracy: 0.0000e+00 - val_loss: 124.7300 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/700\n",
      "12/12 - 0s - loss: 177.6443 - accuracy: 0.0000e+00 - val_loss: 123.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 550/700\n",
      "12/12 - 0s - loss: 177.9308 - accuracy: 0.0000e+00 - val_loss: 127.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 551/700\n",
      "12/12 - 0s - loss: 177.5510 - accuracy: 0.0000e+00 - val_loss: 130.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 552/700\n",
      "12/12 - 0s - loss: 178.0924 - accuracy: 0.0000e+00 - val_loss: 130.0205 - val_accuracy: 0.0000e+00\n",
      "Epoch 553/700\n",
      "12/12 - 0s - loss: 177.9767 - accuracy: 0.0000e+00 - val_loss: 126.1836 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/700\n",
      "12/12 - 0s - loss: 177.5725 - accuracy: 0.0000e+00 - val_loss: 123.1814 - val_accuracy: 0.0000e+00\n",
      "Epoch 555/700\n",
      "12/12 - 0s - loss: 178.0822 - accuracy: 0.0000e+00 - val_loss: 124.6917 - val_accuracy: 0.0000e+00\n",
      "Epoch 556/700\n",
      "12/12 - 0s - loss: 177.6230 - accuracy: 0.0000e+00 - val_loss: 126.5090 - val_accuracy: 0.0000e+00\n",
      "Epoch 557/700\n",
      "12/12 - 0s - loss: 177.5509 - accuracy: 0.0000e+00 - val_loss: 128.6060 - val_accuracy: 0.0000e+00\n",
      "Epoch 558/700\n",
      "12/12 - 0s - loss: 177.5679 - accuracy: 0.0000e+00 - val_loss: 126.9976 - val_accuracy: 0.0000e+00\n",
      "Epoch 559/700\n",
      "12/12 - 0s - loss: 177.5259 - accuracy: 0.0000e+00 - val_loss: 126.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 560/700\n",
      "12/12 - 0s - loss: 177.5602 - accuracy: 0.0000e+00 - val_loss: 125.5752 - val_accuracy: 0.0000e+00\n",
      "Epoch 561/700\n",
      "12/12 - 0s - loss: 177.5732 - accuracy: 0.0000e+00 - val_loss: 125.6458 - val_accuracy: 0.0000e+00\n",
      "Epoch 562/700\n",
      "12/12 - 0s - loss: 177.5675 - accuracy: 0.0000e+00 - val_loss: 126.1702 - val_accuracy: 0.0000e+00\n",
      "Epoch 563/700\n",
      "12/12 - 0s - loss: 177.5449 - accuracy: 0.0000e+00 - val_loss: 127.1045 - val_accuracy: 0.0000e+00\n",
      "Epoch 564/700\n",
      "12/12 - 0s - loss: 177.5066 - accuracy: 0.0000e+00 - val_loss: 128.4075 - val_accuracy: 0.0000e+00\n",
      "Epoch 565/700\n",
      "12/12 - 0s - loss: 177.5068 - accuracy: 0.0000e+00 - val_loss: 126.0571 - val_accuracy: 0.0000e+00\n",
      "Epoch 566/700\n",
      "12/12 - 0s - loss: 177.5395 - accuracy: 0.0000e+00 - val_loss: 124.4014 - val_accuracy: 0.0000e+00\n",
      "Epoch 567/700\n",
      "12/12 - 0s - loss: 177.5992 - accuracy: 0.0000e+00 - val_loss: 123.3721 - val_accuracy: 0.0000e+00\n",
      "Epoch 568/700\n",
      "12/12 - 0s - loss: 177.9206 - accuracy: 0.0000e+00 - val_loss: 126.7202 - val_accuracy: 0.0000e+00\n",
      "Epoch 569/700\n",
      "12/12 - 0s - loss: 177.5046 - accuracy: 0.0000e+00 - val_loss: 130.2019 - val_accuracy: 0.0000e+00\n",
      "Epoch 570/700\n",
      "12/12 - 0s - loss: 178.0202 - accuracy: 0.0000e+00 - val_loss: 129.7942 - val_accuracy: 0.0000e+00\n",
      "Epoch 571/700\n",
      "12/12 - 0s - loss: 177.9027 - accuracy: 0.0000e+00 - val_loss: 125.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 572/700\n",
      "12/12 - 0s - loss: 177.5268 - accuracy: 0.0000e+00 - val_loss: 122.8208 - val_accuracy: 0.0000e+00\n",
      "Epoch 573/700\n",
      "12/12 - 0s - loss: 178.0750 - accuracy: 0.0000e+00 - val_loss: 124.3611 - val_accuracy: 0.0000e+00\n",
      "Epoch 574/700\n",
      "12/12 - 0s - loss: 177.5771 - accuracy: 0.0000e+00 - val_loss: 126.2129 - val_accuracy: 0.0000e+00\n",
      "Epoch 575/700\n",
      "12/12 - 0s - loss: 177.5035 - accuracy: 0.0000e+00 - val_loss: 128.3501 - val_accuracy: 0.0000e+00\n",
      "Epoch 576/700\n",
      "12/12 - 0s - loss: 177.4849 - accuracy: 0.0000e+00 - val_loss: 126.7107 - val_accuracy: 0.0000e+00\n",
      "Epoch 577/700\n",
      "12/12 - 0s - loss: 177.4788 - accuracy: 0.0000e+00 - val_loss: 125.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 578/700\n",
      "12/12 - 0s - loss: 177.5136 - accuracy: 0.0000e+00 - val_loss: 125.2598 - val_accuracy: 0.0000e+00\n",
      "Epoch 579/700\n",
      "12/12 - 0s - loss: 177.5263 - accuracy: 0.0000e+00 - val_loss: 125.3320 - val_accuracy: 0.0000e+00\n",
      "Epoch 580/700\n",
      "12/12 - 0s - loss: 177.5202 - accuracy: 0.0000e+00 - val_loss: 125.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 581/700\n",
      "12/12 - 0s - loss: 177.4978 - accuracy: 0.0000e+00 - val_loss: 126.8179 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 582/700\n",
      "12/12 - 0s - loss: 177.4588 - accuracy: 0.0000e+00 - val_loss: 128.1443 - val_accuracy: 0.0000e+00\n",
      "Epoch 583/700\n",
      "12/12 - 0s - loss: 177.4215 - accuracy: 0.0000e+00 - val_loss: 125.7485 - val_accuracy: 0.0000e+00\n",
      "Epoch 584/700\n",
      "12/12 - 0s - loss: 177.4923 - accuracy: 0.0000e+00 - val_loss: 124.0608 - val_accuracy: 0.0000e+00\n",
      "Epoch 585/700\n",
      "12/12 - 0s - loss: 177.5548 - accuracy: 0.0000e+00 - val_loss: 126.8906 - val_accuracy: 0.0000e+00\n",
      "Epoch 586/700\n",
      "12/12 - 0s - loss: 177.4429 - accuracy: 0.0000e+00 - val_loss: 129.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 587/700\n",
      "12/12 - 0s - loss: 177.9285 - accuracy: 0.0000e+00 - val_loss: 129.0293 - val_accuracy: 0.0000e+00\n",
      "Epoch 588/700\n",
      "12/12 - 0s - loss: 177.6738 - accuracy: 0.0000e+00 - val_loss: 124.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 589/700\n",
      "12/12 - 0s - loss: 177.5179 - accuracy: 0.0000e+00 - val_loss: 121.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 590/700\n",
      "12/12 - 0s - loss: 178.5358 - accuracy: 0.0000e+00 - val_loss: 122.3530 - val_accuracy: 0.0000e+00\n",
      "Epoch 591/700\n",
      "12/12 - 0s - loss: 178.1025 - accuracy: 0.0000e+00 - val_loss: 127.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 592/700\n",
      "12/12 - 0s - loss: 177.3867 - accuracy: 0.0000e+00 - val_loss: 133.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 593/700\n",
      "12/12 - 0s - loss: 178.8812 - accuracy: 0.0000e+00 - val_loss: 134.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 594/700\n",
      "12/12 - 0s - loss: 179.4616 - accuracy: 0.0000e+00 - val_loss: 127.9824 - val_accuracy: 0.0000e+00\n",
      "Epoch 595/700\n",
      "12/12 - 0s - loss: 177.3703 - accuracy: 0.0000e+00 - val_loss: 122.6001 - val_accuracy: 0.0000e+00\n",
      "Epoch 596/700\n",
      "12/12 - 0s - loss: 177.9765 - accuracy: 0.0000e+00 - val_loss: 122.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 597/700\n",
      "12/12 - 0s - loss: 178.1275 - accuracy: 0.0000e+00 - val_loss: 126.1238 - val_accuracy: 0.0000e+00\n",
      "Epoch 598/700\n",
      "12/12 - 0s - loss: 177.4294 - accuracy: 0.0000e+00 - val_loss: 130.1870 - val_accuracy: 0.0000e+00\n",
      "Epoch 599/700\n",
      "12/12 - 0s - loss: 178.0006 - accuracy: 0.0000e+00 - val_loss: 130.2068 - val_accuracy: 0.0000e+00\n",
      "Epoch 600/700\n",
      "12/12 - 0s - loss: 178.0060 - accuracy: 0.0000e+00 - val_loss: 126.5806 - val_accuracy: 0.0000e+00\n",
      "Epoch 601/700\n",
      "12/12 - 0s - loss: 177.4014 - accuracy: 0.0000e+00 - val_loss: 123.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 602/700\n",
      "12/12 - 0s - loss: 177.5133 - accuracy: 0.0000e+00 - val_loss: 125.6926 - val_accuracy: 0.0000e+00\n",
      "Epoch 603/700\n",
      "12/12 - 0s - loss: 177.4284 - accuracy: 0.0000e+00 - val_loss: 127.8843 - val_accuracy: 0.0000e+00\n",
      "Epoch 604/700\n",
      "12/12 - 0s - loss: 177.3415 - accuracy: 0.0000e+00 - val_loss: 130.3394 - val_accuracy: 0.0000e+00\n",
      "Epoch 605/700\n",
      "12/12 - 0s - loss: 178.0408 - accuracy: 0.0000e+00 - val_loss: 128.8882 - val_accuracy: 0.0000e+00\n",
      "Epoch 606/700\n",
      "12/12 - 0s - loss: 177.6226 - accuracy: 0.0000e+00 - val_loss: 123.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 607/700\n",
      "12/12 - 0s - loss: 177.4808 - accuracy: 0.0000e+00 - val_loss: 119.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 608/700\n",
      "12/12 - 0s - loss: 178.8114 - accuracy: 0.0000e+00 - val_loss: 120.7537 - val_accuracy: 0.0000e+00\n",
      "Epoch 609/700\n",
      "12/12 - 0s - loss: 178.5118 - accuracy: 0.0000e+00 - val_loss: 125.9531 - val_accuracy: 0.0000e+00\n",
      "Epoch 610/700\n",
      "12/12 - 0s - loss: 177.3930 - accuracy: 0.0000e+00 - val_loss: 131.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 611/700\n",
      "12/12 - 0s - loss: 178.2610 - accuracy: 0.0000e+00 - val_loss: 132.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 612/700\n",
      "12/12 - 0s - loss: 178.5405 - accuracy: 0.0000e+00 - val_loss: 129.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 613/700\n",
      "12/12 - 0s - loss: 177.7322 - accuracy: 0.0000e+00 - val_loss: 123.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 614/700\n",
      "12/12 - 0s - loss: 177.6669 - accuracy: 0.0000e+00 - val_loss: 121.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 615/700\n",
      "12/12 - 0s - loss: 178.0553 - accuracy: 0.0000e+00 - val_loss: 125.3621 - val_accuracy: 0.0000e+00\n",
      "Epoch 616/700\n",
      "12/12 - 0s - loss: 177.3931 - accuracy: 0.0000e+00 - val_loss: 128.9443 - val_accuracy: 0.0000e+00\n",
      "Epoch 617/700\n",
      "12/12 - 0s - loss: 177.6326 - accuracy: 0.0000e+00 - val_loss: 128.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 618/700\n",
      "12/12 - 0s - loss: 177.4959 - accuracy: 0.0000e+00 - val_loss: 124.3411 - val_accuracy: 0.0000e+00\n",
      "Epoch 619/700\n",
      "12/12 - 0s - loss: 177.4207 - accuracy: 0.0000e+00 - val_loss: 121.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 620/700\n",
      "12/12 - 0s - loss: 178.2964 - accuracy: 0.0000e+00 - val_loss: 122.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 621/700\n",
      "12/12 - 0s - loss: 177.7415 - accuracy: 0.0000e+00 - val_loss: 128.5811 - val_accuracy: 0.0000e+00\n",
      "Epoch 622/700\n",
      "12/12 - 0s - loss: 177.5258 - accuracy: 0.0000e+00 - val_loss: 130.1831 - val_accuracy: 0.0000e+00\n",
      "Epoch 623/700\n",
      "12/12 - 0s - loss: 177.9854 - accuracy: 0.0000e+00 - val_loss: 127.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 624/700\n",
      "12/12 - 0s - loss: 177.3301 - accuracy: 0.0000e+00 - val_loss: 122.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 625/700\n",
      "12/12 - 0s - loss: 177.8959 - accuracy: 0.0000e+00 - val_loss: 121.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 626/700\n",
      "12/12 - 0s - loss: 178.1292 - accuracy: 0.0000e+00 - val_loss: 125.3159 - val_accuracy: 0.0000e+00\n",
      "Epoch 627/700\n",
      "12/12 - 0s - loss: 177.3538 - accuracy: 0.0000e+00 - val_loss: 129.2993 - val_accuracy: 0.0000e+00\n",
      "Epoch 628/700\n",
      "12/12 - 0s - loss: 177.7280 - accuracy: 0.0000e+00 - val_loss: 129.1526 - val_accuracy: 0.0000e+00\n",
      "Epoch 629/700\n",
      "12/12 - 0s - loss: 177.6854 - accuracy: 0.0000e+00 - val_loss: 125.2837 - val_accuracy: 0.0000e+00\n",
      "Epoch 630/700\n",
      "12/12 - 0s - loss: 177.3438 - accuracy: 0.0000e+00 - val_loss: 122.2898 - val_accuracy: 0.0000e+00\n",
      "Epoch 631/700\n",
      "12/12 - 0s - loss: 177.7904 - accuracy: 0.0000e+00 - val_loss: 124.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 632/700\n",
      "12/12 - 0s - loss: 177.3798 - accuracy: 0.0000e+00 - val_loss: 126.2551 - val_accuracy: 0.0000e+00\n",
      "Epoch 633/700\n",
      "12/12 - 0s - loss: 177.2954 - accuracy: 0.0000e+00 - val_loss: 128.6731 - val_accuracy: 0.0000e+00\n",
      "Epoch 634/700\n",
      "12/12 - 0s - loss: 177.5447 - accuracy: 0.0000e+00 - val_loss: 127.0969 - val_accuracy: 0.0000e+00\n",
      "Epoch 635/700\n",
      "12/12 - 0s - loss: 177.2563 - accuracy: 0.0000e+00 - val_loss: 126.1702 - val_accuracy: 0.0000e+00\n",
      "Epoch 636/700\n",
      "12/12 - 0s - loss: 177.2877 - accuracy: 0.0000e+00 - val_loss: 125.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 637/700\n",
      "12/12 - 0s - loss: 177.2973 - accuracy: 0.0000e+00 - val_loss: 126.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 638/700\n",
      "12/12 - 0s - loss: 177.2874 - accuracy: 0.0000e+00 - val_loss: 126.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 639/700\n",
      "12/12 - 0s - loss: 177.2581 - accuracy: 0.0000e+00 - val_loss: 127.7622 - val_accuracy: 0.0000e+00\n",
      "Epoch 640/700\n",
      "12/12 - 0s - loss: 177.2789 - accuracy: 0.0000e+00 - val_loss: 124.9661 - val_accuracy: 0.0000e+00\n",
      "Epoch 641/700\n",
      "12/12 - 0s - loss: 177.3153 - accuracy: 0.0000e+00 - val_loss: 122.9431 - val_accuracy: 0.0000e+00\n",
      "Epoch 642/700\n",
      "12/12 - 0s - loss: 177.4720 - accuracy: 0.0000e+00 - val_loss: 125.6943 - val_accuracy: 0.0000e+00\n",
      "Epoch 643/700\n",
      "12/12 - 0s - loss: 177.2808 - accuracy: 0.0000e+00 - val_loss: 128.6692 - val_accuracy: 0.0000e+00\n",
      "Epoch 644/700\n",
      "12/12 - 0s - loss: 177.5373 - accuracy: 0.0000e+00 - val_loss: 127.5581 - val_accuracy: 0.0000e+00\n",
      "Epoch 645/700\n",
      "12/12 - 0s - loss: 177.2173 - accuracy: 0.0000e+00 - val_loss: 122.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 646/700\n",
      "12/12 - 0s - loss: 177.5018 - accuracy: 0.0000e+00 - val_loss: 123.0325 - val_accuracy: 0.0000e+00\n",
      "Epoch 647/700\n",
      "12/12 - 0s - loss: 177.3998 - accuracy: 0.0000e+00 - val_loss: 127.8672 - val_accuracy: 0.0000e+00\n",
      "Epoch 648/700\n",
      "12/12 - 0s - loss: 177.3043 - accuracy: 0.0000e+00 - val_loss: 128.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 649/700\n",
      "12/12 - 0s - loss: 177.4624 - accuracy: 0.0000e+00 - val_loss: 125.1118 - val_accuracy: 0.0000e+00\n",
      "Epoch 650/700\n",
      "12/12 - 0s - loss: 177.2772 - accuracy: 0.0000e+00 - val_loss: 122.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 651/700\n",
      "12/12 - 0s - loss: 177.5054 - accuracy: 0.0000e+00 - val_loss: 125.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 652/700\n",
      "12/12 - 0s - loss: 177.2742 - accuracy: 0.0000e+00 - val_loss: 127.6418 - val_accuracy: 0.0000e+00\n",
      "Epoch 653/700\n",
      "12/12 - 0s - loss: 177.2371 - accuracy: 0.0000e+00 - val_loss: 126.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 654/700\n",
      "12/12 - 0s - loss: 177.2214 - accuracy: 0.0000e+00 - val_loss: 125.4009 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/700\n",
      "12/12 - 0s - loss: 177.2475 - accuracy: 0.0000e+00 - val_loss: 125.1821 - val_accuracy: 0.0000e+00\n",
      "Epoch 656/700\n",
      "12/12 - 0s - loss: 177.2524 - accuracy: 0.0000e+00 - val_loss: 125.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 657/700\n",
      "12/12 - 0s - loss: 177.2367 - accuracy: 0.0000e+00 - val_loss: 126.2659 - val_accuracy: 0.0000e+00\n",
      "Epoch 658/700\n",
      "12/12 - 0s - loss: 177.2043 - accuracy: 0.0000e+00 - val_loss: 127.4688 - val_accuracy: 0.0000e+00\n",
      "Epoch 659/700\n",
      "12/12 - 0s - loss: 177.1840 - accuracy: 0.0000e+00 - val_loss: 124.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 660/700\n",
      "12/12 - 0s - loss: 177.2559 - accuracy: 0.0000e+00 - val_loss: 122.7302 - val_accuracy: 0.0000e+00\n",
      "Epoch 661/700\n",
      "12/12 - 0s - loss: 177.3870 - accuracy: 0.0000e+00 - val_loss: 125.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 662/700\n",
      "12/12 - 0s - loss: 177.2152 - accuracy: 0.0000e+00 - val_loss: 128.6851 - val_accuracy: 0.0000e+00\n",
      "Epoch 663/700\n",
      "12/12 - 0s - loss: 177.5312 - accuracy: 0.0000e+00 - val_loss: 127.6116 - val_accuracy: 0.0000e+00\n",
      "Epoch 664/700\n",
      "12/12 - 0s - loss: 177.2214 - accuracy: 0.0000e+00 - val_loss: 122.7874 - val_accuracy: 0.0000e+00\n",
      "Epoch 665/700\n",
      "12/12 - 0s - loss: 177.3342 - accuracy: 0.0000e+00 - val_loss: 123.1069 - val_accuracy: 0.0000e+00\n",
      "Epoch 666/700\n",
      "12/12 - 0s - loss: 177.2940 - accuracy: 0.0000e+00 - val_loss: 123.9016 - val_accuracy: 0.0000e+00\n",
      "Epoch 667/700\n",
      "12/12 - 0s - loss: 177.2606 - accuracy: 0.0000e+00 - val_loss: 125.1260 - val_accuracy: 0.0000e+00\n",
      "Epoch 668/700\n",
      "12/12 - 0s - loss: 177.2109 - accuracy: 0.0000e+00 - val_loss: 126.7341 - val_accuracy: 0.0000e+00\n",
      "Epoch 669/700\n",
      "12/12 - 0s - loss: 177.1462 - accuracy: 0.0000e+00 - val_loss: 128.6914 - val_accuracy: 0.0000e+00\n",
      "Epoch 670/700\n",
      "12/12 - 0s - loss: 177.5290 - accuracy: 0.0000e+00 - val_loss: 126.5767 - val_accuracy: 0.0000e+00\n",
      "Epoch 671/700\n",
      "12/12 - 0s - loss: 177.1449 - accuracy: 0.0000e+00 - val_loss: 125.1785 - val_accuracy: 0.0000e+00\n",
      "Epoch 672/700\n",
      "12/12 - 0s - loss: 177.1947 - accuracy: 0.0000e+00 - val_loss: 124.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 673/700\n",
      "12/12 - 0s - loss: 177.2192 - accuracy: 0.0000e+00 - val_loss: 124.2649 - val_accuracy: 0.0000e+00\n",
      "Epoch 674/700\n",
      "12/12 - 0s - loss: 177.2212 - accuracy: 0.0000e+00 - val_loss: 124.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 675/700\n",
      "12/12 - 0s - loss: 177.2044 - accuracy: 0.0000e+00 - val_loss: 125.4639 - val_accuracy: 0.0000e+00\n",
      "Epoch 676/700\n",
      "12/12 - 0s - loss: 177.1702 - accuracy: 0.0000e+00 - val_loss: 126.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 677/700\n",
      "12/12 - 0s - loss: 177.1185 - accuracy: 0.0000e+00 - val_loss: 128.3796 - val_accuracy: 0.0000e+00\n",
      "Epoch 678/700\n",
      "12/12 - 0s - loss: 177.4343 - accuracy: 0.0000e+00 - val_loss: 125.9595 - val_accuracy: 0.0000e+00\n",
      "Epoch 679/700\n",
      "12/12 - 0s - loss: 177.1400 - accuracy: 0.0000e+00 - val_loss: 124.2898 - val_accuracy: 0.0000e+00\n",
      "Epoch 680/700\n",
      "12/12 - 0s - loss: 177.1998 - accuracy: 0.0000e+00 - val_loss: 123.2998 - val_accuracy: 0.0000e+00\n",
      "Epoch 681/700\n",
      "12/12 - 0s - loss: 177.2342 - accuracy: 0.0000e+00 - val_loss: 122.9221 - val_accuracy: 0.0000e+00\n",
      "Epoch 682/700\n",
      "12/12 - 0s - loss: 177.2446 - accuracy: 0.0000e+00 - val_loss: 123.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 683/700\n",
      "12/12 - 0s - loss: 177.2349 - accuracy: 0.0000e+00 - val_loss: 123.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 684/700\n",
      "12/12 - 0s - loss: 177.2059 - accuracy: 0.0000e+00 - val_loss: 124.8884 - val_accuracy: 0.0000e+00\n",
      "Epoch 685/700\n",
      "12/12 - 0s - loss: 177.1604 - accuracy: 0.0000e+00 - val_loss: 126.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 686/700\n",
      "12/12 - 0s - loss: 177.0994 - accuracy: 0.0000e+00 - val_loss: 128.3040 - val_accuracy: 0.0000e+00\n",
      "Epoch 687/700\n",
      "12/12 - 0s - loss: 177.4078 - accuracy: 0.0000e+00 - val_loss: 126.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 688/700\n",
      "12/12 - 0s - loss: 177.1047 - accuracy: 0.0000e+00 - val_loss: 124.5605 - val_accuracy: 0.0000e+00\n",
      "Epoch 689/700\n",
      "12/12 - 0s - loss: 177.1589 - accuracy: 0.0000e+00 - val_loss: 123.7263 - val_accuracy: 0.0000e+00\n",
      "Epoch 690/700\n",
      "12/12 - 0s - loss: 177.1866 - accuracy: 0.0000e+00 - val_loss: 123.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 691/700\n",
      "12/12 - 0s - loss: 177.1917 - accuracy: 0.0000e+00 - val_loss: 123.7996 - val_accuracy: 0.0000e+00\n",
      "Epoch 692/700\n",
      "12/12 - 0s - loss: 177.1768 - accuracy: 0.0000e+00 - val_loss: 124.5962 - val_accuracy: 0.0000e+00\n",
      "Epoch 693/700\n",
      "12/12 - 0s - loss: 177.1434 - accuracy: 0.0000e+00 - val_loss: 125.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 694/700\n",
      "12/12 - 0s - loss: 177.0933 - accuracy: 0.0000e+00 - val_loss: 127.4700 - val_accuracy: 0.0000e+00\n",
      "Epoch 695/700\n",
      "12/12 - 0s - loss: 177.1634 - accuracy: 0.0000e+00 - val_loss: 124.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 696/700\n",
      "12/12 - 0s - loss: 177.1188 - accuracy: 0.0000e+00 - val_loss: 123.2371 - val_accuracy: 0.0000e+00\n",
      "Epoch 697/700\n",
      "12/12 - 0s - loss: 177.1813 - accuracy: 0.0000e+00 - val_loss: 122.1975 - val_accuracy: 0.0000e+00\n",
      "Epoch 698/700\n",
      "12/12 - 0s - loss: 177.2756 - accuracy: 0.0000e+00 - val_loss: 126.0776 - val_accuracy: 0.0000e+00\n",
      "Epoch 699/700\n",
      "12/12 - 0s - loss: 177.0666 - accuracy: 0.0000e+00 - val_loss: 130.0955 - val_accuracy: 0.0000e+00\n",
      "Epoch 700/700\n",
      "12/12 - 0s - loss: 177.9156 - accuracy: 0.0000e+00 - val_loss: 129.7229 - val_accuracy: 0.0000e+00\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = horsepower_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=700,\n",
    "    # suppress logging\n",
    "    verbose=2,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# history = horsepower_model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=90,\n",
    "#     # suppress logging\n",
    "#     verbose=2,\n",
    "#     # Calculate validation results on 20% of the training data\n",
    "#     validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: yellow\\assets\n"
     ]
    }
   ],
   "source": [
    "#pickle.dump(horsepower_model, open(\"model.pkl\", \"wb\"))\n",
    "horsepower_model.save(\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.509787\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict([[23, 24]])\n",
    "print(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = horsepower_model.predict(X)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plt = test['Last'].reset_index()\n",
    "plt.plot(test_plt, c='purple')\n",
    "plt.plot(predict, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oSaver = tf.train.Saver()\n",
    "\n",
    "#oSess = oSession\n",
    "#oSaver.save(oSess, sModelPath)  #filename ends with .ckpt\n",
    "\n",
    "pickle.dump(horsepower_model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FaceRec]",
   "language": "python",
   "name": "conda-env-FaceRec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
