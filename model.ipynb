{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "import seaborn as sns\n",
    "from keras.layers import Input,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>515.00</td>\n",
       "      <td>453.16</td>\n",
       "      <td>499.01</td>\n",
       "      <td>500.01</td>\n",
       "      <td>505.04</td>\n",
       "      <td>28535.844106</td>\n",
       "      <td>491.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>548.00</td>\n",
       "      <td>494.02</td>\n",
       "      <td>534.00</td>\n",
       "      <td>535.01</td>\n",
       "      <td>536.00</td>\n",
       "      <td>31159.941300</td>\n",
       "      <td>520.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>537.24</td>\n",
       "      <td>481.63</td>\n",
       "      <td>506.52</td>\n",
       "      <td>504.70</td>\n",
       "      <td>505.38</td>\n",
       "      <td>21126.375080</td>\n",
       "      <td>504.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>508.43</td>\n",
       "      <td>470.00</td>\n",
       "      <td>487.00</td>\n",
       "      <td>484.14</td>\n",
       "      <td>487.00</td>\n",
       "      <td>11879.484756</td>\n",
       "      <td>485.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>507.43</td>\n",
       "      <td>472.81</td>\n",
       "      <td>504.74</td>\n",
       "      <td>504.74</td>\n",
       "      <td>505.00</td>\n",
       "      <td>10262.195861</td>\n",
       "      <td>492.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>2378</td>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>16494.52</td>\n",
       "      <td>15970.33</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16339.27</td>\n",
       "      <td>7842.488826</td>\n",
       "      <td>16279.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>2379</td>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>16341.89</td>\n",
       "      <td>15715.10</td>\n",
       "      <td>16086.34</td>\n",
       "      <td>16087.77</td>\n",
       "      <td>16094.81</td>\n",
       "      <td>5046.326705</td>\n",
       "      <td>15982.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>2380</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>16170.00</td>\n",
       "      <td>15786.46</td>\n",
       "      <td>15975.49</td>\n",
       "      <td>15969.41</td>\n",
       "      <td>15973.22</td>\n",
       "      <td>3226.276565</td>\n",
       "      <td>15979.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>2381</td>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>16894.93</td>\n",
       "      <td>15875.50</td>\n",
       "      <td>16724.62</td>\n",
       "      <td>16719.84</td>\n",
       "      <td>16729.63</td>\n",
       "      <td>7511.143605</td>\n",
       "      <td>16409.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>2382</td>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>17868.00</td>\n",
       "      <td>16570.00</td>\n",
       "      <td>17681.77</td>\n",
       "      <td>17670.67</td>\n",
       "      <td>17680.50</td>\n",
       "      <td>9824.899652</td>\n",
       "      <td>17260.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2383 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        Date      High       Low      Last       Bid       Ask  \\\n",
       "0         0  2014-04-15    515.00    453.16    499.01    500.01    505.04   \n",
       "1         1  2014-04-16    548.00    494.02    534.00    535.01    536.00   \n",
       "2         2  2014-04-17    537.24    481.63    506.52    504.70    505.38   \n",
       "3         3  2014-04-18    508.43    470.00    487.00    484.14    487.00   \n",
       "4         4  2014-04-19    507.43    472.81    504.74    504.74    505.00   \n",
       "...     ...         ...       ...       ...       ...       ...       ...   \n",
       "2378   2378  2020-11-14  16494.52  15970.33  16335.58  16335.58  16339.27   \n",
       "2379   2379  2020-11-15  16341.89  15715.10  16086.34  16087.77  16094.81   \n",
       "2380   2380  2020-11-16  16170.00  15786.46  15975.49  15969.41  15973.22   \n",
       "2381   2381  2020-11-17  16894.93  15875.50  16724.62  16719.84  16729.63   \n",
       "2382   2382  2020-11-18  17868.00  16570.00  17681.77  17670.67  17680.50   \n",
       "\n",
       "            Volume      VWAP  \n",
       "0     28535.844106    491.41  \n",
       "1     31159.941300    520.21  \n",
       "2     21126.375080    504.83  \n",
       "3     11879.484756    485.72  \n",
       "4     10262.195861    492.22  \n",
       "...            ...       ...  \n",
       "2378   7842.488826  16279.18  \n",
       "2379   5046.326705  15982.98  \n",
       "2380   3226.276565  15979.39  \n",
       "2381   7511.143605  16409.99  \n",
       "2382   9824.899652  17260.21  \n",
       "\n",
       "[2383 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bitcoin_data.csv')\n",
    "data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>13650.00</td>\n",
       "      <td>12993.00</td>\n",
       "      <td>13411.86</td>\n",
       "      <td>13413.35</td>\n",
       "      <td>13416.39</td>\n",
       "      <td>8948.197381</td>\n",
       "      <td>13318.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>13675.56</td>\n",
       "      <td>13129.26</td>\n",
       "      <td>13577.60</td>\n",
       "      <td>13572.18</td>\n",
       "      <td>13581.82</td>\n",
       "      <td>8980.671631</td>\n",
       "      <td>13404.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>14100.00</td>\n",
       "      <td>13420.97</td>\n",
       "      <td>13879.14</td>\n",
       "      <td>13878.39</td>\n",
       "      <td>13887.22</td>\n",
       "      <td>6394.173016</td>\n",
       "      <td>13762.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>13907.47</td>\n",
       "      <td>13629.31</td>\n",
       "      <td>13711.21</td>\n",
       "      <td>13700.59</td>\n",
       "      <td>13711.21</td>\n",
       "      <td>2465.795017</td>\n",
       "      <td>13766.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>13842.50</td>\n",
       "      <td>13220.00</td>\n",
       "      <td>13563.72</td>\n",
       "      <td>13570.69</td>\n",
       "      <td>13578.98</td>\n",
       "      <td>7062.704712</td>\n",
       "      <td>13545.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>14083.76</td>\n",
       "      <td>13287.70</td>\n",
       "      <td>14041.58</td>\n",
       "      <td>14030.89</td>\n",
       "      <td>14041.58</td>\n",
       "      <td>7226.516356</td>\n",
       "      <td>13633.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>14277.50</td>\n",
       "      <td>13520.87</td>\n",
       "      <td>14160.59</td>\n",
       "      <td>14162.68</td>\n",
       "      <td>14171.73</td>\n",
       "      <td>10925.676805</td>\n",
       "      <td>13908.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>15770.58</td>\n",
       "      <td>14100.00</td>\n",
       "      <td>15605.04</td>\n",
       "      <td>15603.49</td>\n",
       "      <td>15608.32</td>\n",
       "      <td>18422.631860</td>\n",
       "      <td>14937.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>15968.98</td>\n",
       "      <td>15196.01</td>\n",
       "      <td>15598.09</td>\n",
       "      <td>15598.10</td>\n",
       "      <td>15603.23</td>\n",
       "      <td>13479.467068</td>\n",
       "      <td>15570.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>15778.60</td>\n",
       "      <td>14351.00</td>\n",
       "      <td>14838.97</td>\n",
       "      <td>14832.01</td>\n",
       "      <td>14842.70</td>\n",
       "      <td>10933.924192</td>\n",
       "      <td>15076.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>15664.90</td>\n",
       "      <td>14727.19</td>\n",
       "      <td>15489.15</td>\n",
       "      <td>15480.45</td>\n",
       "      <td>15490.09</td>\n",
       "      <td>5046.499164</td>\n",
       "      <td>15255.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>15854.48</td>\n",
       "      <td>14824.66</td>\n",
       "      <td>15332.04</td>\n",
       "      <td>15335.50</td>\n",
       "      <td>15348.95</td>\n",
       "      <td>14466.079537</td>\n",
       "      <td>15364.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>15482.76</td>\n",
       "      <td>15092.47</td>\n",
       "      <td>15313.65</td>\n",
       "      <td>15313.87</td>\n",
       "      <td>15317.81</td>\n",
       "      <td>8966.481714</td>\n",
       "      <td>15325.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>15991.01</td>\n",
       "      <td>15290.85</td>\n",
       "      <td>15702.00</td>\n",
       "      <td>15696.48</td>\n",
       "      <td>15703.40</td>\n",
       "      <td>10014.264272</td>\n",
       "      <td>15652.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>16369.99</td>\n",
       "      <td>15481.00</td>\n",
       "      <td>16300.00</td>\n",
       "      <td>16297.91</td>\n",
       "      <td>16300.00</td>\n",
       "      <td>16261.206579</td>\n",
       "      <td>15939.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>16494.52</td>\n",
       "      <td>15970.33</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16339.27</td>\n",
       "      <td>7842.488826</td>\n",
       "      <td>16279.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>16341.89</td>\n",
       "      <td>15715.10</td>\n",
       "      <td>16086.34</td>\n",
       "      <td>16087.77</td>\n",
       "      <td>16094.81</td>\n",
       "      <td>5046.326705</td>\n",
       "      <td>15982.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>16170.00</td>\n",
       "      <td>15786.46</td>\n",
       "      <td>15975.49</td>\n",
       "      <td>15969.41</td>\n",
       "      <td>15973.22</td>\n",
       "      <td>3226.276565</td>\n",
       "      <td>15979.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>16894.93</td>\n",
       "      <td>15875.50</td>\n",
       "      <td>16724.62</td>\n",
       "      <td>16719.84</td>\n",
       "      <td>16729.63</td>\n",
       "      <td>7511.143605</td>\n",
       "      <td>16409.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>17868.00</td>\n",
       "      <td>16570.00</td>\n",
       "      <td>17681.77</td>\n",
       "      <td>17670.67</td>\n",
       "      <td>17680.50</td>\n",
       "      <td>9824.899652</td>\n",
       "      <td>17260.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          High       Low      Last       Bid       Ask        Volume      VWAP\n",
       "2363  13650.00  12993.00  13411.86  13413.35  13416.39   8948.197381  13318.04\n",
       "2364  13675.56  13129.26  13577.60  13572.18  13581.82   8980.671631  13404.59\n",
       "2365  14100.00  13420.97  13879.14  13878.39  13887.22   6394.173016  13762.10\n",
       "2366  13907.47  13629.31  13711.21  13700.59  13711.21   2465.795017  13766.72\n",
       "2367  13842.50  13220.00  13563.72  13570.69  13578.98   7062.704712  13545.15\n",
       "2368  14083.76  13287.70  14041.58  14030.89  14041.58   7226.516356  13633.01\n",
       "2369  14277.50  13520.87  14160.59  14162.68  14171.73  10925.676805  13908.16\n",
       "2370  15770.58  14100.00  15605.04  15603.49  15608.32  18422.631860  14937.25\n",
       "2371  15968.98  15196.01  15598.09  15598.10  15603.23  13479.467068  15570.55\n",
       "2372  15778.60  14351.00  14838.97  14832.01  14842.70  10933.924192  15076.99\n",
       "2373  15664.90  14727.19  15489.15  15480.45  15490.09   5046.499164  15255.08\n",
       "2374  15854.48  14824.66  15332.04  15335.50  15348.95  14466.079537  15364.34\n",
       "2375  15482.76  15092.47  15313.65  15313.87  15317.81   8966.481714  15325.34\n",
       "2376  15991.01  15290.85  15702.00  15696.48  15703.40  10014.264272  15652.52\n",
       "2377  16369.99  15481.00  16300.00  16297.91  16300.00  16261.206579  15939.46\n",
       "2378  16494.52  15970.33  16335.58  16335.58  16339.27   7842.488826  16279.18\n",
       "2379  16341.89  15715.10  16086.34  16087.77  16094.81   5046.326705  15982.98\n",
       "2380  16170.00  15786.46  15975.49  15969.41  15973.22   3226.276565  15979.39\n",
       "2381  16894.93  15875.50  16724.62  16719.84  16729.63   7511.143605  16409.99\n",
       "2382  17868.00  16570.00  17681.77  17670.67  17680.50   9824.899652  17260.21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.tail(20)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "High = test.High.values\n",
    "Low = test.Low.values\n",
    "Volume = test.Volume.values\n",
    "Last = test.Last.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13650.  , 12993.  ],\n",
       "       [13675.56, 13129.26],\n",
       "       [14100.  , 13420.97],\n",
       "       [13907.47, 13629.31],\n",
       "       [13842.5 , 13220.  ],\n",
       "       [14083.76, 13287.7 ],\n",
       "       [14277.5 , 13520.87],\n",
       "       [15770.58, 14100.  ],\n",
       "       [15968.98, 15196.01],\n",
       "       [15778.6 , 14351.  ],\n",
       "       [15664.9 , 14727.19],\n",
       "       [15854.48, 14824.66],\n",
       "       [15482.76, 15092.47],\n",
       "       [15991.01, 15290.85],\n",
       "       [16369.99, 15481.  ],\n",
       "       [16494.52, 15970.33],\n",
       "       [16341.89, 15715.1 ],\n",
       "       [16170.  , 15786.46],\n",
       "       [16894.93, 15875.5 ],\n",
       "       [17868.  , 16570.  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(High)):\n",
    "    row = []\n",
    "    yrow = []\n",
    "    row.append(High[i])\n",
    "    row.append(Low[i])\n",
    "#     row.append(Volume[i])\n",
    "    yrow.append(Last[i])\n",
    "    X.append(row)\n",
    "    y.append(yrow)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower = np.array(X_train)\n",
    "horsepower2 = np.array(X_train)\n",
    "horsepower_normalizer = preprocessing.Normalization(input_shape=[1,])\n",
    "horsepower_normalizer.adapt(horsepower)\n",
    "horsepower_normalizer2 = preprocessing.Normalization(input_shape=[1,])\n",
    "horsepower_normalizer2.adapt(horsepower2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input_layer = Input(shape=(X.shape[1],))\n",
    "# dense_layer_1 = Dense(100, input_shape=(X.shape[1],), activation='relu')\n",
    "# dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "# dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "# output = Dense(1)\n",
    "\n",
    "# model = Model([\n",
    "#     Dense(100, input_dim=X.shape[1], activation='relu'),\n",
    "#     Dense(50, activation='relu'),\n",
    "#     Dense(25, activation='relu'),\n",
    "#     Dense(units=1, activation='softmax')\n",
    "# ])\n",
    "# model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "horsepower_model = tf.keras.Sequential([\n",
    "#     horsepower_normalizer,\n",
    "    layers.Dense(50, activation='relu', input_dim=2),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(25, activation='relu'),\n",
    "    layers.Dense(units=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1047.5471],\n",
       "       [ 861.4209],\n",
       "       [1097.2865],\n",
       "       [ 999.3417]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horsepower_model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 4 samples\n",
      "Epoch 1/90\n",
      "12/12 - 1s - loss: 5034.3350 - accuracy: 0.0000e+00 - val_loss: 4707.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/90\n",
      "12/12 - 0s - loss: 4913.6450 - accuracy: 0.0000e+00 - val_loss: 4588.1885 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/90\n",
      "12/12 - 0s - loss: 4793.1641 - accuracy: 0.0000e+00 - val_loss: 4469.3262 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/90\n",
      "12/12 - 0s - loss: 4675.0469 - accuracy: 0.0000e+00 - val_loss: 4354.5791 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/90\n",
      "12/12 - 0s - loss: 4558.0601 - accuracy: 0.0000e+00 - val_loss: 4239.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/90\n",
      "12/12 - 0s - loss: 4440.2554 - accuracy: 0.0000e+00 - val_loss: 4122.3623 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/90\n",
      "12/12 - 0s - loss: 4321.3335 - accuracy: 0.0000e+00 - val_loss: 4009.0364 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/90\n",
      "12/12 - 0s - loss: 4203.0273 - accuracy: 0.0000e+00 - val_loss: 3896.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/90\n",
      "12/12 - 0s - loss: 4087.0498 - accuracy: 0.0000e+00 - val_loss: 3782.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/90\n",
      "12/12 - 0s - loss: 3970.7878 - accuracy: 0.0000e+00 - val_loss: 3666.9368 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/90\n",
      "12/12 - 0s - loss: 3853.5156 - accuracy: 0.0000e+00 - val_loss: 3550.7759 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/90\n",
      "12/12 - 0s - loss: 3735.3401 - accuracy: 0.0000e+00 - val_loss: 3433.7688 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/90\n",
      "12/12 - 0s - loss: 3616.2375 - accuracy: 0.0000e+00 - val_loss: 3315.9556 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/90\n",
      "12/12 - 0s - loss: 3496.1768 - accuracy: 0.0000e+00 - val_loss: 3197.1726 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/90\n",
      "12/12 - 0s - loss: 3375.1230 - accuracy: 0.0000e+00 - val_loss: 3077.3982 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/90\n",
      "12/12 - 0s - loss: 3253.0588 - accuracy: 0.0000e+00 - val_loss: 2956.6206 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/90\n",
      "12/12 - 0s - loss: 3129.9729 - accuracy: 0.0000e+00 - val_loss: 2834.8250 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/90\n",
      "12/12 - 0s - loss: 3005.8477 - accuracy: 0.0000e+00 - val_loss: 2711.9912 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/90\n",
      "12/12 - 0s - loss: 2880.6660 - accuracy: 0.0000e+00 - val_loss: 2588.1045 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/90\n",
      "12/12 - 0s - loss: 2754.4287 - accuracy: 0.0000e+00 - val_loss: 2463.1472 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/90\n",
      "12/12 - 0s - loss: 2627.0845 - accuracy: 0.0000e+00 - val_loss: 2337.1042 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/90\n",
      "12/12 - 0s - loss: 2498.6741 - accuracy: 0.0000e+00 - val_loss: 2209.9626 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/90\n",
      "12/12 - 0s - loss: 2369.1663 - accuracy: 0.0000e+00 - val_loss: 2081.7139 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/90\n",
      "12/12 - 0s - loss: 2238.5608 - accuracy: 0.0000e+00 - val_loss: 1952.3369 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/90\n",
      "12/12 - 0s - loss: 2106.7725 - accuracy: 0.0000e+00 - val_loss: 1821.8120 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/90\n",
      "12/12 - 0s - loss: 1973.7803 - accuracy: 0.0000e+00 - val_loss: 1690.1169 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/90\n",
      "12/12 - 0s - loss: 1839.5677 - accuracy: 0.0000e+00 - val_loss: 1557.2312 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/90\n",
      "12/12 - 0s - loss: 1704.1162 - accuracy: 0.0000e+00 - val_loss: 1423.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/90\n",
      "12/12 - 0s - loss: 1567.4039 - accuracy: 0.0000e+00 - val_loss: 1287.8511 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/90\n",
      "12/12 - 0s - loss: 1429.4131 - accuracy: 0.0000e+00 - val_loss: 1151.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/90\n",
      "12/12 - 0s - loss: 1290.2643 - accuracy: 0.0000e+00 - val_loss: 1015.2957 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/90\n",
      "12/12 - 0s - loss: 1149.9203 - accuracy: 0.0000e+00 - val_loss: 877.1631 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/90\n",
      "12/12 - 0s - loss: 1008.4423 - accuracy: 0.0000e+00 - val_loss: 737.2615 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/90\n",
      "12/12 - 0s - loss: 865.6783 - accuracy: 0.0000e+00 - val_loss: 595.5488 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/90\n",
      "12/12 - 0s - loss: 721.5676 - accuracy: 0.0000e+00 - val_loss: 452.3289 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/90\n",
      "12/12 - 0s - loss: 576.2267 - accuracy: 0.0000e+00 - val_loss: 307.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/90\n",
      "12/12 - 0s - loss: 429.5120 - accuracy: 0.0000e+00 - val_loss: 162.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/90\n",
      "12/12 - 0s - loss: 301.1136 - accuracy: 0.0000e+00 - val_loss: 55.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/90\n",
      "12/12 - 0s - loss: 189.8689 - accuracy: 0.0000e+00 - val_loss: 122.0498 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/90\n",
      "12/12 - 0s - loss: 188.3154 - accuracy: 0.0000e+00 - val_loss: 243.5925 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/90\n",
      "12/12 - 0s - loss: 214.8203 - accuracy: 0.0000e+00 - val_loss: 343.3267 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/90\n",
      "12/12 - 0s - loss: 275.9622 - accuracy: 0.0000e+00 - val_loss: 416.2646 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/90\n",
      "12/12 - 0s - loss: 337.6179 - accuracy: 0.0000e+00 - val_loss: 465.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/90\n",
      "12/12 - 0s - loss: 379.0198 - accuracy: 0.0000e+00 - val_loss: 492.8652 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/90\n",
      "12/12 - 0s - loss: 402.2745 - accuracy: 0.0000e+00 - val_loss: 501.4236 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/90\n",
      "12/12 - 0s - loss: 409.3672 - accuracy: 0.0000e+00 - val_loss: 492.9685 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/90\n",
      "12/12 - 0s - loss: 402.0444 - accuracy: 0.0000e+00 - val_loss: 469.3569 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/90\n",
      "12/12 - 0s - loss: 381.8690 - accuracy: 0.0000e+00 - val_loss: 432.2878 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/90\n",
      "12/12 - 0s - loss: 350.2677 - accuracy: 0.0000e+00 - val_loss: 383.2773 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/90\n",
      "12/12 - 0s - loss: 308.5426 - accuracy: 0.0000e+00 - val_loss: 323.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/90\n",
      "12/12 - 0s - loss: 259.5848 - accuracy: 0.0000e+00 - val_loss: 257.3215 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/90\n",
      "12/12 - 0s - loss: 221.0590 - accuracy: 0.0000e+00 - val_loss: 187.9373 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/90\n",
      "12/12 - 0s - loss: 200.5970 - accuracy: 0.0000e+00 - val_loss: 121.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/90\n",
      "12/12 - 0s - loss: 188.6580 - accuracy: 0.0000e+00 - val_loss: 58.2627 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/90\n",
      "12/12 - 0s - loss: 180.9660 - accuracy: 0.0000e+00 - val_loss: 53.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/90\n",
      "12/12 - 0s - loss: 183.7839 - accuracy: 0.0000e+00 - val_loss: 70.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/90\n",
      "12/12 - 0s - loss: 205.8767 - accuracy: 0.0000e+00 - val_loss: 85.5037 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/90\n",
      "12/12 - 0s - loss: 228.5330 - accuracy: 0.0000e+00 - val_loss: 90.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/90\n",
      "12/12 - 0s - loss: 236.5435 - accuracy: 0.0000e+00 - val_loss: 86.5425 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/90\n",
      "12/12 - 0s - loss: 230.2703 - accuracy: 0.0000e+00 - val_loss: 74.6167 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/90\n",
      "12/12 - 0s - loss: 211.2341 - accuracy: 0.0000e+00 - val_loss: 57.1733 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/90\n",
      "12/12 - 0s - loss: 192.8682 - accuracy: 0.0000e+00 - val_loss: 53.5327 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/90\n",
      "12/12 - 0s - loss: 180.0286 - accuracy: 0.0000e+00 - val_loss: 54.1187 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/90\n",
      "12/12 - 0s - loss: 180.8456 - accuracy: 0.0000e+00 - val_loss: 84.5457 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/90\n",
      "12/12 - 0s - loss: 181.9577 - accuracy: 0.0000e+00 - val_loss: 109.4717 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/90\n",
      "12/12 - 0s - loss: 186.4475 - accuracy: 0.0000e+00 - val_loss: 128.5127 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/90\n",
      "12/12 - 0s - loss: 189.8818 - accuracy: 0.0000e+00 - val_loss: 142.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/90\n",
      "12/12 - 0s - loss: 192.3528 - accuracy: 0.0000e+00 - val_loss: 150.9907 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/90\n",
      "12/12 - 0s - loss: 193.9427 - accuracy: 0.0000e+00 - val_loss: 155.3206 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/90\n",
      "12/12 - 0s - loss: 194.7291 - accuracy: 0.0000e+00 - val_loss: 155.5752 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/90\n",
      "12/12 - 0s - loss: 194.7812 - accuracy: 0.0000e+00 - val_loss: 152.1135 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/90\n",
      "12/12 - 0s - loss: 194.1648 - accuracy: 0.0000e+00 - val_loss: 145.2615 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/90\n",
      "12/12 - 0s - loss: 192.9365 - accuracy: 0.0000e+00 - val_loss: 135.3169 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/90\n",
      "12/12 - 0s - loss: 191.1523 - accuracy: 0.0000e+00 - val_loss: 122.5537 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/90\n",
      "12/12 - 0s - loss: 188.8608 - accuracy: 0.0000e+00 - val_loss: 107.2200 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/90\n",
      "12/12 - 0s - loss: 186.0949 - accuracy: 0.0000e+00 - val_loss: 89.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/90\n",
      "12/12 - 0s - loss: 182.8962 - accuracy: 0.0000e+00 - val_loss: 69.6750 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/90\n",
      "12/12 - 0s - loss: 180.9893 - accuracy: 0.0000e+00 - val_loss: 52.5361 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/90\n",
      "12/12 - 0s - loss: 180.5038 - accuracy: 0.0000e+00 - val_loss: 52.6125 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/90\n",
      "12/12 - 0s - loss: 180.0352 - accuracy: 0.0000e+00 - val_loss: 52.6650 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/90\n",
      "12/12 - 0s - loss: 179.5389 - accuracy: 0.0000e+00 - val_loss: 52.6897 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/90\n",
      "12/12 - 0s - loss: 182.0052 - accuracy: 0.0000e+00 - val_loss: 52.7417 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/90\n",
      "12/12 - 0s - loss: 184.1242 - accuracy: 0.0000e+00 - val_loss: 52.7249 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/90\n",
      "12/12 - 0s - loss: 183.5784 - accuracy: 0.0000e+00 - val_loss: 52.6460 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/90\n",
      "12/12 - 0s - loss: 180.6166 - accuracy: 0.0000e+00 - val_loss: 52.5085 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/90\n",
      "12/12 - 0s - loss: 179.1347 - accuracy: 0.0000e+00 - val_loss: 52.3879 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/90\n",
      "12/12 - 0s - loss: 179.4221 - accuracy: 0.0000e+00 - val_loss: 52.2825 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/90\n",
      "12/12 - 0s - loss: 179.6743 - accuracy: 0.0000e+00 - val_loss: 55.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/90\n",
      "12/12 - 0s - loss: 179.9025 - accuracy: 0.0000e+00 - val_loss: 63.4971 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/90\n",
      "12/12 - 0s - loss: 180.0953 - accuracy: 0.0000e+00 - val_loss: 70.4946 - val_accuracy: 0.0000e+00\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = horsepower_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=90,\n",
    "    # suppress logging\n",
    "    verbose=2,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>179.134689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.387939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>179.422119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.282471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>179.674316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.173828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>179.902512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.497070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>180.095291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.494629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss  accuracy   val_loss  val_accuracy  epoch\n",
       "85  179.134689       0.0  52.387939           0.0     85\n",
       "86  179.422119       0.0  52.282471           0.0     86\n",
       "87  179.674316       0.0  55.173828           0.0     87\n",
       "88  179.902512       0.0  63.497070           0.0     88\n",
       "89  180.095291       0.0  70.494629           0.0     89"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13638.807]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = horsepower_model.predict([[13842.50,13220.00]])\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a7a54a55c8>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_plt = test['Last'].reset_index().drop(columns='index')\n",
    "plt.plot(test_plt, c='purple')\n",
    "plt.plot(predict, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.train' has no attribute 'Saver'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-9f2748e10069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moSaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moSess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moSaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moSess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msModelPath\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#filename ends with .ckpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.train' has no attribute 'Saver'"
     ]
    }
   ],
   "source": [
    "oSaver = tf.train.Saver()\n",
    "\n",
    "oSess = oSession\n",
    "oSaver.save(oSess, sModelPath)  #filename ends with .ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FaceRec]",
   "language": "python",
   "name": "conda-env-FaceRec-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
