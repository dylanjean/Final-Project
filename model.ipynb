{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "import seaborn as sns\n",
    "from keras.layers import Input,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>515.00</td>\n",
       "      <td>453.16</td>\n",
       "      <td>499.01</td>\n",
       "      <td>500.01</td>\n",
       "      <td>505.04</td>\n",
       "      <td>28535.844106</td>\n",
       "      <td>491.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>548.00</td>\n",
       "      <td>494.02</td>\n",
       "      <td>534.00</td>\n",
       "      <td>535.01</td>\n",
       "      <td>536.00</td>\n",
       "      <td>31159.941300</td>\n",
       "      <td>520.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>537.24</td>\n",
       "      <td>481.63</td>\n",
       "      <td>506.52</td>\n",
       "      <td>504.70</td>\n",
       "      <td>505.38</td>\n",
       "      <td>21126.375080</td>\n",
       "      <td>504.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>508.43</td>\n",
       "      <td>470.00</td>\n",
       "      <td>487.00</td>\n",
       "      <td>484.14</td>\n",
       "      <td>487.00</td>\n",
       "      <td>11879.484756</td>\n",
       "      <td>485.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>507.43</td>\n",
       "      <td>472.81</td>\n",
       "      <td>504.74</td>\n",
       "      <td>504.74</td>\n",
       "      <td>505.00</td>\n",
       "      <td>10262.195861</td>\n",
       "      <td>492.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>2378</td>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>16494.52</td>\n",
       "      <td>15970.33</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16339.27</td>\n",
       "      <td>7842.488826</td>\n",
       "      <td>16279.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>2379</td>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>16341.89</td>\n",
       "      <td>15715.10</td>\n",
       "      <td>16086.34</td>\n",
       "      <td>16087.77</td>\n",
       "      <td>16094.81</td>\n",
       "      <td>5046.326705</td>\n",
       "      <td>15982.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>2380</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>16170.00</td>\n",
       "      <td>15786.46</td>\n",
       "      <td>15975.49</td>\n",
       "      <td>15969.41</td>\n",
       "      <td>15973.22</td>\n",
       "      <td>3226.276565</td>\n",
       "      <td>15979.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>2381</td>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>16894.93</td>\n",
       "      <td>15875.50</td>\n",
       "      <td>16724.62</td>\n",
       "      <td>16719.84</td>\n",
       "      <td>16729.63</td>\n",
       "      <td>7511.143605</td>\n",
       "      <td>16409.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>2382</td>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>17868.00</td>\n",
       "      <td>16570.00</td>\n",
       "      <td>17681.77</td>\n",
       "      <td>17670.67</td>\n",
       "      <td>17680.50</td>\n",
       "      <td>9824.899652</td>\n",
       "      <td>17260.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2383 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        Date      High       Low      Last       Bid       Ask  \\\n",
       "0         0  2014-04-15    515.00    453.16    499.01    500.01    505.04   \n",
       "1         1  2014-04-16    548.00    494.02    534.00    535.01    536.00   \n",
       "2         2  2014-04-17    537.24    481.63    506.52    504.70    505.38   \n",
       "3         3  2014-04-18    508.43    470.00    487.00    484.14    487.00   \n",
       "4         4  2014-04-19    507.43    472.81    504.74    504.74    505.00   \n",
       "...     ...         ...       ...       ...       ...       ...       ...   \n",
       "2378   2378  2020-11-14  16494.52  15970.33  16335.58  16335.58  16339.27   \n",
       "2379   2379  2020-11-15  16341.89  15715.10  16086.34  16087.77  16094.81   \n",
       "2380   2380  2020-11-16  16170.00  15786.46  15975.49  15969.41  15973.22   \n",
       "2381   2381  2020-11-17  16894.93  15875.50  16724.62  16719.84  16729.63   \n",
       "2382   2382  2020-11-18  17868.00  16570.00  17681.77  17670.67  17680.50   \n",
       "\n",
       "            Volume      VWAP  \n",
       "0     28535.844106    491.41  \n",
       "1     31159.941300    520.21  \n",
       "2     21126.375080    504.83  \n",
       "3     11879.484756    485.72  \n",
       "4     10262.195861    492.22  \n",
       "...            ...       ...  \n",
       "2378   7842.488826  16279.18  \n",
       "2379   5046.326705  15982.98  \n",
       "2380   3226.276565  15979.39  \n",
       "2381   7511.143605  16409.99  \n",
       "2382   9824.899652  17260.21  \n",
       "\n",
       "[2383 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bitcoin_data.csv')\n",
    "data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>13650.00</td>\n",
       "      <td>12993.00</td>\n",
       "      <td>13411.86</td>\n",
       "      <td>13413.35</td>\n",
       "      <td>13416.39</td>\n",
       "      <td>8948.197381</td>\n",
       "      <td>13318.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>13675.56</td>\n",
       "      <td>13129.26</td>\n",
       "      <td>13577.60</td>\n",
       "      <td>13572.18</td>\n",
       "      <td>13581.82</td>\n",
       "      <td>8980.671631</td>\n",
       "      <td>13404.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>14100.00</td>\n",
       "      <td>13420.97</td>\n",
       "      <td>13879.14</td>\n",
       "      <td>13878.39</td>\n",
       "      <td>13887.22</td>\n",
       "      <td>6394.173016</td>\n",
       "      <td>13762.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>13907.47</td>\n",
       "      <td>13629.31</td>\n",
       "      <td>13711.21</td>\n",
       "      <td>13700.59</td>\n",
       "      <td>13711.21</td>\n",
       "      <td>2465.795017</td>\n",
       "      <td>13766.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>13842.50</td>\n",
       "      <td>13220.00</td>\n",
       "      <td>13563.72</td>\n",
       "      <td>13570.69</td>\n",
       "      <td>13578.98</td>\n",
       "      <td>7062.704712</td>\n",
       "      <td>13545.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>14083.76</td>\n",
       "      <td>13287.70</td>\n",
       "      <td>14041.58</td>\n",
       "      <td>14030.89</td>\n",
       "      <td>14041.58</td>\n",
       "      <td>7226.516356</td>\n",
       "      <td>13633.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>14277.50</td>\n",
       "      <td>13520.87</td>\n",
       "      <td>14160.59</td>\n",
       "      <td>14162.68</td>\n",
       "      <td>14171.73</td>\n",
       "      <td>10925.676805</td>\n",
       "      <td>13908.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>15770.58</td>\n",
       "      <td>14100.00</td>\n",
       "      <td>15605.04</td>\n",
       "      <td>15603.49</td>\n",
       "      <td>15608.32</td>\n",
       "      <td>18422.631860</td>\n",
       "      <td>14937.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>15968.98</td>\n",
       "      <td>15196.01</td>\n",
       "      <td>15598.09</td>\n",
       "      <td>15598.10</td>\n",
       "      <td>15603.23</td>\n",
       "      <td>13479.467068</td>\n",
       "      <td>15570.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>15778.60</td>\n",
       "      <td>14351.00</td>\n",
       "      <td>14838.97</td>\n",
       "      <td>14832.01</td>\n",
       "      <td>14842.70</td>\n",
       "      <td>10933.924192</td>\n",
       "      <td>15076.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>15664.90</td>\n",
       "      <td>14727.19</td>\n",
       "      <td>15489.15</td>\n",
       "      <td>15480.45</td>\n",
       "      <td>15490.09</td>\n",
       "      <td>5046.499164</td>\n",
       "      <td>15255.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>15854.48</td>\n",
       "      <td>14824.66</td>\n",
       "      <td>15332.04</td>\n",
       "      <td>15335.50</td>\n",
       "      <td>15348.95</td>\n",
       "      <td>14466.079537</td>\n",
       "      <td>15364.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>15482.76</td>\n",
       "      <td>15092.47</td>\n",
       "      <td>15313.65</td>\n",
       "      <td>15313.87</td>\n",
       "      <td>15317.81</td>\n",
       "      <td>8966.481714</td>\n",
       "      <td>15325.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>15991.01</td>\n",
       "      <td>15290.85</td>\n",
       "      <td>15702.00</td>\n",
       "      <td>15696.48</td>\n",
       "      <td>15703.40</td>\n",
       "      <td>10014.264272</td>\n",
       "      <td>15652.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>16369.99</td>\n",
       "      <td>15481.00</td>\n",
       "      <td>16300.00</td>\n",
       "      <td>16297.91</td>\n",
       "      <td>16300.00</td>\n",
       "      <td>16261.206579</td>\n",
       "      <td>15939.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>16494.52</td>\n",
       "      <td>15970.33</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16335.58</td>\n",
       "      <td>16339.27</td>\n",
       "      <td>7842.488826</td>\n",
       "      <td>16279.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>16341.89</td>\n",
       "      <td>15715.10</td>\n",
       "      <td>16086.34</td>\n",
       "      <td>16087.77</td>\n",
       "      <td>16094.81</td>\n",
       "      <td>5046.326705</td>\n",
       "      <td>15982.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>16170.00</td>\n",
       "      <td>15786.46</td>\n",
       "      <td>15975.49</td>\n",
       "      <td>15969.41</td>\n",
       "      <td>15973.22</td>\n",
       "      <td>3226.276565</td>\n",
       "      <td>15979.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>16894.93</td>\n",
       "      <td>15875.50</td>\n",
       "      <td>16724.62</td>\n",
       "      <td>16719.84</td>\n",
       "      <td>16729.63</td>\n",
       "      <td>7511.143605</td>\n",
       "      <td>16409.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>17868.00</td>\n",
       "      <td>16570.00</td>\n",
       "      <td>17681.77</td>\n",
       "      <td>17670.67</td>\n",
       "      <td>17680.50</td>\n",
       "      <td>9824.899652</td>\n",
       "      <td>17260.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          High       Low      Last       Bid       Ask        Volume      VWAP\n",
       "2363  13650.00  12993.00  13411.86  13413.35  13416.39   8948.197381  13318.04\n",
       "2364  13675.56  13129.26  13577.60  13572.18  13581.82   8980.671631  13404.59\n",
       "2365  14100.00  13420.97  13879.14  13878.39  13887.22   6394.173016  13762.10\n",
       "2366  13907.47  13629.31  13711.21  13700.59  13711.21   2465.795017  13766.72\n",
       "2367  13842.50  13220.00  13563.72  13570.69  13578.98   7062.704712  13545.15\n",
       "2368  14083.76  13287.70  14041.58  14030.89  14041.58   7226.516356  13633.01\n",
       "2369  14277.50  13520.87  14160.59  14162.68  14171.73  10925.676805  13908.16\n",
       "2370  15770.58  14100.00  15605.04  15603.49  15608.32  18422.631860  14937.25\n",
       "2371  15968.98  15196.01  15598.09  15598.10  15603.23  13479.467068  15570.55\n",
       "2372  15778.60  14351.00  14838.97  14832.01  14842.70  10933.924192  15076.99\n",
       "2373  15664.90  14727.19  15489.15  15480.45  15490.09   5046.499164  15255.08\n",
       "2374  15854.48  14824.66  15332.04  15335.50  15348.95  14466.079537  15364.34\n",
       "2375  15482.76  15092.47  15313.65  15313.87  15317.81   8966.481714  15325.34\n",
       "2376  15991.01  15290.85  15702.00  15696.48  15703.40  10014.264272  15652.52\n",
       "2377  16369.99  15481.00  16300.00  16297.91  16300.00  16261.206579  15939.46\n",
       "2378  16494.52  15970.33  16335.58  16335.58  16339.27   7842.488826  16279.18\n",
       "2379  16341.89  15715.10  16086.34  16087.77  16094.81   5046.326705  15982.98\n",
       "2380  16170.00  15786.46  15975.49  15969.41  15973.22   3226.276565  15979.39\n",
       "2381  16894.93  15875.50  16724.62  16719.84  16729.63   7511.143605  16409.99\n",
       "2382  17868.00  16570.00  17681.77  17670.67  17680.50   9824.899652  17260.21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.tail(20)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "High = test.High.values\n",
    "Low = test.Low.values\n",
    "Volume = test.Volume.values\n",
    "Last = test.Last.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13650.  , 12993.  ],\n",
       "       [13675.56, 13129.26],\n",
       "       [14100.  , 13420.97],\n",
       "       [13907.47, 13629.31],\n",
       "       [13842.5 , 13220.  ],\n",
       "       [14083.76, 13287.7 ],\n",
       "       [14277.5 , 13520.87],\n",
       "       [15770.58, 14100.  ],\n",
       "       [15968.98, 15196.01],\n",
       "       [15778.6 , 14351.  ],\n",
       "       [15664.9 , 14727.19],\n",
       "       [15854.48, 14824.66],\n",
       "       [15482.76, 15092.47],\n",
       "       [15991.01, 15290.85],\n",
       "       [16369.99, 15481.  ],\n",
       "       [16494.52, 15970.33],\n",
       "       [16341.89, 15715.1 ],\n",
       "       [16170.  , 15786.46],\n",
       "       [16894.93, 15875.5 ],\n",
       "       [17868.  , 16570.  ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(High)):\n",
    "    row = []\n",
    "    yrow = []\n",
    "    row.append(High[i])\n",
    "    row.append(Low[i])\n",
    "#     row.append(Volume[i])\n",
    "    yrow.append(Last[i])\n",
    "    X.append(row)\n",
    "    y.append(yrow)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower = np.array(X_train)\n",
    "horsepower2 = np.array(X_train)\n",
    "horsepower_normalizer = preprocessing.Normalization(input_shape=[1,])\n",
    "horsepower_normalizer.adapt(horsepower)\n",
    "horsepower_normalizer2 = preprocessing.Normalization(input_shape=[1,])\n",
    "horsepower_normalizer2.adapt(horsepower2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # input_layer = Input(shape=(X.shape[1],))\n",
    "# dense_layer_1 = Dense(100, input_shape=(X.shape[1],), activation='relu')\n",
    "# dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "# dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "# output = Dense(1)\n",
    "\n",
    "# model = Model([\n",
    "#     Dense(100, input_dim=X.shape[1], activation='relu'),\n",
    "#     Dense(50, activation='relu'),\n",
    "#     Dense(25, activation='relu'),\n",
    "#     Dense(units=1, activation='softmax')\n",
    "# ])\n",
    "# model.compile(loss=\"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
    "\n",
    "horsepower_model = tf.keras.Sequential([\n",
    "#     horsepower_normalizer,\n",
    "    layers.Dense(50, activation='relu', input_dim=2),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(25, activation='relu'),\n",
    "    layers.Dense(units=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-298.51135],\n",
       "       [-250.56612],\n",
       "       [-307.97375],\n",
       "       [-288.61554]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horsepower_model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='mean_absolute_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 4 samples\n",
      "Epoch 1/700\n",
      "12/12 - 0s - loss: 15353.7256 - accuracy: 0.0000e+00 - val_loss: 14933.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/700\n",
      "12/12 - 0s - loss: 15317.3438 - accuracy: 0.0000e+00 - val_loss: 14898.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/700\n",
      "12/12 - 0s - loss: 15280.9014 - accuracy: 0.0000e+00 - val_loss: 14866.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/700\n",
      "12/12 - 0s - loss: 15245.8643 - accuracy: 0.0000e+00 - val_loss: 14834.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/700\n",
      "12/12 - 0s - loss: 15212.9609 - accuracy: 0.0000e+00 - val_loss: 14802.8887 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/700\n",
      "12/12 - 0s - loss: 15179.9424 - accuracy: 0.0000e+00 - val_loss: 14770.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/700\n",
      "12/12 - 0s - loss: 15146.9141 - accuracy: 0.0000e+00 - val_loss: 14737.8623 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/700\n",
      "12/12 - 0s - loss: 15113.7969 - accuracy: 0.0000e+00 - val_loss: 14705.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/700\n",
      "12/12 - 0s - loss: 15080.5205 - accuracy: 0.0000e+00 - val_loss: 14672.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/700\n",
      "12/12 - 0s - loss: 15047.1123 - accuracy: 0.0000e+00 - val_loss: 14639.2363 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/700\n",
      "12/12 - 0s - loss: 15013.5938 - accuracy: 0.0000e+00 - val_loss: 14606.1680 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/700\n",
      "12/12 - 0s - loss: 14979.9805 - accuracy: 0.0000e+00 - val_loss: 14573.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/700\n",
      "12/12 - 0s - loss: 14946.2852 - accuracy: 0.0000e+00 - val_loss: 14539.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/700\n",
      "12/12 - 0s - loss: 14912.5303 - accuracy: 0.0000e+00 - val_loss: 14506.5254 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/700\n",
      "12/12 - 0s - loss: 14878.7188 - accuracy: 0.0000e+00 - val_loss: 14473.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/700\n",
      "12/12 - 0s - loss: 14844.9346 - accuracy: 0.0000e+00 - val_loss: 14439.7930 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/700\n",
      "12/12 - 0s - loss: 14811.1299 - accuracy: 0.0000e+00 - val_loss: 14406.3467 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/700\n",
      "12/12 - 0s - loss: 14777.2783 - accuracy: 0.0000e+00 - val_loss: 14372.8926 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/700\n",
      "12/12 - 0s - loss: 14744.1396 - accuracy: 0.0000e+00 - val_loss: 14339.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/700\n",
      "12/12 - 0s - loss: 14711.5752 - accuracy: 0.0000e+00 - val_loss: 14306.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/700\n",
      "12/12 - 0s - loss: 14679.0029 - accuracy: 0.0000e+00 - val_loss: 14272.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/700\n",
      "12/12 - 0s - loss: 14647.0273 - accuracy: 0.0000e+00 - val_loss: 14239.3633 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/700\n",
      "12/12 - 0s - loss: 14616.4971 - accuracy: 0.0000e+00 - val_loss: 14207.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/700\n",
      "12/12 - 0s - loss: 14587.0859 - accuracy: 0.0000e+00 - val_loss: 14176.1924 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/700\n",
      "12/12 - 0s - loss: 14558.3076 - accuracy: 0.0000e+00 - val_loss: 14145.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/700\n",
      "12/12 - 0s - loss: 14529.5947 - accuracy: 0.0000e+00 - val_loss: 14115.8867 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/700\n",
      "12/12 - 0s - loss: 14500.7031 - accuracy: 0.0000e+00 - val_loss: 14087.2217 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/700\n",
      "12/12 - 0s - loss: 14471.5674 - accuracy: 0.0000e+00 - val_loss: 14058.7832 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/700\n",
      "12/12 - 0s - loss: 14442.3525 - accuracy: 0.0000e+00 - val_loss: 14030.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/700\n",
      "12/12 - 0s - loss: 14413.0986 - accuracy: 0.0000e+00 - val_loss: 14002.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/700\n",
      "12/12 - 0s - loss: 14383.8506 - accuracy: 0.0000e+00 - val_loss: 13974.3066 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/700\n",
      "12/12 - 0s - loss: 14354.5869 - accuracy: 0.0000e+00 - val_loss: 13946.5293 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/700\n",
      "12/12 - 0s - loss: 14325.3203 - accuracy: 0.0000e+00 - val_loss: 13920.0488 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/700\n",
      "12/12 - 0s - loss: 14296.2627 - accuracy: 0.0000e+00 - val_loss: 13893.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/700\n",
      "12/12 - 0s - loss: 14266.9873 - accuracy: 0.0000e+00 - val_loss: 13866.7617 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/700\n",
      "12/12 - 0s - loss: 14237.8330 - accuracy: 0.0000e+00 - val_loss: 13839.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/700\n",
      "12/12 - 0s - loss: 14208.8164 - accuracy: 0.0000e+00 - val_loss: 13814.2246 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/700\n",
      "12/12 - 0s - loss: 14181.2471 - accuracy: 0.0000e+00 - val_loss: 13788.5723 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/700\n",
      "12/12 - 0s - loss: 14153.7373 - accuracy: 0.0000e+00 - val_loss: 13762.4570 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/700\n",
      "12/12 - 0s - loss: 14126.1016 - accuracy: 0.0000e+00 - val_loss: 13735.8311 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/700\n",
      "12/12 - 0s - loss: 14098.4033 - accuracy: 0.0000e+00 - val_loss: 13708.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/700\n",
      "12/12 - 0s - loss: 14070.3984 - accuracy: 0.0000e+00 - val_loss: 13680.5537 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/700\n",
      "12/12 - 0s - loss: 14041.9844 - accuracy: 0.0000e+00 - val_loss: 13651.8457 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/700\n",
      "12/12 - 0s - loss: 14013.2080 - accuracy: 0.0000e+00 - val_loss: 13622.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/700\n",
      "12/12 - 0s - loss: 13984.0850 - accuracy: 0.0000e+00 - val_loss: 13592.7510 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/700\n",
      "12/12 - 0s - loss: 13954.7578 - accuracy: 0.0000e+00 - val_loss: 13562.5303 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/700\n",
      "12/12 - 0s - loss: 13925.3750 - accuracy: 0.0000e+00 - val_loss: 13532.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/700\n",
      "12/12 - 0s - loss: 13896.1064 - accuracy: 0.0000e+00 - val_loss: 13501.5098 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/700\n",
      "12/12 - 0s - loss: 13866.8633 - accuracy: 0.0000e+00 - val_loss: 13471.3662 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/700\n",
      "12/12 - 0s - loss: 13837.6670 - accuracy: 0.0000e+00 - val_loss: 13441.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/700\n",
      "12/12 - 0s - loss: 13808.3604 - accuracy: 0.0000e+00 - val_loss: 13410.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/700\n",
      "12/12 - 0s - loss: 13778.9531 - accuracy: 0.0000e+00 - val_loss: 13380.5762 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/700\n",
      "12/12 - 0s - loss: 13749.2031 - accuracy: 0.0000e+00 - val_loss: 13350.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/700\n",
      "12/12 - 0s - loss: 13719.1904 - accuracy: 0.0000e+00 - val_loss: 13320.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/700\n",
      "12/12 - 0s - loss: 13688.7109 - accuracy: 0.0000e+00 - val_loss: 13290.2617 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/700\n",
      "12/12 - 0s - loss: 13657.8281 - accuracy: 0.0000e+00 - val_loss: 13259.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/700\n",
      "12/12 - 0s - loss: 13626.6768 - accuracy: 0.0000e+00 - val_loss: 13227.6641 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/700\n",
      "12/12 - 0s - loss: 13595.0869 - accuracy: 0.0000e+00 - val_loss: 13194.6143 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/700\n",
      "12/12 - 0s - loss: 13563.0625 - accuracy: 0.0000e+00 - val_loss: 13161.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/700\n",
      "12/12 - 0s - loss: 13530.2812 - accuracy: 0.0000e+00 - val_loss: 13126.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/700\n",
      "12/12 - 0s - loss: 13496.4795 - accuracy: 0.0000e+00 - val_loss: 13091.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/700\n",
      "12/12 - 0s - loss: 13461.5811 - accuracy: 0.0000e+00 - val_loss: 13055.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/700\n",
      "12/12 - 0s - loss: 13425.8174 - accuracy: 0.0000e+00 - val_loss: 13020.7227 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/700\n",
      "12/12 - 0s - loss: 13389.6377 - accuracy: 0.0000e+00 - val_loss: 12984.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/700\n",
      "12/12 - 0s - loss: 13352.9951 - accuracy: 0.0000e+00 - val_loss: 12947.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/700\n",
      "12/12 - 0s - loss: 13315.4053 - accuracy: 0.0000e+00 - val_loss: 12909.1660 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/700\n",
      "12/12 - 0s - loss: 13276.6299 - accuracy: 0.0000e+00 - val_loss: 12870.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/700\n",
      "12/12 - 0s - loss: 13237.1514 - accuracy: 0.0000e+00 - val_loss: 12831.0342 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/700\n",
      "12/12 - 0s - loss: 13197.3115 - accuracy: 0.0000e+00 - val_loss: 12795.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/700\n",
      "12/12 - 0s - loss: 13157.8984 - accuracy: 0.0000e+00 - val_loss: 12761.0664 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/700\n",
      "12/12 - 0s - loss: 13119.4766 - accuracy: 0.0000e+00 - val_loss: 12726.0254 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/700\n",
      "12/12 - 0s - loss: 13081.8799 - accuracy: 0.0000e+00 - val_loss: 12689.4072 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/700\n",
      "12/12 - 0s - loss: 13043.6982 - accuracy: 0.0000e+00 - val_loss: 12651.2598 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/700\n",
      "12/12 - 0s - loss: 13004.4424 - accuracy: 0.0000e+00 - val_loss: 12611.9395 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/700\n",
      "12/12 - 0s - loss: 12964.3164 - accuracy: 0.0000e+00 - val_loss: 12571.5078 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/700\n",
      "12/12 - 0s - loss: 12923.3545 - accuracy: 0.0000e+00 - val_loss: 12530.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/700\n",
      "12/12 - 0s - loss: 12881.5596 - accuracy: 0.0000e+00 - val_loss: 12487.3857 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/700\n",
      "12/12 - 0s - loss: 12838.8828 - accuracy: 0.0000e+00 - val_loss: 12443.6689 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/700\n",
      "12/12 - 0s - loss: 12795.4033 - accuracy: 0.0000e+00 - val_loss: 12399.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/700\n",
      "12/12 - 0s - loss: 12751.1875 - accuracy: 0.0000e+00 - val_loss: 12353.7803 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/700\n",
      "12/12 - 0s - loss: 12706.2998 - accuracy: 0.0000e+00 - val_loss: 12307.8008 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/700\n",
      "12/12 - 0s - loss: 12660.9609 - accuracy: 0.0000e+00 - val_loss: 12261.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/700\n",
      "12/12 - 0s - loss: 12615.3486 - accuracy: 0.0000e+00 - val_loss: 12215.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/700\n",
      "12/12 - 0s - loss: 12569.9307 - accuracy: 0.0000e+00 - val_loss: 12170.3008 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/700\n",
      "12/12 - 0s - loss: 12524.3174 - accuracy: 0.0000e+00 - val_loss: 12125.5127 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/700\n",
      "12/12 - 0s - loss: 12478.1260 - accuracy: 0.0000e+00 - val_loss: 12080.1846 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/700\n",
      "12/12 - 0s - loss: 12431.6328 - accuracy: 0.0000e+00 - val_loss: 12034.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/700\n",
      "12/12 - 0s - loss: 12384.8525 - accuracy: 0.0000e+00 - val_loss: 11988.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/700\n",
      "12/12 - 0s - loss: 12337.4531 - accuracy: 0.0000e+00 - val_loss: 11940.3818 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/700\n",
      "12/12 - 0s - loss: 12289.0859 - accuracy: 0.0000e+00 - val_loss: 11891.5127 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/700\n",
      "12/12 - 0s - loss: 12239.9170 - accuracy: 0.0000e+00 - val_loss: 11841.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/700\n",
      "12/12 - 0s - loss: 12190.1484 - accuracy: 0.0000e+00 - val_loss: 11793.1865 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/700\n",
      "12/12 - 0s - loss: 12140.6904 - accuracy: 0.0000e+00 - val_loss: 11743.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/700\n",
      "12/12 - 0s - loss: 12090.8594 - accuracy: 0.0000e+00 - val_loss: 11693.2891 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/700\n",
      "12/12 - 0s - loss: 12040.1016 - accuracy: 0.0000e+00 - val_loss: 11641.9590 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/700\n",
      "12/12 - 0s - loss: 11988.3516 - accuracy: 0.0000e+00 - val_loss: 11589.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/700\n",
      "12/12 - 0s - loss: 11935.5830 - accuracy: 0.0000e+00 - val_loss: 11536.7266 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/700\n",
      "12/12 - 0s - loss: 11882.0273 - accuracy: 0.0000e+00 - val_loss: 11483.4668 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/700\n",
      "12/12 - 0s - loss: 11828.3750 - accuracy: 0.0000e+00 - val_loss: 11429.7949 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/700\n",
      "12/12 - 0s - loss: 11773.8174 - accuracy: 0.0000e+00 - val_loss: 11375.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/700\n",
      "12/12 - 0s - loss: 11718.0811 - accuracy: 0.0000e+00 - val_loss: 11319.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/700\n",
      "12/12 - 0s - loss: 11661.2861 - accuracy: 0.0000e+00 - val_loss: 11264.1445 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/700\n",
      "12/12 - 0s - loss: 11604.3984 - accuracy: 0.0000e+00 - val_loss: 11207.8457 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/700\n",
      "12/12 - 0s - loss: 11546.8311 - accuracy: 0.0000e+00 - val_loss: 11150.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/700\n",
      "12/12 - 0s - loss: 11488.0586 - accuracy: 0.0000e+00 - val_loss: 11090.7383 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/700\n",
      "12/12 - 0s - loss: 11428.1455 - accuracy: 0.0000e+00 - val_loss: 11030.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/700\n",
      "12/12 - 0s - loss: 11367.3203 - accuracy: 0.0000e+00 - val_loss: 10969.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/700\n",
      "12/12 - 0s - loss: 11306.3564 - accuracy: 0.0000e+00 - val_loss: 10907.9561 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/700\n",
      "12/12 - 0s - loss: 11244.3174 - accuracy: 0.0000e+00 - val_loss: 10846.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/700\n",
      "12/12 - 0s - loss: 11181.9072 - accuracy: 0.0000e+00 - val_loss: 10784.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/700\n",
      "12/12 - 0s - loss: 11119.8701 - accuracy: 0.0000e+00 - val_loss: 10722.5078 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/700\n",
      "12/12 - 0s - loss: 11057.3389 - accuracy: 0.0000e+00 - val_loss: 10659.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/700\n",
      "12/12 - 0s - loss: 10994.4111 - accuracy: 0.0000e+00 - val_loss: 10597.1582 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/700\n",
      "12/12 - 0s - loss: 10932.5479 - accuracy: 0.0000e+00 - val_loss: 10534.4668 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/700\n",
      "12/12 - 0s - loss: 10870.3516 - accuracy: 0.0000e+00 - val_loss: 10471.6641 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/700\n",
      "12/12 - 0s - loss: 10806.5713 - accuracy: 0.0000e+00 - val_loss: 10407.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/700\n",
      "12/12 - 0s - loss: 10741.5332 - accuracy: 0.0000e+00 - val_loss: 10342.2461 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/700\n",
      "12/12 - 0s - loss: 10675.0527 - accuracy: 0.0000e+00 - val_loss: 10275.8574 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/700\n",
      "12/12 - 0s - loss: 10607.1816 - accuracy: 0.0000e+00 - val_loss: 10208.7461 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/700\n",
      "12/12 - 0s - loss: 10538.0156 - accuracy: 0.0000e+00 - val_loss: 10141.6055 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/700\n",
      "12/12 - 0s - loss: 10468.8135 - accuracy: 0.0000e+00 - val_loss: 10073.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/700\n",
      "12/12 - 0s - loss: 10399.4756 - accuracy: 0.0000e+00 - val_loss: 10005.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/700\n",
      "12/12 - 0s - loss: 10329.4170 - accuracy: 0.0000e+00 - val_loss: 9935.4844 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/700\n",
      "12/12 - 0s - loss: 10258.1309 - accuracy: 0.0000e+00 - val_loss: 9864.7617 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/700\n",
      "12/12 - 0s - loss: 10185.4951 - accuracy: 0.0000e+00 - val_loss: 9793.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/700\n",
      "12/12 - 0s - loss: 10112.0869 - accuracy: 0.0000e+00 - val_loss: 9720.3525 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/700\n",
      "12/12 - 0s - loss: 10037.4238 - accuracy: 0.0000e+00 - val_loss: 9645.8799 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/700\n",
      "12/12 - 0s - loss: 9961.5312 - accuracy: 0.0000e+00 - val_loss: 9570.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/700\n",
      "12/12 - 0s - loss: 9884.5742 - accuracy: 0.0000e+00 - val_loss: 9492.8672 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/700\n",
      "12/12 - 0s - loss: 9806.6055 - accuracy: 0.0000e+00 - val_loss: 9414.6113 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/700\n",
      "12/12 - 0s - loss: 9728.0771 - accuracy: 0.0000e+00 - val_loss: 9335.3887 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/700\n",
      "12/12 - 0s - loss: 9648.7412 - accuracy: 0.0000e+00 - val_loss: 9254.9365 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/700\n",
      "12/12 - 0s - loss: 9568.1367 - accuracy: 0.0000e+00 - val_loss: 9173.8477 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/700\n",
      "12/12 - 0s - loss: 9486.2998 - accuracy: 0.0000e+00 - val_loss: 9092.3428 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/700\n",
      "12/12 - 0s - loss: 9403.3154 - accuracy: 0.0000e+00 - val_loss: 9010.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/700\n",
      "12/12 - 0s - loss: 9319.2471 - accuracy: 0.0000e+00 - val_loss: 8926.9238 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/700\n",
      "12/12 - 0s - loss: 9234.1240 - accuracy: 0.0000e+00 - val_loss: 8841.8896 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/700\n",
      "12/12 - 0s - loss: 9147.6523 - accuracy: 0.0000e+00 - val_loss: 8754.9238 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/700\n",
      "12/12 - 0s - loss: 9059.5879 - accuracy: 0.0000e+00 - val_loss: 8666.4531 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/700\n",
      "12/12 - 0s - loss: 8970.3672 - accuracy: 0.0000e+00 - val_loss: 8576.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/700\n",
      "12/12 - 0s - loss: 8880.1543 - accuracy: 0.0000e+00 - val_loss: 8486.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/700\n",
      "12/12 - 0s - loss: 8788.6299 - accuracy: 0.0000e+00 - val_loss: 8395.8633 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/700\n",
      "12/12 - 0s - loss: 8695.8740 - accuracy: 0.0000e+00 - val_loss: 8303.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/700\n",
      "12/12 - 0s - loss: 8601.7549 - accuracy: 0.0000e+00 - val_loss: 8210.0996 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/700\n",
      "12/12 - 0s - loss: 8506.2275 - accuracy: 0.0000e+00 - val_loss: 8114.7646 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/700\n",
      "12/12 - 0s - loss: 8409.4297 - accuracy: 0.0000e+00 - val_loss: 8017.9932 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/700\n",
      "12/12 - 0s - loss: 8311.3438 - accuracy: 0.0000e+00 - val_loss: 7919.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/700\n",
      "12/12 - 0s - loss: 8211.7305 - accuracy: 0.0000e+00 - val_loss: 7819.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/700\n",
      "12/12 - 0s - loss: 8110.7285 - accuracy: 0.0000e+00 - val_loss: 7717.6621 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/700\n",
      "12/12 - 0s - loss: 8008.2598 - accuracy: 0.0000e+00 - val_loss: 7614.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/700\n",
      "12/12 - 0s - loss: 7904.4414 - accuracy: 0.0000e+00 - val_loss: 7510.4927 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/700\n",
      "12/12 - 0s - loss: 7799.2871 - accuracy: 0.0000e+00 - val_loss: 7405.3965 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/700\n",
      "12/12 - 0s - loss: 7693.0444 - accuracy: 0.0000e+00 - val_loss: 7299.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/700\n",
      "12/12 - 0s - loss: 7585.6426 - accuracy: 0.0000e+00 - val_loss: 7191.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/700\n",
      "12/12 - 0s - loss: 7476.6211 - accuracy: 0.0000e+00 - val_loss: 7082.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/700\n",
      "12/12 - 0s - loss: 7365.9575 - accuracy: 0.0000e+00 - val_loss: 6972.1201 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/700\n",
      "12/12 - 0s - loss: 7253.6313 - accuracy: 0.0000e+00 - val_loss: 6859.3955 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/700\n",
      "12/12 - 0s - loss: 7139.5371 - accuracy: 0.0000e+00 - val_loss: 6744.8257 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/700\n",
      "12/12 - 0s - loss: 7023.5464 - accuracy: 0.0000e+00 - val_loss: 6628.7871 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/700\n",
      "12/12 - 0s - loss: 6905.8784 - accuracy: 0.0000e+00 - val_loss: 6512.5317 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/700\n",
      "12/12 - 0s - loss: 6786.8931 - accuracy: 0.0000e+00 - val_loss: 6395.6113 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/700\n",
      "12/12 - 0s - loss: 6667.0112 - accuracy: 0.0000e+00 - val_loss: 6277.4683 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/700\n",
      "12/12 - 0s - loss: 6546.2319 - accuracy: 0.0000e+00 - val_loss: 6156.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/700\n",
      "12/12 - 0s - loss: 6423.5332 - accuracy: 0.0000e+00 - val_loss: 6032.9893 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/700\n",
      "12/12 - 0s - loss: 6298.7983 - accuracy: 0.0000e+00 - val_loss: 5907.2217 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/700\n",
      "12/12 - 0s - loss: 6172.3403 - accuracy: 0.0000e+00 - val_loss: 5780.1943 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/700\n",
      "12/12 - 0s - loss: 6044.0366 - accuracy: 0.0000e+00 - val_loss: 5652.5210 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/700\n",
      "12/12 - 0s - loss: 5915.0371 - accuracy: 0.0000e+00 - val_loss: 5521.9219 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/700\n",
      "12/12 - 0s - loss: 5782.8862 - accuracy: 0.0000e+00 - val_loss: 5389.2988 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/700\n",
      "12/12 - 0s - loss: 5649.2324 - accuracy: 0.0000e+00 - val_loss: 5258.2866 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/700\n",
      "12/12 - 0s - loss: 5514.8711 - accuracy: 0.0000e+00 - val_loss: 5126.5332 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/700\n",
      "12/12 - 0s - loss: 5380.6118 - accuracy: 0.0000e+00 - val_loss: 4993.1831 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/700\n",
      "12/12 - 0s - loss: 5244.8433 - accuracy: 0.0000e+00 - val_loss: 4858.1504 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/700\n",
      "12/12 - 0s - loss: 5107.2603 - accuracy: 0.0000e+00 - val_loss: 4720.9033 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/700\n",
      "12/12 - 0s - loss: 4967.5938 - accuracy: 0.0000e+00 - val_loss: 4582.1851 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/700\n",
      "12/12 - 0s - loss: 4826.1064 - accuracy: 0.0000e+00 - val_loss: 4439.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/700\n",
      "12/12 - 0s - loss: 4682.8970 - accuracy: 0.0000e+00 - val_loss: 4293.3857 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/700\n",
      "12/12 - 0s - loss: 4537.4126 - accuracy: 0.0000e+00 - val_loss: 4147.2334 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/700\n",
      "12/12 - 0s - loss: 4390.3936 - accuracy: 0.0000e+00 - val_loss: 3999.8171 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/700\n",
      "12/12 - 0s - loss: 4241.1040 - accuracy: 0.0000e+00 - val_loss: 3850.7622 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/700\n",
      "12/12 - 0s - loss: 4089.6025 - accuracy: 0.0000e+00 - val_loss: 3700.2119 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/700\n",
      "12/12 - 0s - loss: 3935.9004 - accuracy: 0.0000e+00 - val_loss: 3548.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/700\n",
      "12/12 - 0s - loss: 3780.7317 - accuracy: 0.0000e+00 - val_loss: 3392.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/700\n",
      "12/12 - 0s - loss: 3622.0891 - accuracy: 0.0000e+00 - val_loss: 3234.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/700\n",
      "12/12 - 0s - loss: 3462.2021 - accuracy: 0.0000e+00 - val_loss: 3074.3188 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/700\n",
      "12/12 - 0s - loss: 3300.0969 - accuracy: 0.0000e+00 - val_loss: 2912.1533 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/700\n",
      "12/12 - 0s - loss: 3135.5671 - accuracy: 0.0000e+00 - val_loss: 2747.7373 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/700\n",
      "12/12 - 0s - loss: 2968.5273 - accuracy: 0.0000e+00 - val_loss: 2580.9561 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/700\n",
      "12/12 - 0s - loss: 2799.0608 - accuracy: 0.0000e+00 - val_loss: 2413.0603 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/700\n",
      "12/12 - 0s - loss: 2627.9326 - accuracy: 0.0000e+00 - val_loss: 2239.8721 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/700\n",
      "12/12 - 0s - loss: 2453.3938 - accuracy: 0.0000e+00 - val_loss: 2065.4438 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/700\n",
      "12/12 - 0s - loss: 2277.1179 - accuracy: 0.0000e+00 - val_loss: 1888.6951 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/700\n",
      "12/12 - 0s - loss: 2098.2405 - accuracy: 0.0000e+00 - val_loss: 1711.8450 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/700\n",
      "12/12 - 0s - loss: 1917.8975 - accuracy: 0.0000e+00 - val_loss: 1531.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/700\n",
      "12/12 - 0s - loss: 1735.3951 - accuracy: 0.0000e+00 - val_loss: 1347.7498 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/700\n",
      "12/12 - 0s - loss: 1550.1831 - accuracy: 0.0000e+00 - val_loss: 1162.0564 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/700\n",
      "12/12 - 0s - loss: 1362.6560 - accuracy: 0.0000e+00 - val_loss: 973.9265 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/700\n",
      "12/12 - 0s - loss: 1172.2628 - accuracy: 0.0000e+00 - val_loss: 783.7397 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/700\n",
      "12/12 - 0s - loss: 979.0798 - accuracy: 0.0000e+00 - val_loss: 590.8098 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/700\n",
      "12/12 - 0s - loss: 783.0432 - accuracy: 0.0000e+00 - val_loss: 395.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/700\n",
      "12/12 - 0s - loss: 584.5547 - accuracy: 0.0000e+00 - val_loss: 196.8357 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/700\n",
      "12/12 - 0s - loss: 383.0405 - accuracy: 0.0000e+00 - val_loss: 70.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/700\n",
      "12/12 - 0s - loss: 210.9895 - accuracy: 0.0000e+00 - val_loss: 198.9521 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/700\n",
      "12/12 - 0s - loss: 211.2901 - accuracy: 0.0000e+00 - val_loss: 365.2649 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/700\n",
      "12/12 - 0s - loss: 270.2867 - accuracy: 0.0000e+00 - val_loss: 487.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/700\n",
      "12/12 - 0s - loss: 372.4717 - accuracy: 0.0000e+00 - val_loss: 561.8384 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/700\n",
      "12/12 - 0s - loss: 435.0759 - accuracy: 0.0000e+00 - val_loss: 594.1809 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/700\n",
      "12/12 - 0s - loss: 462.0805 - accuracy: 0.0000e+00 - val_loss: 590.6145 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/700\n",
      "12/12 - 0s - loss: 459.2437 - accuracy: 0.0000e+00 - val_loss: 555.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/700\n",
      "12/12 - 0s - loss: 430.0122 - accuracy: 0.0000e+00 - val_loss: 494.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/700\n",
      "12/12 - 0s - loss: 377.9398 - accuracy: 0.0000e+00 - val_loss: 409.3394 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/700\n",
      "12/12 - 0s - loss: 306.1649 - accuracy: 0.0000e+00 - val_loss: 304.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/700\n",
      "12/12 - 0s - loss: 235.8835 - accuracy: 0.0000e+00 - val_loss: 192.4238 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/700\n",
      "12/12 - 0s - loss: 207.1905 - accuracy: 0.0000e+00 - val_loss: 85.0999 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/700\n",
      "12/12 - 0s - loss: 191.8135 - accuracy: 0.0000e+00 - val_loss: 67.8997 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/700\n",
      "12/12 - 0s - loss: 211.4971 - accuracy: 0.0000e+00 - val_loss: 95.2219 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/700\n",
      "12/12 - 0s - loss: 257.1393 - accuracy: 0.0000e+00 - val_loss: 109.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/700\n",
      "12/12 - 0s - loss: 279.0787 - accuracy: 0.0000e+00 - val_loss: 105.8408 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/700\n",
      "12/12 - 0s - loss: 273.9949 - accuracy: 0.0000e+00 - val_loss: 87.8735 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/700\n",
      "12/12 - 0s - loss: 245.3433 - accuracy: 0.0000e+00 - val_loss: 67.7786 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/700\n",
      "12/12 - 0s - loss: 205.1767 - accuracy: 0.0000e+00 - val_loss: 76.9460 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/700\n",
      "12/12 - 0s - loss: 191.3284 - accuracy: 0.0000e+00 - val_loss: 137.6584 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/700\n",
      "12/12 - 0s - loss: 197.1332 - accuracy: 0.0000e+00 - val_loss: 191.6660 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/700\n",
      "12/12 - 0s - loss: 206.8909 - accuracy: 0.0000e+00 - val_loss: 234.2991 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/700\n",
      "12/12 - 0s - loss: 214.5789 - accuracy: 0.0000e+00 - val_loss: 266.6062 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/700\n",
      "12/12 - 0s - loss: 220.3901 - accuracy: 0.0000e+00 - val_loss: 289.5459 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/700\n",
      "12/12 - 0s - loss: 228.4639 - accuracy: 0.0000e+00 - val_loss: 292.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/700\n",
      "12/12 - 0s - loss: 230.0837 - accuracy: 0.0000e+00 - val_loss: 278.1311 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/700\n",
      "12/12 - 0s - loss: 224.0099 - accuracy: 0.0000e+00 - val_loss: 253.4954 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/700\n",
      "12/12 - 0s - loss: 217.9255 - accuracy: 0.0000e+00 - val_loss: 225.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/700\n",
      "12/12 - 0s - loss: 212.7973 - accuracy: 0.0000e+00 - val_loss: 193.4373 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/700\n",
      "12/12 - 0s - loss: 207.0823 - accuracy: 0.0000e+00 - val_loss: 158.7371 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/700\n",
      "12/12 - 0s - loss: 200.8236 - accuracy: 0.0000e+00 - val_loss: 121.3418 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/700\n",
      "12/12 - 0s - loss: 194.0742 - accuracy: 0.0000e+00 - val_loss: 82.4817 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/700\n",
      "12/12 - 0s - loss: 191.4291 - accuracy: 0.0000e+00 - val_loss: 67.2615 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/700\n",
      "12/12 - 0s - loss: 190.5146 - accuracy: 0.0000e+00 - val_loss: 67.4946 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/700\n",
      "12/12 - 0s - loss: 196.7001 - accuracy: 0.0000e+00 - val_loss: 67.5842 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/700\n",
      "12/12 - 0s - loss: 204.2521 - accuracy: 0.0000e+00 - val_loss: 67.4998 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/700\n",
      "12/12 - 0s - loss: 198.6430 - accuracy: 0.0000e+00 - val_loss: 67.3066 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/700\n",
      "12/12 - 0s - loss: 190.6799 - accuracy: 0.0000e+00 - val_loss: 70.6458 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/700\n",
      "12/12 - 0s - loss: 190.8477 - accuracy: 0.0000e+00 - val_loss: 84.3757 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/700\n",
      "12/12 - 0s - loss: 191.4404 - accuracy: 0.0000e+00 - val_loss: 105.5530 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/700\n",
      "12/12 - 0s - loss: 191.9555 - accuracy: 0.0000e+00 - val_loss: 123.8245 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/700\n",
      "12/12 - 0s - loss: 194.4782 - accuracy: 0.0000e+00 - val_loss: 134.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/700\n",
      "12/12 - 0s - loss: 196.3349 - accuracy: 0.0000e+00 - val_loss: 137.2080 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/700\n",
      "12/12 - 0s - loss: 196.8884 - accuracy: 0.0000e+00 - val_loss: 133.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/700\n",
      "12/12 - 0s - loss: 196.2643 - accuracy: 0.0000e+00 - val_loss: 124.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/700\n",
      "12/12 - 0s - loss: 194.5762 - accuracy: 0.0000e+00 - val_loss: 109.8616 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/700\n",
      "12/12 - 0s - loss: 192.0072 - accuracy: 0.0000e+00 - val_loss: 95.8367 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/700\n",
      "12/12 - 0s - loss: 191.6520 - accuracy: 0.0000e+00 - val_loss: 82.7390 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/700\n",
      "12/12 - 0s - loss: 191.3096 - accuracy: 0.0000e+00 - val_loss: 75.6057 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/700\n",
      "12/12 - 0s - loss: 190.9792 - accuracy: 0.0000e+00 - val_loss: 68.7053 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/700\n",
      "12/12 - 0s - loss: 190.6589 - accuracy: 0.0000e+00 - val_loss: 67.0359 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/700\n",
      "12/12 - 0s - loss: 190.3480 - accuracy: 0.0000e+00 - val_loss: 67.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/700\n",
      "12/12 - 0s - loss: 190.4054 - accuracy: 0.0000e+00 - val_loss: 67.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/700\n",
      "12/12 - 0s - loss: 191.2177 - accuracy: 0.0000e+00 - val_loss: 67.1169 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/700\n",
      "12/12 - 0s - loss: 191.1366 - accuracy: 0.0000e+00 - val_loss: 67.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/700\n",
      "12/12 - 0s - loss: 190.2470 - accuracy: 0.0000e+00 - val_loss: 66.9719 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/700\n",
      "12/12 - 0s - loss: 190.2850 - accuracy: 0.0000e+00 - val_loss: 66.8965 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/700\n",
      "12/12 - 0s - loss: 190.4878 - accuracy: 0.0000e+00 - val_loss: 70.0706 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/700\n",
      "12/12 - 0s - loss: 190.6478 - accuracy: 0.0000e+00 - val_loss: 72.9817 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/700\n",
      "12/12 - 0s - loss: 190.7706 - accuracy: 0.0000e+00 - val_loss: 75.1279 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/700\n",
      "12/12 - 0s - loss: 190.8584 - accuracy: 0.0000e+00 - val_loss: 76.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/700\n",
      "12/12 - 0s - loss: 190.9145 - accuracy: 0.0000e+00 - val_loss: 77.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/700\n",
      "12/12 - 0s - loss: 190.9434 - accuracy: 0.0000e+00 - val_loss: 77.6870 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/700\n",
      "12/12 - 0s - loss: 190.9461 - accuracy: 0.0000e+00 - val_loss: 77.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/700\n",
      "12/12 - 0s - loss: 190.9263 - accuracy: 0.0000e+00 - val_loss: 76.7471 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/700\n",
      "12/12 - 0s - loss: 190.8851 - accuracy: 0.0000e+00 - val_loss: 75.6294 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/700\n",
      "12/12 - 0s - loss: 190.8241 - accuracy: 0.0000e+00 - val_loss: 74.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/700\n",
      "12/12 - 0s - loss: 190.7478 - accuracy: 0.0000e+00 - val_loss: 72.3020 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/700\n",
      "12/12 - 0s - loss: 190.6551 - accuracy: 0.0000e+00 - val_loss: 70.1606 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/700\n",
      "12/12 - 0s - loss: 190.5492 - accuracy: 0.0000e+00 - val_loss: 67.7395 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/700\n",
      "12/12 - 0s - loss: 190.4298 - accuracy: 0.0000e+00 - val_loss: 66.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/700\n",
      "12/12 - 0s - loss: 190.3000 - accuracy: 0.0000e+00 - val_loss: 66.7334 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/700\n",
      "12/12 - 0s - loss: 190.1599 - accuracy: 0.0000e+00 - val_loss: 66.7600 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/700\n",
      "12/12 - 0s - loss: 190.0093 - accuracy: 0.0000e+00 - val_loss: 66.7893 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/700\n",
      "12/12 - 0s - loss: 189.9453 - accuracy: 0.0000e+00 - val_loss: 66.7732 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/700\n",
      "12/12 - 0s - loss: 189.9079 - accuracy: 0.0000e+00 - val_loss: 66.7168 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/700\n",
      "12/12 - 0s - loss: 189.9750 - accuracy: 0.0000e+00 - val_loss: 66.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/700\n",
      "12/12 - 0s - loss: 190.0684 - accuracy: 0.0000e+00 - val_loss: 66.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/700\n",
      "12/12 - 0s - loss: 190.1301 - accuracy: 0.0000e+00 - val_loss: 66.6086 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/700\n",
      "12/12 - 0s - loss: 190.1619 - accuracy: 0.0000e+00 - val_loss: 66.5881 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/700\n",
      "12/12 - 0s - loss: 190.1677 - accuracy: 0.0000e+00 - val_loss: 66.5767 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/700\n",
      "12/12 - 0s - loss: 190.1489 - accuracy: 0.0000e+00 - val_loss: 66.5703 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/700\n",
      "12/12 - 0s - loss: 190.1086 - accuracy: 0.0000e+00 - val_loss: 66.5698 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/700\n",
      "12/12 - 0s - loss: 190.0485 - accuracy: 0.0000e+00 - val_loss: 66.5737 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/700\n",
      "12/12 - 0s - loss: 189.9709 - accuracy: 0.0000e+00 - val_loss: 66.5835 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/700\n",
      "12/12 - 0s - loss: 189.8770 - accuracy: 0.0000e+00 - val_loss: 66.5969 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/700\n",
      "12/12 - 0s - loss: 189.7690 - accuracy: 0.0000e+00 - val_loss: 66.6145 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/700\n",
      "12/12 - 0s - loss: 190.1761 - accuracy: 0.0000e+00 - val_loss: 66.5872 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/700\n",
      "12/12 - 0s - loss: 189.9091 - accuracy: 0.0000e+00 - val_loss: 66.5193 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/700\n",
      "12/12 - 0s - loss: 189.8435 - accuracy: 0.0000e+00 - val_loss: 66.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/700\n",
      "12/12 - 0s - loss: 189.9707 - accuracy: 0.0000e+00 - val_loss: 66.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/700\n",
      "12/12 - 0s - loss: 190.0605 - accuracy: 0.0000e+00 - val_loss: 66.3845 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/700\n",
      "12/12 - 0s - loss: 190.1178 - accuracy: 0.0000e+00 - val_loss: 66.4482 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/700\n",
      "12/12 - 0s - loss: 190.1453 - accuracy: 0.0000e+00 - val_loss: 66.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/700\n",
      "12/12 - 0s - loss: 190.1456 - accuracy: 0.0000e+00 - val_loss: 66.3914 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/700\n",
      "12/12 - 0s - loss: 190.1226 - accuracy: 0.0000e+00 - val_loss: 66.3225 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/700\n",
      "12/12 - 0s - loss: 190.0770 - accuracy: 0.0000e+00 - val_loss: 66.3232 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/700\n",
      "12/12 - 0s - loss: 190.0122 - accuracy: 0.0000e+00 - val_loss: 66.3291 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/700\n",
      "12/12 - 0s - loss: 189.9294 - accuracy: 0.0000e+00 - val_loss: 66.3396 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/700\n",
      "12/12 - 0s - loss: 189.8298 - accuracy: 0.0000e+00 - val_loss: 66.3540 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/700\n",
      "12/12 - 0s - loss: 189.7166 - accuracy: 0.0000e+00 - val_loss: 66.3726 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/700\n",
      "12/12 - 0s - loss: 189.5891 - accuracy: 0.0000e+00 - val_loss: 66.3945 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/700\n",
      "12/12 - 0s - loss: 190.1709 - accuracy: 0.0000e+00 - val_loss: 66.3711 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/700\n",
      "12/12 - 0s - loss: 189.9751 - accuracy: 0.0000e+00 - val_loss: 66.3049 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/700\n",
      "12/12 - 0s - loss: 189.6289 - accuracy: 0.0000e+00 - val_loss: 66.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/700\n",
      "12/12 - 0s - loss: 189.7483 - accuracy: 0.0000e+00 - val_loss: 66.2073 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/700\n",
      "12/12 - 0s - loss: 189.8316 - accuracy: 0.0000e+00 - val_loss: 66.1731 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/700\n",
      "12/12 - 0s - loss: 189.8822 - accuracy: 0.0000e+00 - val_loss: 66.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/700\n",
      "12/12 - 0s - loss: 189.9028 - accuracy: 0.0000e+00 - val_loss: 66.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/700\n",
      "12/12 - 0s - loss: 189.8972 - accuracy: 0.0000e+00 - val_loss: 66.1206 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/700\n",
      "12/12 - 0s - loss: 189.8672 - accuracy: 0.0000e+00 - val_loss: 66.1167 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/700\n",
      "12/12 - 0s - loss: 189.8149 - accuracy: 0.0000e+00 - val_loss: 66.1191 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/700\n",
      "12/12 - 0s - loss: 189.7433 - accuracy: 0.0000e+00 - val_loss: 66.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/700\n",
      "12/12 - 0s - loss: 189.6539 - accuracy: 0.0000e+00 - val_loss: 66.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/700\n",
      "12/12 - 0s - loss: 189.5477 - accuracy: 0.0000e+00 - val_loss: 66.1553 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/700\n",
      "12/12 - 0s - loss: 189.4271 - accuracy: 0.0000e+00 - val_loss: 66.1741 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/700\n",
      "12/12 - 0s - loss: 189.9702 - accuracy: 0.0000e+00 - val_loss: 66.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/700\n",
      "12/12 - 0s - loss: 189.7202 - accuracy: 0.0000e+00 - val_loss: 66.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/700\n",
      "12/12 - 0s - loss: 189.4921 - accuracy: 0.0000e+00 - val_loss: 66.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/700\n",
      "12/12 - 0s - loss: 189.6208 - accuracy: 0.0000e+00 - val_loss: 65.9744 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/700\n",
      "12/12 - 0s - loss: 189.7119 - accuracy: 0.0000e+00 - val_loss: 65.9370 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/700\n",
      "12/12 - 0s - loss: 189.7688 - accuracy: 0.0000e+00 - val_loss: 65.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/700\n",
      "12/12 - 0s - loss: 189.7949 - accuracy: 0.0000e+00 - val_loss: 65.8916 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/700\n",
      "12/12 - 0s - loss: 189.7933 - accuracy: 0.0000e+00 - val_loss: 65.8799 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/700\n",
      "12/12 - 0s - loss: 189.7662 - accuracy: 0.0000e+00 - val_loss: 65.8752 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/700\n",
      "12/12 - 0s - loss: 189.7164 - accuracy: 0.0000e+00 - val_loss: 65.8772 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/700\n",
      "12/12 - 0s - loss: 189.6461 - accuracy: 0.0000e+00 - val_loss: 65.8833 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/700\n",
      "12/12 - 0s - loss: 189.5564 - accuracy: 0.0000e+00 - val_loss: 65.8945 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/700\n",
      "12/12 - 0s - loss: 189.4515 - accuracy: 0.0000e+00 - val_loss: 65.9104 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/700\n",
      "12/12 - 0s - loss: 189.3306 - accuracy: 0.0000e+00 - val_loss: 65.9314 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/700\n",
      "12/12 - 0s - loss: 189.3772 - accuracy: 0.0000e+00 - val_loss: 65.9028 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/700\n",
      "12/12 - 0s - loss: 189.2242 - accuracy: 0.0000e+00 - val_loss: 65.8828 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/700\n",
      "12/12 - 0s - loss: 189.2255 - accuracy: 0.0000e+00 - val_loss: 65.8706 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/700\n",
      "12/12 - 0s - loss: 189.1995 - accuracy: 0.0000e+00 - val_loss: 65.8655 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/700\n",
      "12/12 - 0s - loss: 189.3025 - accuracy: 0.0000e+00 - val_loss: 65.8137 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/700\n",
      "12/12 - 0s - loss: 189.2589 - accuracy: 0.0000e+00 - val_loss: 65.7720 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/700\n",
      "12/12 - 0s - loss: 189.3303 - accuracy: 0.0000e+00 - val_loss: 65.7412 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/700\n",
      "12/12 - 0s - loss: 189.3687 - accuracy: 0.0000e+00 - val_loss: 65.7180 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/700\n",
      "12/12 - 0s - loss: 189.3767 - accuracy: 0.0000e+00 - val_loss: 65.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/700\n",
      "12/12 - 0s - loss: 189.3593 - accuracy: 0.0000e+00 - val_loss: 65.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/700\n",
      "12/12 - 0s - loss: 189.3163 - accuracy: 0.0000e+00 - val_loss: 65.6948 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/700\n",
      "12/12 - 0s - loss: 189.2515 - accuracy: 0.0000e+00 - val_loss: 65.7004 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/700\n",
      "12/12 - 0s - loss: 189.1674 - accuracy: 0.0000e+00 - val_loss: 65.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/700\n",
      "12/12 - 0s - loss: 189.0654 - accuracy: 0.0000e+00 - val_loss: 65.7253 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/700\n",
      "12/12 - 0s - loss: 189.6876 - accuracy: 0.0000e+00 - val_loss: 65.6902 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/700\n",
      "12/12 - 0s - loss: 189.3044 - accuracy: 0.0000e+00 - val_loss: 65.6121 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/700\n",
      "12/12 - 0s - loss: 189.1917 - accuracy: 0.0000e+00 - val_loss: 65.5481 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/700\n",
      "12/12 - 0s - loss: 189.3426 - accuracy: 0.0000e+00 - val_loss: 65.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/700\n",
      "12/12 - 0s - loss: 189.4526 - accuracy: 0.0000e+00 - val_loss: 65.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/700\n",
      "12/12 - 0s - loss: 189.5251 - accuracy: 0.0000e+00 - val_loss: 66.9553 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/700\n",
      "12/12 - 0s - loss: 189.5642 - accuracy: 0.0000e+00 - val_loss: 67.3933 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/700\n",
      "12/12 - 0s - loss: 189.5729 - accuracy: 0.0000e+00 - val_loss: 67.2222 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/700\n",
      "12/12 - 0s - loss: 189.5544 - accuracy: 0.0000e+00 - val_loss: 66.5032 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/700\n",
      "12/12 - 0s - loss: 189.5105 - accuracy: 0.0000e+00 - val_loss: 65.3740 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/700\n",
      "12/12 - 0s - loss: 189.4449 - accuracy: 0.0000e+00 - val_loss: 65.3789 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/700\n",
      "12/12 - 0s - loss: 189.3586 - accuracy: 0.0000e+00 - val_loss: 65.3899 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/700\n",
      "12/12 - 0s - loss: 189.2542 - accuracy: 0.0000e+00 - val_loss: 65.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/700\n",
      "12/12 - 0s - loss: 189.1331 - accuracy: 0.0000e+00 - val_loss: 65.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/700\n",
      "12/12 - 0s - loss: 188.9975 - accuracy: 0.0000e+00 - val_loss: 65.4478 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/700\n",
      "12/12 - 0s - loss: 188.9511 - accuracy: 0.0000e+00 - val_loss: 65.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/700\n",
      "12/12 - 0s - loss: 188.8717 - accuracy: 0.0000e+00 - val_loss: 65.4011 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/700\n",
      "12/12 - 0s - loss: 188.8653 - accuracy: 0.0000e+00 - val_loss: 65.3914 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/700\n",
      "12/12 - 0s - loss: 188.8324 - accuracy: 0.0000e+00 - val_loss: 65.3867 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/700\n",
      "12/12 - 0s - loss: 189.0271 - accuracy: 0.0000e+00 - val_loss: 65.3337 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/700\n",
      "12/12 - 0s - loss: 188.8849 - accuracy: 0.0000e+00 - val_loss: 65.2917 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/700\n",
      "12/12 - 0s - loss: 188.9548 - accuracy: 0.0000e+00 - val_loss: 65.2603 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/700\n",
      "12/12 - 0s - loss: 188.9916 - accuracy: 0.0000e+00 - val_loss: 65.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/700\n",
      "12/12 - 0s - loss: 188.9968 - accuracy: 0.0000e+00 - val_loss: 65.2229 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/700\n",
      "12/12 - 0s - loss: 188.9748 - accuracy: 0.0000e+00 - val_loss: 65.2161 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/700\n",
      "12/12 - 0s - loss: 188.9273 - accuracy: 0.0000e+00 - val_loss: 65.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/700\n",
      "12/12 - 0s - loss: 188.8574 - accuracy: 0.0000e+00 - val_loss: 65.2214 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/700\n",
      "12/12 - 0s - loss: 188.7674 - accuracy: 0.0000e+00 - val_loss: 65.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/700\n",
      "12/12 - 0s - loss: 188.9326 - accuracy: 0.0000e+00 - val_loss: 65.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/700\n",
      "12/12 - 0s - loss: 188.7209 - accuracy: 0.0000e+00 - val_loss: 65.1636 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/700\n",
      "12/12 - 0s - loss: 188.7499 - accuracy: 0.0000e+00 - val_loss: 65.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/700\n",
      "12/12 - 0s - loss: 188.7493 - accuracy: 0.0000e+00 - val_loss: 65.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/700\n",
      "12/12 - 0s - loss: 188.7207 - accuracy: 0.0000e+00 - val_loss: 65.1248 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/700\n",
      "12/12 - 0s - loss: 188.6669 - accuracy: 0.0000e+00 - val_loss: 65.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/700\n",
      "12/12 - 0s - loss: 188.7884 - accuracy: 0.0000e+00 - val_loss: 65.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/700\n",
      "12/12 - 0s - loss: 188.6851 - accuracy: 0.0000e+00 - val_loss: 65.0376 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/700\n",
      "12/12 - 0s - loss: 188.7428 - accuracy: 0.0000e+00 - val_loss: 65.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/700\n",
      "12/12 - 0s - loss: 188.7663 - accuracy: 0.0000e+00 - val_loss: 64.9897 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/700\n",
      "12/12 - 0s - loss: 188.7597 - accuracy: 0.0000e+00 - val_loss: 64.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/700\n",
      "12/12 - 0s - loss: 188.7260 - accuracy: 0.0000e+00 - val_loss: 64.9746 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/700\n",
      "12/12 - 0s - loss: 188.6680 - accuracy: 0.0000e+00 - val_loss: 64.9771 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/700\n",
      "12/12 - 0s - loss: 188.5877 - accuracy: 0.0000e+00 - val_loss: 64.9846 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/700\n",
      "12/12 - 0s - loss: 188.6785 - accuracy: 0.0000e+00 - val_loss: 64.9417 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/700\n",
      "12/12 - 0s - loss: 188.5616 - accuracy: 0.0000e+00 - val_loss: 64.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/700\n",
      "12/12 - 0s - loss: 188.5996 - accuracy: 0.0000e+00 - val_loss: 64.8853 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/700\n",
      "12/12 - 0s - loss: 188.6067 - accuracy: 0.0000e+00 - val_loss: 64.8687 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/700\n",
      "12/12 - 0s - loss: 188.5842 - accuracy: 0.0000e+00 - val_loss: 64.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/700\n",
      "12/12 - 0s - loss: 188.5366 - accuracy: 0.0000e+00 - val_loss: 64.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/700\n",
      "12/12 - 0s - loss: 188.4655 - accuracy: 0.0000e+00 - val_loss: 64.8689 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/700\n",
      "12/12 - 0s - loss: 188.7258 - accuracy: 0.0000e+00 - val_loss: 64.8213 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/700\n",
      "12/12 - 0s - loss: 188.4552 - accuracy: 0.0000e+00 - val_loss: 64.7859 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/700\n",
      "12/12 - 0s - loss: 188.5007 - accuracy: 0.0000e+00 - val_loss: 64.7603 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/700\n",
      "12/12 - 0s - loss: 188.5142 - accuracy: 0.0000e+00 - val_loss: 64.7434 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/700\n",
      "12/12 - 0s - loss: 188.4972 - accuracy: 0.0000e+00 - val_loss: 64.7349 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/700\n",
      "12/12 - 0s - loss: 188.4541 - accuracy: 0.0000e+00 - val_loss: 64.7324 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/700\n",
      "12/12 - 0s - loss: 188.3865 - accuracy: 0.0000e+00 - val_loss: 64.7366 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/700\n",
      "12/12 - 0s - loss: 188.5168 - accuracy: 0.0000e+00 - val_loss: 64.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/700\n",
      "12/12 - 0s - loss: 188.3839 - accuracy: 0.0000e+00 - val_loss: 64.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/700\n",
      "12/12 - 0s - loss: 188.4346 - accuracy: 0.0000e+00 - val_loss: 64.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/700\n",
      "12/12 - 0s - loss: 188.4510 - accuracy: 0.0000e+00 - val_loss: 64.6077 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/700\n",
      "12/12 - 0s - loss: 188.4368 - accuracy: 0.0000e+00 - val_loss: 64.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/700\n",
      "12/12 - 0s - loss: 188.3956 - accuracy: 0.0000e+00 - val_loss: 64.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/700\n",
      "12/12 - 0s - loss: 188.3299 - accuracy: 0.0000e+00 - val_loss: 64.5984 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/700\n",
      "12/12 - 0s - loss: 188.2407 - accuracy: 0.0000e+00 - val_loss: 64.6091 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/700\n",
      "12/12 - 0s - loss: 188.7579 - accuracy: 0.0000e+00 - val_loss: 64.5659 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/700\n",
      "12/12 - 0s - loss: 188.2128 - accuracy: 0.0000e+00 - val_loss: 64.4729 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/700\n",
      "12/12 - 0s - loss: 188.4400 - accuracy: 0.0000e+00 - val_loss: 64.3970 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/700\n",
      "12/12 - 0s - loss: 188.6221 - accuracy: 0.0000e+00 - val_loss: 65.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/700\n",
      "12/12 - 0s - loss: 188.7578 - accuracy: 0.0000e+00 - val_loss: 67.4104 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/700\n",
      "12/12 - 0s - loss: 188.8508 - accuracy: 0.0000e+00 - val_loss: 68.8997 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/700\n",
      "12/12 - 0s - loss: 188.9064 - accuracy: 0.0000e+00 - val_loss: 69.6228 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/700\n",
      "12/12 - 0s - loss: 188.9266 - accuracy: 0.0000e+00 - val_loss: 69.6523 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/700\n",
      "12/12 - 0s - loss: 188.9152 - accuracy: 0.0000e+00 - val_loss: 69.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/700\n",
      "12/12 - 0s - loss: 188.8762 - accuracy: 0.0000e+00 - val_loss: 67.8943 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/700\n",
      "12/12 - 0s - loss: 188.8113 - accuracy: 0.0000e+00 - val_loss: 66.2236 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/700\n",
      "12/12 - 0s - loss: 188.7244 - accuracy: 0.0000e+00 - val_loss: 64.1956 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/700\n",
      "12/12 - 0s - loss: 188.6165 - accuracy: 0.0000e+00 - val_loss: 64.2104 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/700\n",
      "12/12 - 0s - loss: 188.4892 - accuracy: 0.0000e+00 - val_loss: 64.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/700\n",
      "12/12 - 0s - loss: 188.3455 - accuracy: 0.0000e+00 - val_loss: 64.2559 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/700\n",
      "12/12 - 0s - loss: 188.1863 - accuracy: 0.0000e+00 - val_loss: 64.2849 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/700\n",
      "12/12 - 0s - loss: 188.0134 - accuracy: 0.0000e+00 - val_loss: 64.3171 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/700\n",
      "12/12 - 0s - loss: 188.9659 - accuracy: 0.0000e+00 - val_loss: 64.2922 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/700\n",
      "12/12 - 0s - loss: 188.8241 - accuracy: 0.0000e+00 - val_loss: 64.2156 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/700\n",
      "12/12 - 0s - loss: 188.0149 - accuracy: 0.0000e+00 - val_loss: 64.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/700\n",
      "12/12 - 0s - loss: 188.1473 - accuracy: 0.0000e+00 - val_loss: 64.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/700\n",
      "12/12 - 0s - loss: 188.2377 - accuracy: 0.0000e+00 - val_loss: 64.0662 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/700\n",
      "12/12 - 0s - loss: 188.2887 - accuracy: 0.0000e+00 - val_loss: 64.0383 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/700\n",
      "12/12 - 0s - loss: 188.3054 - accuracy: 0.0000e+00 - val_loss: 64.0188 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/700\n",
      "12/12 - 0s - loss: 188.2902 - accuracy: 0.0000e+00 - val_loss: 64.0088 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/700\n",
      "12/12 - 0s - loss: 188.2467 - accuracy: 0.0000e+00 - val_loss: 64.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/700\n",
      "12/12 - 0s - loss: 188.1781 - accuracy: 0.0000e+00 - val_loss: 64.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/700\n",
      "12/12 - 0s - loss: 188.0862 - accuracy: 0.0000e+00 - val_loss: 64.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/700\n",
      "12/12 - 0s - loss: 187.9728 - accuracy: 0.0000e+00 - val_loss: 64.0371 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/700\n",
      "12/12 - 0s - loss: 187.8409 - accuracy: 0.0000e+00 - val_loss: 64.0586 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/700\n",
      "12/12 - 0s - loss: 188.4969 - accuracy: 0.0000e+00 - val_loss: 64.0225 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/700\n",
      "12/12 - 0s - loss: 188.1294 - accuracy: 0.0000e+00 - val_loss: 63.9358 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/700\n",
      "12/12 - 0s - loss: 187.9506 - accuracy: 0.0000e+00 - val_loss: 63.8630 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/700\n",
      "12/12 - 0s - loss: 188.1141 - accuracy: 0.0000e+00 - val_loss: 63.8042 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/700\n",
      "12/12 - 0s - loss: 188.2321 - accuracy: 0.0000e+00 - val_loss: 63.7593 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/700\n",
      "12/12 - 0s - loss: 188.3077 - accuracy: 0.0000e+00 - val_loss: 64.7522 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/700\n",
      "12/12 - 0s - loss: 188.3453 - accuracy: 0.0000e+00 - val_loss: 65.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/700\n",
      "12/12 - 0s - loss: 188.3495 - accuracy: 0.0000e+00 - val_loss: 64.8076 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/700\n",
      "12/12 - 0s - loss: 188.3234 - accuracy: 0.0000e+00 - val_loss: 63.8782 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/700\n",
      "12/12 - 0s - loss: 188.2690 - accuracy: 0.0000e+00 - val_loss: 63.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/700\n",
      "12/12 - 0s - loss: 188.1887 - accuracy: 0.0000e+00 - val_loss: 63.6841 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/700\n",
      "12/12 - 0s - loss: 188.0861 - accuracy: 0.0000e+00 - val_loss: 63.6958 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/700\n",
      "12/12 - 0s - loss: 187.9631 - accuracy: 0.0000e+00 - val_loss: 63.7170 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/700\n",
      "12/12 - 0s - loss: 187.8228 - accuracy: 0.0000e+00 - val_loss: 63.7400 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/700\n",
      "12/12 - 0s - loss: 187.6650 - accuracy: 0.0000e+00 - val_loss: 63.7683 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/700\n",
      "12/12 - 0s - loss: 188.1948 - accuracy: 0.0000e+00 - val_loss: 63.7375 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/700\n",
      "12/12 - 0s - loss: 187.9373 - accuracy: 0.0000e+00 - val_loss: 63.6526 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/700\n",
      "12/12 - 0s - loss: 187.7193 - accuracy: 0.0000e+00 - val_loss: 63.5833 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/700\n",
      "12/12 - 0s - loss: 187.8712 - accuracy: 0.0000e+00 - val_loss: 63.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/700\n",
      "12/12 - 0s - loss: 187.9773 - accuracy: 0.0000e+00 - val_loss: 63.4851 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/700\n",
      "12/12 - 0s - loss: 188.0420 - accuracy: 0.0000e+00 - val_loss: 63.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/700\n",
      "12/12 - 0s - loss: 188.0693 - accuracy: 0.0000e+00 - val_loss: 63.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/700\n",
      "12/12 - 0s - loss: 188.0636 - accuracy: 0.0000e+00 - val_loss: 63.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/700\n",
      "12/12 - 0s - loss: 188.0269 - accuracy: 0.0000e+00 - val_loss: 63.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/700\n",
      "12/12 - 0s - loss: 187.9637 - accuracy: 0.0000e+00 - val_loss: 63.4150 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/700\n",
      "12/12 - 0s - loss: 187.8745 - accuracy: 0.0000e+00 - val_loss: 63.4243 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/700\n",
      "12/12 - 0s - loss: 187.7639 - accuracy: 0.0000e+00 - val_loss: 63.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/700\n",
      "12/12 - 0s - loss: 187.6334 - accuracy: 0.0000e+00 - val_loss: 63.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/700\n",
      "12/12 - 0s - loss: 187.4838 - accuracy: 0.0000e+00 - val_loss: 63.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/700\n",
      "12/12 - 0s - loss: 187.8033 - accuracy: 0.0000e+00 - val_loss: 63.4517 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/700\n",
      "12/12 - 0s - loss: 187.4836 - accuracy: 0.0000e+00 - val_loss: 63.3630 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/700\n",
      "12/12 - 0s - loss: 187.5674 - accuracy: 0.0000e+00 - val_loss: 63.2886 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/700\n",
      "12/12 - 0s - loss: 187.7294 - accuracy: 0.0000e+00 - val_loss: 63.2307 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/700\n",
      "12/12 - 0s - loss: 187.8448 - accuracy: 0.0000e+00 - val_loss: 63.2603 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/700\n",
      "12/12 - 0s - loss: 187.9164 - accuracy: 0.0000e+00 - val_loss: 64.3015 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/700\n",
      "12/12 - 0s - loss: 187.9500 - accuracy: 0.0000e+00 - val_loss: 64.5698 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/700\n",
      "12/12 - 0s - loss: 187.9491 - accuracy: 0.0000e+00 - val_loss: 64.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/700\n",
      "12/12 - 0s - loss: 187.9162 - accuracy: 0.0000e+00 - val_loss: 63.1060 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/700\n",
      "12/12 - 0s - loss: 187.8563 - accuracy: 0.0000e+00 - val_loss: 63.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/700\n",
      "12/12 - 0s - loss: 187.7695 - accuracy: 0.0000e+00 - val_loss: 63.1155 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/700\n",
      "12/12 - 0s - loss: 187.6598 - accuracy: 0.0000e+00 - val_loss: 63.1311 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/700\n",
      "12/12 - 0s - loss: 187.5291 - accuracy: 0.0000e+00 - val_loss: 63.1514 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/700\n",
      "12/12 - 0s - loss: 187.3805 - accuracy: 0.0000e+00 - val_loss: 63.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/700\n",
      "12/12 - 0s - loss: 187.2148 - accuracy: 0.0000e+00 - val_loss: 63.2065 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/700\n",
      "12/12 - 0s - loss: 187.9721 - accuracy: 0.0000e+00 - val_loss: 63.1753 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/700\n",
      "12/12 - 0s - loss: 187.7163 - accuracy: 0.0000e+00 - val_loss: 63.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/700\n",
      "12/12 - 0s - loss: 187.2655 - accuracy: 0.0000e+00 - val_loss: 63.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/700\n",
      "12/12 - 0s - loss: 187.4215 - accuracy: 0.0000e+00 - val_loss: 62.9585 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/700\n",
      "12/12 - 0s - loss: 187.5296 - accuracy: 0.0000e+00 - val_loss: 62.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/700\n",
      "12/12 - 0s - loss: 187.5964 - accuracy: 0.0000e+00 - val_loss: 62.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/700\n",
      "12/12 - 0s - loss: 187.6241 - accuracy: 0.0000e+00 - val_loss: 62.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/700\n",
      "12/12 - 0s - loss: 187.6167 - accuracy: 0.0000e+00 - val_loss: 62.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/700\n",
      "12/12 - 0s - loss: 187.5775 - accuracy: 0.0000e+00 - val_loss: 62.8401 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/700\n",
      "12/12 - 0s - loss: 187.5107 - accuracy: 0.0000e+00 - val_loss: 62.8435 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/700\n",
      "12/12 - 0s - loss: 187.4180 - accuracy: 0.0000e+00 - val_loss: 62.8530 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/700\n",
      "12/12 - 0s - loss: 187.3033 - accuracy: 0.0000e+00 - val_loss: 62.8696 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/700\n",
      "12/12 - 0s - loss: 187.1673 - accuracy: 0.0000e+00 - val_loss: 62.8911 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/700\n",
      "12/12 - 0s - loss: 187.0119 - accuracy: 0.0000e+00 - val_loss: 62.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/700\n",
      "12/12 - 0s - loss: 187.6477 - accuracy: 0.0000e+00 - val_loss: 62.8823 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/700\n",
      "12/12 - 0s - loss: 187.3176 - accuracy: 0.0000e+00 - val_loss: 62.7913 - val_accuracy: 0.0000e+00\n",
      "Epoch 501/700\n",
      "12/12 - 0s - loss: 187.0976 - accuracy: 0.0000e+00 - val_loss: 62.7141 - val_accuracy: 0.0000e+00\n",
      "Epoch 502/700\n",
      "12/12 - 0s - loss: 187.2658 - accuracy: 0.0000e+00 - val_loss: 62.6536 - val_accuracy: 0.0000e+00\n",
      "Epoch 503/700\n",
      "12/12 - 0s - loss: 187.3836 - accuracy: 0.0000e+00 - val_loss: 62.6055 - val_accuracy: 0.0000e+00\n",
      "Epoch 504/700\n",
      "12/12 - 0s - loss: 187.4588 - accuracy: 0.0000e+00 - val_loss: 62.8018 - val_accuracy: 0.0000e+00\n",
      "Epoch 505/700\n",
      "12/12 - 0s - loss: 187.4940 - accuracy: 0.0000e+00 - val_loss: 63.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 506/700\n",
      "12/12 - 0s - loss: 187.4924 - accuracy: 0.0000e+00 - val_loss: 62.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/700\n",
      "12/12 - 0s - loss: 187.4587 - accuracy: 0.0000e+00 - val_loss: 62.5244 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/700\n",
      "12/12 - 0s - loss: 187.3960 - accuracy: 0.0000e+00 - val_loss: 62.5261 - val_accuracy: 0.0000e+00\n",
      "Epoch 509/700\n",
      "12/12 - 0s - loss: 187.3062 - accuracy: 0.0000e+00 - val_loss: 62.5349 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 510/700\n",
      "12/12 - 0s - loss: 187.1925 - accuracy: 0.0000e+00 - val_loss: 62.5508 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/700\n",
      "12/12 - 0s - loss: 187.0582 - accuracy: 0.0000e+00 - val_loss: 62.5718 - val_accuracy: 0.0000e+00\n",
      "Epoch 512/700\n",
      "12/12 - 0s - loss: 186.9036 - accuracy: 0.0000e+00 - val_loss: 62.5979 - val_accuracy: 0.0000e+00\n",
      "Epoch 513/700\n",
      "12/12 - 0s - loss: 186.7668 - accuracy: 0.0000e+00 - val_loss: 62.5605 - val_accuracy: 0.0000e+00\n",
      "Epoch 514/700\n",
      "12/12 - 0s - loss: 186.7719 - accuracy: 0.0000e+00 - val_loss: 62.5339 - val_accuracy: 0.0000e+00\n",
      "Epoch 515/700\n",
      "12/12 - 0s - loss: 186.7728 - accuracy: 0.0000e+00 - val_loss: 62.5188 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/700\n",
      "12/12 - 0s - loss: 186.7419 - accuracy: 0.0000e+00 - val_loss: 62.5105 - val_accuracy: 0.0000e+00\n",
      "Epoch 517/700\n",
      "12/12 - 0s - loss: 186.6812 - accuracy: 0.0000e+00 - val_loss: 62.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 518/700\n",
      "12/12 - 0s - loss: 187.0736 - accuracy: 0.0000e+00 - val_loss: 62.4521 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/700\n",
      "12/12 - 0s - loss: 186.7084 - accuracy: 0.0000e+00 - val_loss: 62.4060 - val_accuracy: 0.0000e+00\n",
      "Epoch 520/700\n",
      "12/12 - 0s - loss: 186.7790 - accuracy: 0.0000e+00 - val_loss: 62.3699 - val_accuracy: 0.0000e+00\n",
      "Epoch 521/700\n",
      "12/12 - 0s - loss: 186.8099 - accuracy: 0.0000e+00 - val_loss: 62.3467 - val_accuracy: 0.0000e+00\n",
      "Epoch 522/700\n",
      "12/12 - 0s - loss: 186.8041 - accuracy: 0.0000e+00 - val_loss: 62.3318 - val_accuracy: 0.0000e+00\n",
      "Epoch 523/700\n",
      "12/12 - 0s - loss: 186.7665 - accuracy: 0.0000e+00 - val_loss: 62.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 524/700\n",
      "12/12 - 0s - loss: 186.6984 - accuracy: 0.0000e+00 - val_loss: 62.3284 - val_accuracy: 0.0000e+00\n",
      "Epoch 525/700\n",
      "12/12 - 0s - loss: 186.6042 - accuracy: 0.0000e+00 - val_loss: 62.3389 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/700\n",
      "12/12 - 0s - loss: 186.8301 - accuracy: 0.0000e+00 - val_loss: 62.2859 - val_accuracy: 0.0000e+00\n",
      "Epoch 527/700\n",
      "12/12 - 0s - loss: 186.5764 - accuracy: 0.0000e+00 - val_loss: 62.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 528/700\n",
      "12/12 - 0s - loss: 186.6246 - accuracy: 0.0000e+00 - val_loss: 62.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 529/700\n",
      "12/12 - 0s - loss: 186.6340 - accuracy: 0.0000e+00 - val_loss: 62.1987 - val_accuracy: 0.0000e+00\n",
      "Epoch 530/700\n",
      "12/12 - 0s - loss: 186.6094 - accuracy: 0.0000e+00 - val_loss: 62.1899 - val_accuracy: 0.0000e+00\n",
      "Epoch 531/700\n",
      "12/12 - 0s - loss: 186.5539 - accuracy: 0.0000e+00 - val_loss: 62.1897 - val_accuracy: 0.0000e+00\n",
      "Epoch 532/700\n",
      "12/12 - 0s - loss: 186.4697 - accuracy: 0.0000e+00 - val_loss: 62.1951 - val_accuracy: 0.0000e+00\n",
      "Epoch 533/700\n",
      "12/12 - 0s - loss: 186.8166 - accuracy: 0.0000e+00 - val_loss: 62.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 534/700\n",
      "12/12 - 0s - loss: 186.4602 - accuracy: 0.0000e+00 - val_loss: 62.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 535/700\n",
      "12/12 - 0s - loss: 186.5173 - accuracy: 0.0000e+00 - val_loss: 62.0642 - val_accuracy: 0.0000e+00\n",
      "Epoch 536/700\n",
      "12/12 - 0s - loss: 186.5338 - accuracy: 0.0000e+00 - val_loss: 62.0437 - val_accuracy: 0.0000e+00\n",
      "Epoch 537/700\n",
      "12/12 - 0s - loss: 186.5149 - accuracy: 0.0000e+00 - val_loss: 62.0337 - val_accuracy: 0.0000e+00\n",
      "Epoch 538/700\n",
      "12/12 - 0s - loss: 186.4648 - accuracy: 0.0000e+00 - val_loss: 62.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 539/700\n",
      "12/12 - 0s - loss: 186.3862 - accuracy: 0.0000e+00 - val_loss: 62.0366 - val_accuracy: 0.0000e+00\n",
      "Epoch 540/700\n",
      "12/12 - 0s - loss: 186.5088 - accuracy: 0.0000e+00 - val_loss: 61.9783 - val_accuracy: 0.0000e+00\n",
      "Epoch 541/700\n",
      "12/12 - 0s - loss: 186.3860 - accuracy: 0.0000e+00 - val_loss: 61.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 542/700\n",
      "12/12 - 0s - loss: 186.4467 - accuracy: 0.0000e+00 - val_loss: 61.9009 - val_accuracy: 0.0000e+00\n",
      "Epoch 543/700\n",
      "12/12 - 0s - loss: 186.4670 - accuracy: 0.0000e+00 - val_loss: 61.8794 - val_accuracy: 0.0000e+00\n",
      "Epoch 544/700\n",
      "12/12 - 0s - loss: 186.4518 - accuracy: 0.0000e+00 - val_loss: 61.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 545/700\n",
      "12/12 - 0s - loss: 186.4041 - accuracy: 0.0000e+00 - val_loss: 61.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 546/700\n",
      "12/12 - 0s - loss: 186.3270 - accuracy: 0.0000e+00 - val_loss: 61.8689 - val_accuracy: 0.0000e+00\n",
      "Epoch 547/700\n",
      "12/12 - 0s - loss: 186.2239 - accuracy: 0.0000e+00 - val_loss: 61.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/700\n",
      "12/12 - 0s - loss: 186.7316 - accuracy: 0.0000e+00 - val_loss: 61.8284 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/700\n",
      "12/12 - 0s - loss: 186.1824 - accuracy: 0.0000e+00 - val_loss: 61.7893 - val_accuracy: 0.0000e+00\n",
      "Epoch 550/700\n",
      "12/12 - 0s - loss: 186.2270 - accuracy: 0.0000e+00 - val_loss: 61.7598 - val_accuracy: 0.0000e+00\n",
      "Epoch 551/700\n",
      "12/12 - 0s - loss: 186.2314 - accuracy: 0.0000e+00 - val_loss: 61.7432 - val_accuracy: 0.0000e+00\n",
      "Epoch 552/700\n",
      "12/12 - 0s - loss: 186.2023 - accuracy: 0.0000e+00 - val_loss: 61.7349 - val_accuracy: 0.0000e+00\n",
      "Epoch 553/700\n",
      "12/12 - 0s - loss: 186.1419 - accuracy: 0.0000e+00 - val_loss: 61.7346 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/700\n",
      "12/12 - 0s - loss: 186.3030 - accuracy: 0.0000e+00 - val_loss: 61.6711 - val_accuracy: 0.0000e+00\n",
      "Epoch 555/700\n",
      "12/12 - 0s - loss: 186.1749 - accuracy: 0.0000e+00 - val_loss: 61.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 556/700\n",
      "12/12 - 0s - loss: 186.2507 - accuracy: 0.0000e+00 - val_loss: 61.5837 - val_accuracy: 0.0000e+00\n",
      "Epoch 557/700\n",
      "12/12 - 0s - loss: 186.2839 - accuracy: 0.0000e+00 - val_loss: 61.5586 - val_accuracy: 0.0000e+00\n",
      "Epoch 558/700\n",
      "12/12 - 0s - loss: 186.2805 - accuracy: 0.0000e+00 - val_loss: 61.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 559/700\n",
      "12/12 - 0s - loss: 186.2427 - accuracy: 0.0000e+00 - val_loss: 61.5378 - val_accuracy: 0.0000e+00\n",
      "Epoch 560/700\n",
      "12/12 - 0s - loss: 186.1741 - accuracy: 0.0000e+00 - val_loss: 61.5408 - val_accuracy: 0.0000e+00\n",
      "Epoch 561/700\n",
      "12/12 - 0s - loss: 186.0774 - accuracy: 0.0000e+00 - val_loss: 61.5505 - val_accuracy: 0.0000e+00\n",
      "Epoch 562/700\n",
      "12/12 - 0s - loss: 185.9651 - accuracy: 0.0000e+00 - val_loss: 61.4944 - val_accuracy: 0.0000e+00\n",
      "Epoch 563/700\n",
      "12/12 - 0s - loss: 186.0505 - accuracy: 0.0000e+00 - val_loss: 61.4517 - val_accuracy: 0.0000e+00\n",
      "Epoch 564/700\n",
      "12/12 - 0s - loss: 186.1012 - accuracy: 0.0000e+00 - val_loss: 61.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 565/700\n",
      "12/12 - 0s - loss: 186.1118 - accuracy: 0.0000e+00 - val_loss: 61.4019 - val_accuracy: 0.0000e+00\n",
      "Epoch 566/700\n",
      "12/12 - 0s - loss: 186.0872 - accuracy: 0.0000e+00 - val_loss: 61.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 567/700\n",
      "12/12 - 0s - loss: 186.0300 - accuracy: 0.0000e+00 - val_loss: 61.3923 - val_accuracy: 0.0000e+00\n",
      "Epoch 568/700\n",
      "12/12 - 0s - loss: 185.9436 - accuracy: 0.0000e+00 - val_loss: 61.3994 - val_accuracy: 0.0000e+00\n",
      "Epoch 569/700\n",
      "12/12 - 0s - loss: 185.9083 - accuracy: 0.0000e+00 - val_loss: 61.3394 - val_accuracy: 0.0000e+00\n",
      "Epoch 570/700\n",
      "12/12 - 0s - loss: 185.9351 - accuracy: 0.0000e+00 - val_loss: 61.2944 - val_accuracy: 0.0000e+00\n",
      "Epoch 571/700\n",
      "12/12 - 0s - loss: 185.9943 - accuracy: 0.0000e+00 - val_loss: 61.2617 - val_accuracy: 0.0000e+00\n",
      "Epoch 572/700\n",
      "12/12 - 0s - loss: 186.0129 - accuracy: 0.0000e+00 - val_loss: 61.2400 - val_accuracy: 0.0000e+00\n",
      "Epoch 573/700\n",
      "12/12 - 0s - loss: 185.9947 - accuracy: 0.0000e+00 - val_loss: 61.2292 - val_accuracy: 0.0000e+00\n",
      "Epoch 574/700\n",
      "12/12 - 0s - loss: 185.9429 - accuracy: 0.0000e+00 - val_loss: 61.2258 - val_accuracy: 0.0000e+00\n",
      "Epoch 575/700\n",
      "12/12 - 0s - loss: 185.8614 - accuracy: 0.0000e+00 - val_loss: 61.2324 - val_accuracy: 0.0000e+00\n",
      "Epoch 576/700\n",
      "12/12 - 0s - loss: 185.7526 - accuracy: 0.0000e+00 - val_loss: 61.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 577/700\n",
      "12/12 - 0s - loss: 186.2692 - accuracy: 0.0000e+00 - val_loss: 61.1909 - val_accuracy: 0.0000e+00\n",
      "Epoch 578/700\n",
      "12/12 - 0s - loss: 185.7078 - accuracy: 0.0000e+00 - val_loss: 61.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 579/700\n",
      "12/12 - 0s - loss: 185.7511 - accuracy: 0.0000e+00 - val_loss: 61.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 580/700\n",
      "12/12 - 0s - loss: 185.7552 - accuracy: 0.0000e+00 - val_loss: 61.1033 - val_accuracy: 0.0000e+00\n",
      "Epoch 581/700\n",
      "12/12 - 0s - loss: 185.7240 - accuracy: 0.0000e+00 - val_loss: 61.0950 - val_accuracy: 0.0000e+00\n",
      "Epoch 582/700\n",
      "12/12 - 0s - loss: 185.6608 - accuracy: 0.0000e+00 - val_loss: 61.0959 - val_accuracy: 0.0000e+00\n",
      "Epoch 583/700\n",
      "12/12 - 0s - loss: 185.8678 - accuracy: 0.0000e+00 - val_loss: 61.0298 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584/700\n",
      "12/12 - 0s - loss: 185.6927 - accuracy: 0.0000e+00 - val_loss: 60.9775 - val_accuracy: 0.0000e+00\n",
      "Epoch 585/700\n",
      "12/12 - 0s - loss: 185.7709 - accuracy: 0.0000e+00 - val_loss: 60.9404 - val_accuracy: 0.0000e+00\n",
      "Epoch 586/700\n",
      "12/12 - 0s - loss: 185.8050 - accuracy: 0.0000e+00 - val_loss: 60.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 587/700\n",
      "12/12 - 0s - loss: 185.8003 - accuracy: 0.0000e+00 - val_loss: 60.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 588/700\n",
      "12/12 - 0s - loss: 185.7608 - accuracy: 0.0000e+00 - val_loss: 60.8918 - val_accuracy: 0.0000e+00\n",
      "Epoch 589/700\n",
      "12/12 - 0s - loss: 185.6901 - accuracy: 0.0000e+00 - val_loss: 60.8940 - val_accuracy: 0.0000e+00\n",
      "Epoch 590/700\n",
      "12/12 - 0s - loss: 185.5903 - accuracy: 0.0000e+00 - val_loss: 60.9058 - val_accuracy: 0.0000e+00\n",
      "Epoch 591/700\n",
      "12/12 - 0s - loss: 185.5382 - accuracy: 0.0000e+00 - val_loss: 60.8474 - val_accuracy: 0.0000e+00\n",
      "Epoch 592/700\n",
      "12/12 - 0s - loss: 185.5616 - accuracy: 0.0000e+00 - val_loss: 60.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 593/700\n",
      "12/12 - 0s - loss: 185.6138 - accuracy: 0.0000e+00 - val_loss: 60.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 594/700\n",
      "12/12 - 0s - loss: 185.6249 - accuracy: 0.0000e+00 - val_loss: 60.7524 - val_accuracy: 0.0000e+00\n",
      "Epoch 595/700\n",
      "12/12 - 0s - loss: 185.5995 - accuracy: 0.0000e+00 - val_loss: 60.7417 - val_accuracy: 0.0000e+00\n",
      "Epoch 596/700\n",
      "12/12 - 0s - loss: 185.5405 - accuracy: 0.0000e+00 - val_loss: 60.7419 - val_accuracy: 0.0000e+00\n",
      "Epoch 597/700\n",
      "12/12 - 0s - loss: 185.4517 - accuracy: 0.0000e+00 - val_loss: 60.7483 - val_accuracy: 0.0000e+00\n",
      "Epoch 598/700\n",
      "12/12 - 0s - loss: 185.4810 - accuracy: 0.0000e+00 - val_loss: 60.6877 - val_accuracy: 0.0000e+00\n",
      "Epoch 599/700\n",
      "12/12 - 0s - loss: 185.4438 - accuracy: 0.0000e+00 - val_loss: 60.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 600/700\n",
      "12/12 - 0s - loss: 185.5047 - accuracy: 0.0000e+00 - val_loss: 60.6064 - val_accuracy: 0.0000e+00\n",
      "Epoch 601/700\n",
      "12/12 - 0s - loss: 185.5233 - accuracy: 0.0000e+00 - val_loss: 60.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 602/700\n",
      "12/12 - 0s - loss: 185.5042 - accuracy: 0.0000e+00 - val_loss: 60.5730 - val_accuracy: 0.0000e+00\n",
      "Epoch 603/700\n",
      "12/12 - 0s - loss: 185.4520 - accuracy: 0.0000e+00 - val_loss: 60.5708 - val_accuracy: 0.0000e+00\n",
      "Epoch 604/700\n",
      "12/12 - 0s - loss: 185.3674 - accuracy: 0.0000e+00 - val_loss: 60.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 605/700\n",
      "12/12 - 0s - loss: 185.2561 - accuracy: 0.0000e+00 - val_loss: 60.5896 - val_accuracy: 0.0000e+00\n",
      "Epoch 606/700\n",
      "12/12 - 0s - loss: 185.8454 - accuracy: 0.0000e+00 - val_loss: 60.5330 - val_accuracy: 0.0000e+00\n",
      "Epoch 607/700\n",
      "12/12 - 0s - loss: 185.2100 - accuracy: 0.0000e+00 - val_loss: 60.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 608/700\n",
      "12/12 - 0s - loss: 185.2546 - accuracy: 0.0000e+00 - val_loss: 60.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 609/700\n",
      "12/12 - 0s - loss: 185.2598 - accuracy: 0.0000e+00 - val_loss: 60.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 610/700\n",
      "12/12 - 0s - loss: 185.2278 - accuracy: 0.0000e+00 - val_loss: 60.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 611/700\n",
      "12/12 - 0s - loss: 185.1616 - accuracy: 0.0000e+00 - val_loss: 60.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 612/700\n",
      "12/12 - 0s - loss: 185.4227 - accuracy: 0.0000e+00 - val_loss: 60.3662 - val_accuracy: 0.0000e+00\n",
      "Epoch 613/700\n",
      "12/12 - 0s - loss: 185.1956 - accuracy: 0.0000e+00 - val_loss: 60.3135 - val_accuracy: 0.0000e+00\n",
      "Epoch 614/700\n",
      "12/12 - 0s - loss: 185.2755 - accuracy: 0.0000e+00 - val_loss: 60.2749 - val_accuracy: 0.0000e+00\n",
      "Epoch 615/700\n",
      "12/12 - 0s - loss: 185.3114 - accuracy: 0.0000e+00 - val_loss: 60.2468 - val_accuracy: 0.0000e+00\n",
      "Epoch 616/700\n",
      "12/12 - 0s - loss: 185.3068 - accuracy: 0.0000e+00 - val_loss: 60.2312 - val_accuracy: 0.0000e+00\n",
      "Epoch 617/700\n",
      "12/12 - 0s - loss: 185.2670 - accuracy: 0.0000e+00 - val_loss: 60.2241 - val_accuracy: 0.0000e+00\n",
      "Epoch 618/700\n",
      "12/12 - 0s - loss: 185.1934 - accuracy: 0.0000e+00 - val_loss: 60.2275 - val_accuracy: 0.0000e+00\n",
      "Epoch 619/700\n",
      "12/12 - 0s - loss: 185.0906 - accuracy: 0.0000e+00 - val_loss: 60.2385 - val_accuracy: 0.0000e+00\n",
      "Epoch 620/700\n",
      "12/12 - 0s - loss: 185.0689 - accuracy: 0.0000e+00 - val_loss: 60.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 621/700\n",
      "12/12 - 0s - loss: 185.0628 - accuracy: 0.0000e+00 - val_loss: 60.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 622/700\n",
      "12/12 - 0s - loss: 185.1168 - accuracy: 0.0000e+00 - val_loss: 60.1018 - val_accuracy: 0.0000e+00\n",
      "Epoch 623/700\n",
      "12/12 - 0s - loss: 185.1285 - accuracy: 0.0000e+00 - val_loss: 60.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 624/700\n",
      "12/12 - 0s - loss: 185.1021 - accuracy: 0.0000e+00 - val_loss: 60.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 625/700\n",
      "12/12 - 0s - loss: 185.0421 - accuracy: 0.0000e+00 - val_loss: 60.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 626/700\n",
      "12/12 - 0s - loss: 184.9507 - accuracy: 0.0000e+00 - val_loss: 60.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 627/700\n",
      "12/12 - 0s - loss: 184.9967 - accuracy: 0.0000e+00 - val_loss: 60.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 628/700\n",
      "12/12 - 0s - loss: 184.9423 - accuracy: 0.0000e+00 - val_loss: 59.9644 - val_accuracy: 0.0000e+00\n",
      "Epoch 629/700\n",
      "12/12 - 0s - loss: 185.0056 - accuracy: 0.0000e+00 - val_loss: 59.9297 - val_accuracy: 0.0000e+00\n",
      "Epoch 630/700\n",
      "12/12 - 0s - loss: 185.0253 - accuracy: 0.0000e+00 - val_loss: 59.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 631/700\n",
      "12/12 - 0s - loss: 185.0057 - accuracy: 0.0000e+00 - val_loss: 59.8940 - val_accuracy: 0.0000e+00\n",
      "Epoch 632/700\n",
      "12/12 - 0s - loss: 184.9521 - accuracy: 0.0000e+00 - val_loss: 59.8906 - val_accuracy: 0.0000e+00\n",
      "Epoch 633/700\n",
      "12/12 - 0s - loss: 184.8658 - accuracy: 0.0000e+00 - val_loss: 59.8975 - val_accuracy: 0.0000e+00\n",
      "Epoch 634/700\n",
      "12/12 - 0s - loss: 184.7512 - accuracy: 0.0000e+00 - val_loss: 59.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 635/700\n",
      "12/12 - 0s - loss: 185.3577 - accuracy: 0.0000e+00 - val_loss: 59.8533 - val_accuracy: 0.0000e+00\n",
      "Epoch 636/700\n",
      "12/12 - 0s - loss: 184.7041 - accuracy: 0.0000e+00 - val_loss: 59.8083 - val_accuracy: 0.0000e+00\n",
      "Epoch 637/700\n",
      "12/12 - 0s - loss: 184.7511 - accuracy: 0.0000e+00 - val_loss: 59.7788 - val_accuracy: 0.0000e+00\n",
      "Epoch 638/700\n",
      "12/12 - 0s - loss: 184.7556 - accuracy: 0.0000e+00 - val_loss: 59.7593 - val_accuracy: 0.0000e+00\n",
      "Epoch 639/700\n",
      "12/12 - 0s - loss: 184.7227 - accuracy: 0.0000e+00 - val_loss: 59.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 640/700\n",
      "12/12 - 0s - loss: 184.6561 - accuracy: 0.0000e+00 - val_loss: 59.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 641/700\n",
      "12/12 - 0s - loss: 184.9108 - accuracy: 0.0000e+00 - val_loss: 59.6816 - val_accuracy: 0.0000e+00\n",
      "Epoch 642/700\n",
      "12/12 - 0s - loss: 184.6908 - accuracy: 0.0000e+00 - val_loss: 59.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 643/700\n",
      "12/12 - 0s - loss: 184.7732 - accuracy: 0.0000e+00 - val_loss: 59.5837 - val_accuracy: 0.0000e+00\n",
      "Epoch 644/700\n",
      "12/12 - 0s - loss: 184.8044 - accuracy: 0.0000e+00 - val_loss: 59.5552 - val_accuracy: 0.0000e+00\n",
      "Epoch 645/700\n",
      "12/12 - 0s - loss: 184.7930 - accuracy: 0.0000e+00 - val_loss: 59.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 646/700\n",
      "12/12 - 0s - loss: 184.7431 - accuracy: 0.0000e+00 - val_loss: 59.5300 - val_accuracy: 0.0000e+00\n",
      "Epoch 647/700\n",
      "12/12 - 0s - loss: 184.6581 - accuracy: 0.0000e+00 - val_loss: 59.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 648/700\n",
      "12/12 - 0s - loss: 184.5420 - accuracy: 0.0000e+00 - val_loss: 59.5403 - val_accuracy: 0.0000e+00\n",
      "Epoch 649/700\n",
      "12/12 - 0s - loss: 184.3985 - accuracy: 0.0000e+00 - val_loss: 59.5562 - val_accuracy: 0.0000e+00\n",
      "Epoch 650/700\n",
      "12/12 - 0s - loss: 185.0916 - accuracy: 0.0000e+00 - val_loss: 59.4990 - val_accuracy: 0.0000e+00\n",
      "Epoch 651/700\n",
      "12/12 - 0s - loss: 184.3884 - accuracy: 0.0000e+00 - val_loss: 59.3743 - val_accuracy: 0.0000e+00\n",
      "Epoch 652/700\n",
      "12/12 - 0s - loss: 184.6098 - accuracy: 0.0000e+00 - val_loss: 59.2715 - val_accuracy: 0.0000e+00\n",
      "Epoch 653/700\n",
      "12/12 - 0s - loss: 184.8601 - accuracy: 0.0000e+00 - val_loss: 59.5291 - val_accuracy: 0.0000e+00\n",
      "Epoch 654/700\n",
      "12/12 - 0s - loss: 185.0542 - accuracy: 0.0000e+00 - val_loss: 62.5142 - val_accuracy: 0.0000e+00\n",
      "Epoch 655/700\n",
      "12/12 - 0s - loss: 185.1934 - accuracy: 0.0000e+00 - val_loss: 64.3325 - val_accuracy: 0.0000e+00\n",
      "Epoch 656/700\n",
      "12/12 - 0s - loss: 185.2647 - accuracy: 0.0000e+00 - val_loss: 65.0999 - val_accuracy: 0.0000e+00\n",
      "Epoch 657/700\n",
      "12/12 - 0s - loss: 185.2681 - accuracy: 0.0000e+00 - val_loss: 64.9146 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 658/700\n",
      "12/12 - 0s - loss: 185.2240 - accuracy: 0.0000e+00 - val_loss: 63.9053 - val_accuracy: 0.0000e+00\n",
      "Epoch 659/700\n",
      "12/12 - 0s - loss: 185.1446 - accuracy: 0.0000e+00 - val_loss: 62.1511 - val_accuracy: 0.0000e+00\n",
      "Epoch 660/700\n",
      "12/12 - 0s - loss: 185.0387 - accuracy: 0.0000e+00 - val_loss: 59.7551 - val_accuracy: 0.0000e+00\n",
      "Epoch 661/700\n",
      "12/12 - 0s - loss: 184.9152 - accuracy: 0.0000e+00 - val_loss: 59.0239 - val_accuracy: 0.0000e+00\n",
      "Epoch 662/700\n",
      "12/12 - 0s - loss: 184.7664 - accuracy: 0.0000e+00 - val_loss: 59.0481 - val_accuracy: 0.0000e+00\n",
      "Epoch 663/700\n",
      "12/12 - 0s - loss: 184.6011 - accuracy: 0.0000e+00 - val_loss: 59.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 664/700\n",
      "12/12 - 0s - loss: 184.4243 - accuracy: 0.0000e+00 - val_loss: 59.1116 - val_accuracy: 0.0000e+00\n",
      "Epoch 665/700\n",
      "12/12 - 0s - loss: 184.2250 - accuracy: 0.0000e+00 - val_loss: 59.1516 - val_accuracy: 0.0000e+00\n",
      "Epoch 666/700\n",
      "12/12 - 0s - loss: 184.5780 - accuracy: 0.0000e+00 - val_loss: 59.1135 - val_accuracy: 0.0000e+00\n",
      "Epoch 667/700\n",
      "12/12 - 0s - loss: 184.2825 - accuracy: 0.0000e+00 - val_loss: 59.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 668/700\n",
      "12/12 - 0s - loss: 184.2498 - accuracy: 0.0000e+00 - val_loss: 58.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 669/700\n",
      "12/12 - 0s - loss: 184.4255 - accuracy: 0.0000e+00 - val_loss: 58.8447 - val_accuracy: 0.0000e+00\n",
      "Epoch 670/700\n",
      "12/12 - 0s - loss: 184.5569 - accuracy: 0.0000e+00 - val_loss: 58.7896 - val_accuracy: 0.0000e+00\n",
      "Epoch 671/700\n",
      "12/12 - 0s - loss: 184.6363 - accuracy: 0.0000e+00 - val_loss: 58.7490 - val_accuracy: 0.0000e+00\n",
      "Epoch 672/700\n",
      "12/12 - 0s - loss: 184.6694 - accuracy: 0.0000e+00 - val_loss: 58.7200 - val_accuracy: 0.0000e+00\n",
      "Epoch 673/700\n",
      "12/12 - 0s - loss: 184.6603 - accuracy: 0.0000e+00 - val_loss: 58.7041 - val_accuracy: 0.0000e+00\n",
      "Epoch 674/700\n",
      "12/12 - 0s - loss: 184.6178 - accuracy: 0.0000e+00 - val_loss: 58.6985 - val_accuracy: 0.0000e+00\n",
      "Epoch 675/700\n",
      "12/12 - 0s - loss: 184.5376 - accuracy: 0.0000e+00 - val_loss: 58.7029 - val_accuracy: 0.0000e+00\n",
      "Epoch 676/700\n",
      "12/12 - 0s - loss: 184.4198 - accuracy: 0.0000e+00 - val_loss: 58.7158 - val_accuracy: 0.0000e+00\n",
      "Epoch 677/700\n",
      "12/12 - 0s - loss: 184.2764 - accuracy: 0.0000e+00 - val_loss: 58.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 678/700\n",
      "12/12 - 0s - loss: 184.1096 - accuracy: 0.0000e+00 - val_loss: 58.7646 - val_accuracy: 0.0000e+00\n",
      "Epoch 679/700\n",
      "12/12 - 0s - loss: 183.9199 - accuracy: 0.0000e+00 - val_loss: 58.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 680/700\n",
      "12/12 - 0s - loss: 184.2041 - accuracy: 0.0000e+00 - val_loss: 58.7542 - val_accuracy: 0.0000e+00\n",
      "Epoch 681/700\n",
      "12/12 - 0s - loss: 183.8077 - accuracy: 0.0000e+00 - val_loss: 58.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 682/700\n",
      "12/12 - 0s - loss: 184.0201 - accuracy: 0.0000e+00 - val_loss: 58.5464 - val_accuracy: 0.0000e+00\n",
      "Epoch 683/700\n",
      "12/12 - 0s - loss: 184.2215 - accuracy: 0.0000e+00 - val_loss: 58.4712 - val_accuracy: 0.0000e+00\n",
      "Epoch 684/700\n",
      "12/12 - 0s - loss: 184.3643 - accuracy: 0.0000e+00 - val_loss: 58.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 685/700\n",
      "12/12 - 0s - loss: 184.4548 - accuracy: 0.0000e+00 - val_loss: 59.7344 - val_accuracy: 0.0000e+00\n",
      "Epoch 686/700\n",
      "12/12 - 0s - loss: 184.4958 - accuracy: 0.0000e+00 - val_loss: 60.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 687/700\n",
      "12/12 - 0s - loss: 184.4950 - accuracy: 0.0000e+00 - val_loss: 59.5574 - val_accuracy: 0.0000e+00\n",
      "Epoch 688/700\n",
      "12/12 - 0s - loss: 184.4540 - accuracy: 0.0000e+00 - val_loss: 58.3110 - val_accuracy: 0.0000e+00\n",
      "Epoch 689/700\n",
      "12/12 - 0s - loss: 184.3787 - accuracy: 0.0000e+00 - val_loss: 58.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 690/700\n",
      "12/12 - 0s - loss: 184.2708 - accuracy: 0.0000e+00 - val_loss: 58.3228 - val_accuracy: 0.0000e+00\n",
      "Epoch 691/700\n",
      "12/12 - 0s - loss: 184.1350 - accuracy: 0.0000e+00 - val_loss: 58.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 692/700\n",
      "12/12 - 0s - loss: 183.9743 - accuracy: 0.0000e+00 - val_loss: 58.3679 - val_accuracy: 0.0000e+00\n",
      "Epoch 693/700\n",
      "12/12 - 0s - loss: 183.7887 - accuracy: 0.0000e+00 - val_loss: 58.4001 - val_accuracy: 0.0000e+00\n",
      "Epoch 694/700\n",
      "12/12 - 0s - loss: 183.5839 - accuracy: 0.0000e+00 - val_loss: 58.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 695/700\n",
      "12/12 - 0s - loss: 184.3426 - accuracy: 0.0000e+00 - val_loss: 58.3972 - val_accuracy: 0.0000e+00\n",
      "Epoch 696/700\n",
      "12/12 - 0s - loss: 184.0110 - accuracy: 0.0000e+00 - val_loss: 58.2844 - val_accuracy: 0.0000e+00\n",
      "Epoch 697/700\n",
      "12/12 - 0s - loss: 183.6500 - accuracy: 0.0000e+00 - val_loss: 58.1926 - val_accuracy: 0.0000e+00\n",
      "Epoch 698/700\n",
      "12/12 - 0s - loss: 183.8448 - accuracy: 0.0000e+00 - val_loss: 58.1182 - val_accuracy: 0.0000e+00\n",
      "Epoch 699/700\n",
      "12/12 - 0s - loss: 183.9816 - accuracy: 0.0000e+00 - val_loss: 58.0598 - val_accuracy: 0.0000e+00\n",
      "Epoch 700/700\n",
      "12/12 - 0s - loss: 184.0649 - accuracy: 0.0000e+00 - val_loss: 58.0171 - val_accuracy: 0.0000e+00\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = horsepower_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=700,\n",
    "    # suppress logging\n",
    "    verbose=2,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>184.010986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.284424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>183.649979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.192627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>183.844803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.118164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>183.981613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.059814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>184.064941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.017090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  accuracy   val_loss  val_accuracy  epoch\n",
       "695  184.010986       0.0  58.284424           0.0    695\n",
       "696  183.649979       0.0  58.192627           0.0    696\n",
       "697  183.844803       0.0  58.118164           0.0    697\n",
       "698  183.981613       0.0  58.059814           0.0    698\n",
       "699  184.064941       0.0  58.017090           0.0    699"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13399.166 ],\n",
       "       [13482.966 ],\n",
       "       [13840.691 ],\n",
       "       [13857.1045],\n",
       "       [13611.081 ],\n",
       "       [13762.957 ],\n",
       "       [13978.702 ],\n",
       "       [14989.337 ],\n",
       "       [15673.184 ],\n",
       "       [15129.099 ],\n",
       "       [15279.999 ],\n",
       "       [15421.147 ],\n",
       "       [15384.357 ],\n",
       "       [15733.555 ],\n",
       "       [16016.083 ],\n",
       "       [16332.808 ],\n",
       "       [16125.317 ],\n",
       "       [16079.841 ],\n",
       "       [16475.389 ],\n",
       "       [17305.123 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = horsepower_model.predict(X)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x270dc8f0d68>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_plt = test['Last'].reset_index().drop(columns='index')\n",
    "plt.plot(test_plt, c='purple')\n",
    "plt.plot(predict, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
